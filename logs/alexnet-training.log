I0429 13:36:15.381860 25258 caffe.cpp:204] Using GPUs 1
I0429 13:36:15.409157 25258 caffe.cpp:209] GPU 1: GeForce GTX 1080 Ti
I0429 13:36:17.958443 25258 solver.cpp:45] Initializing solver from parameters: 
test_iter: 200
test_interval: 250
base_lr: 0.01
display: 20
max_iter: 20000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000
snapshot: 250
snapshot_prefix: "snap"
solver_mode: GPU
device_id: 1
net: "alex.train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I0429 13:36:17.958598 25258 solver.cpp:102] Creating training net from net file: alex.train_val.prototxt
I0429 13:36:17.959291 25258 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0429 13:36:17.959321 25258 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top_1
I0429 13:36:17.959327 25258 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top_2
I0429 13:36:17.959332 25258 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top_3
I0429 13:36:17.959559 25258 net.cpp:51] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "retina256/retina256_train_mean.binaryproto"
  }
  data_param {
    source: "retina256/retina256_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0429 13:36:17.959760 25258 layer_factory.hpp:77] Creating layer data
I0429 13:36:17.959872 25258 db_lmdb.cpp:35] Opened lmdb retina256/retina256_train_lmdb
I0429 13:36:17.959905 25258 net.cpp:84] Creating Layer data
I0429 13:36:17.959916 25258 net.cpp:380] data -> data
I0429 13:36:17.959946 25258 net.cpp:380] data -> label
I0429 13:36:17.959969 25258 data_transformer.cpp:25] Loading mean file from: retina256/retina256_train_mean.binaryproto
I0429 13:36:17.963685 25258 data_layer.cpp:45] output data size: 100,3,227,227
I0429 13:36:18.076221 25258 net.cpp:122] Setting up data
I0429 13:36:18.076253 25258 net.cpp:129] Top shape: 100 3 227 227 (15458700)
I0429 13:36:18.076261 25258 net.cpp:129] Top shape: 100 (100)
I0429 13:36:18.076267 25258 net.cpp:137] Memory required for data: 61835200
I0429 13:36:18.076278 25258 layer_factory.hpp:77] Creating layer conv1
I0429 13:36:18.076300 25258 net.cpp:84] Creating Layer conv1
I0429 13:36:18.076308 25258 net.cpp:406] conv1 <- data
I0429 13:36:18.076323 25258 net.cpp:380] conv1 -> conv1
I0429 13:36:20.518404 25258 net.cpp:122] Setting up conv1
I0429 13:36:20.518440 25258 net.cpp:129] Top shape: 100 96 55 55 (29040000)
I0429 13:36:20.518445 25258 net.cpp:137] Memory required for data: 177995200
I0429 13:36:20.518465 25258 layer_factory.hpp:77] Creating layer relu1
I0429 13:36:20.518477 25258 net.cpp:84] Creating Layer relu1
I0429 13:36:20.518483 25258 net.cpp:406] relu1 <- conv1
I0429 13:36:20.518489 25258 net.cpp:367] relu1 -> conv1 (in-place)
I0429 13:36:20.518648 25258 net.cpp:122] Setting up relu1
I0429 13:36:20.518657 25258 net.cpp:129] Top shape: 100 96 55 55 (29040000)
I0429 13:36:20.518662 25258 net.cpp:137] Memory required for data: 294155200
I0429 13:36:20.518666 25258 layer_factory.hpp:77] Creating layer norm1
I0429 13:36:20.518677 25258 net.cpp:84] Creating Layer norm1
I0429 13:36:20.518682 25258 net.cpp:406] norm1 <- conv1
I0429 13:36:20.518688 25258 net.cpp:380] norm1 -> norm1
I0429 13:36:20.518854 25258 net.cpp:122] Setting up norm1
I0429 13:36:20.518862 25258 net.cpp:129] Top shape: 100 96 55 55 (29040000)
I0429 13:36:20.518873 25258 net.cpp:137] Memory required for data: 410315200
I0429 13:36:20.518909 25258 layer_factory.hpp:77] Creating layer pool1
I0429 13:36:20.518919 25258 net.cpp:84] Creating Layer pool1
I0429 13:36:20.518929 25258 net.cpp:406] pool1 <- norm1
I0429 13:36:20.518940 25258 net.cpp:380] pool1 -> pool1
I0429 13:36:20.518996 25258 net.cpp:122] Setting up pool1
I0429 13:36:20.519007 25258 net.cpp:129] Top shape: 100 96 27 27 (6998400)
I0429 13:36:20.519012 25258 net.cpp:137] Memory required for data: 438308800
I0429 13:36:20.519018 25258 layer_factory.hpp:77] Creating layer conv2
I0429 13:36:20.519035 25258 net.cpp:84] Creating Layer conv2
I0429 13:36:20.519043 25258 net.cpp:406] conv2 <- pool1
I0429 13:36:20.519053 25258 net.cpp:380] conv2 -> conv2
I0429 13:36:20.525862 25258 net.cpp:122] Setting up conv2
I0429 13:36:20.525918 25258 net.cpp:129] Top shape: 100 256 27 27 (18662400)
I0429 13:36:20.525923 25258 net.cpp:137] Memory required for data: 512958400
I0429 13:36:20.525944 25258 layer_factory.hpp:77] Creating layer relu2
I0429 13:36:20.525961 25258 net.cpp:84] Creating Layer relu2
I0429 13:36:20.525967 25258 net.cpp:406] relu2 <- conv2
I0429 13:36:20.525974 25258 net.cpp:367] relu2 -> conv2 (in-place)
I0429 13:36:20.526195 25258 net.cpp:122] Setting up relu2
I0429 13:36:20.526203 25258 net.cpp:129] Top shape: 100 256 27 27 (18662400)
I0429 13:36:20.526207 25258 net.cpp:137] Memory required for data: 587608000
I0429 13:36:20.526212 25258 layer_factory.hpp:77] Creating layer norm2
I0429 13:36:20.526226 25258 net.cpp:84] Creating Layer norm2
I0429 13:36:20.526230 25258 net.cpp:406] norm2 <- conv2
I0429 13:36:20.526238 25258 net.cpp:380] norm2 -> norm2
I0429 13:36:20.526955 25258 net.cpp:122] Setting up norm2
I0429 13:36:20.526970 25258 net.cpp:129] Top shape: 100 256 27 27 (18662400)
I0429 13:36:20.526975 25258 net.cpp:137] Memory required for data: 662257600
I0429 13:36:20.526980 25258 layer_factory.hpp:77] Creating layer pool2
I0429 13:36:20.526996 25258 net.cpp:84] Creating Layer pool2
I0429 13:36:20.527001 25258 net.cpp:406] pool2 <- norm2
I0429 13:36:20.527009 25258 net.cpp:380] pool2 -> pool2
I0429 13:36:20.527051 25258 net.cpp:122] Setting up pool2
I0429 13:36:20.527058 25258 net.cpp:129] Top shape: 100 256 13 13 (4326400)
I0429 13:36:20.527061 25258 net.cpp:137] Memory required for data: 679563200
I0429 13:36:20.527065 25258 layer_factory.hpp:77] Creating layer conv3
I0429 13:36:20.527083 25258 net.cpp:84] Creating Layer conv3
I0429 13:36:20.527088 25258 net.cpp:406] conv3 <- pool2
I0429 13:36:20.527094 25258 net.cpp:380] conv3 -> conv3
I0429 13:36:20.535995 25258 net.cpp:122] Setting up conv3
I0429 13:36:20.536023 25258 net.cpp:129] Top shape: 100 384 13 13 (6489600)
I0429 13:36:20.536028 25258 net.cpp:137] Memory required for data: 705521600
I0429 13:36:20.536041 25258 layer_factory.hpp:77] Creating layer relu3
I0429 13:36:20.536051 25258 net.cpp:84] Creating Layer relu3
I0429 13:36:20.536056 25258 net.cpp:406] relu3 <- conv3
I0429 13:36:20.536063 25258 net.cpp:367] relu3 -> conv3 (in-place)
I0429 13:36:20.536548 25258 net.cpp:122] Setting up relu3
I0429 13:36:20.536561 25258 net.cpp:129] Top shape: 100 384 13 13 (6489600)
I0429 13:36:20.536566 25258 net.cpp:137] Memory required for data: 731480000
I0429 13:36:20.536569 25258 layer_factory.hpp:77] Creating layer conv4
I0429 13:36:20.536582 25258 net.cpp:84] Creating Layer conv4
I0429 13:36:20.536587 25258 net.cpp:406] conv4 <- conv3
I0429 13:36:20.536595 25258 net.cpp:380] conv4 -> conv4
I0429 13:36:20.543900 25258 net.cpp:122] Setting up conv4
I0429 13:36:20.543920 25258 net.cpp:129] Top shape: 100 384 13 13 (6489600)
I0429 13:36:20.543925 25258 net.cpp:137] Memory required for data: 757438400
I0429 13:36:20.543933 25258 layer_factory.hpp:77] Creating layer relu4
I0429 13:36:20.543943 25258 net.cpp:84] Creating Layer relu4
I0429 13:36:20.543948 25258 net.cpp:406] relu4 <- conv4
I0429 13:36:20.543954 25258 net.cpp:367] relu4 -> conv4 (in-place)
I0429 13:36:20.544435 25258 net.cpp:122] Setting up relu4
I0429 13:36:20.544453 25258 net.cpp:129] Top shape: 100 384 13 13 (6489600)
I0429 13:36:20.544486 25258 net.cpp:137] Memory required for data: 783396800
I0429 13:36:20.544492 25258 layer_factory.hpp:77] Creating layer conv5
I0429 13:36:20.544505 25258 net.cpp:84] Creating Layer conv5
I0429 13:36:20.544510 25258 net.cpp:406] conv5 <- conv4
I0429 13:36:20.544518 25258 net.cpp:380] conv5 -> conv5
I0429 13:36:20.550648 25258 net.cpp:122] Setting up conv5
I0429 13:36:20.550670 25258 net.cpp:129] Top shape: 100 256 13 13 (4326400)
I0429 13:36:20.550674 25258 net.cpp:137] Memory required for data: 800702400
I0429 13:36:20.550688 25258 layer_factory.hpp:77] Creating layer relu5
I0429 13:36:20.550696 25258 net.cpp:84] Creating Layer relu5
I0429 13:36:20.550703 25258 net.cpp:406] relu5 <- conv5
I0429 13:36:20.550710 25258 net.cpp:367] relu5 -> conv5 (in-place)
I0429 13:36:20.550860 25258 net.cpp:122] Setting up relu5
I0429 13:36:20.550871 25258 net.cpp:129] Top shape: 100 256 13 13 (4326400)
I0429 13:36:20.550878 25258 net.cpp:137] Memory required for data: 818008000
I0429 13:36:20.550881 25258 layer_factory.hpp:77] Creating layer pool5
I0429 13:36:20.550889 25258 net.cpp:84] Creating Layer pool5
I0429 13:36:20.550892 25258 net.cpp:406] pool5 <- conv5
I0429 13:36:20.550900 25258 net.cpp:380] pool5 -> pool5
I0429 13:36:20.550940 25258 net.cpp:122] Setting up pool5
I0429 13:36:20.550946 25258 net.cpp:129] Top shape: 100 256 6 6 (921600)
I0429 13:36:20.550951 25258 net.cpp:137] Memory required for data: 821694400
I0429 13:36:20.550956 25258 layer_factory.hpp:77] Creating layer fc6
I0429 13:36:20.550967 25258 net.cpp:84] Creating Layer fc6
I0429 13:36:20.550971 25258 net.cpp:406] fc6 <- pool5
I0429 13:36:20.550977 25258 net.cpp:380] fc6 -> fc6
I0429 13:36:20.889286 25258 net.cpp:122] Setting up fc6
I0429 13:36:20.889319 25258 net.cpp:129] Top shape: 100 4096 (409600)
I0429 13:36:20.889324 25258 net.cpp:137] Memory required for data: 823332800
I0429 13:36:20.889335 25258 layer_factory.hpp:77] Creating layer relu6
I0429 13:36:20.889348 25258 net.cpp:84] Creating Layer relu6
I0429 13:36:20.889353 25258 net.cpp:406] relu6 <- fc6
I0429 13:36:20.889360 25258 net.cpp:367] relu6 -> fc6 (in-place)
I0429 13:36:20.889559 25258 net.cpp:122] Setting up relu6
I0429 13:36:20.889572 25258 net.cpp:129] Top shape: 100 4096 (409600)
I0429 13:36:20.889576 25258 net.cpp:137] Memory required for data: 824971200
I0429 13:36:20.889580 25258 layer_factory.hpp:77] Creating layer drop6
I0429 13:36:20.889588 25258 net.cpp:84] Creating Layer drop6
I0429 13:36:20.889592 25258 net.cpp:406] drop6 <- fc6
I0429 13:36:20.889598 25258 net.cpp:367] drop6 -> fc6 (in-place)
I0429 13:36:20.889628 25258 net.cpp:122] Setting up drop6
I0429 13:36:20.889634 25258 net.cpp:129] Top shape: 100 4096 (409600)
I0429 13:36:20.889639 25258 net.cpp:137] Memory required for data: 826609600
I0429 13:36:20.889642 25258 layer_factory.hpp:77] Creating layer fc7
I0429 13:36:20.889652 25258 net.cpp:84] Creating Layer fc7
I0429 13:36:20.889655 25258 net.cpp:406] fc7 <- fc6
I0429 13:36:20.889662 25258 net.cpp:380] fc7 -> fc7
I0429 13:36:21.060091 25258 net.cpp:122] Setting up fc7
I0429 13:36:21.060137 25258 net.cpp:129] Top shape: 100 4096 (409600)
I0429 13:36:21.060144 25258 net.cpp:137] Memory required for data: 828248000
I0429 13:36:21.060159 25258 layer_factory.hpp:77] Creating layer relu7
I0429 13:36:21.060180 25258 net.cpp:84] Creating Layer relu7
I0429 13:36:21.060194 25258 net.cpp:406] relu7 <- fc7
I0429 13:36:21.060205 25258 net.cpp:367] relu7 -> fc7 (in-place)
I0429 13:36:21.060493 25258 net.cpp:122] Setting up relu7
I0429 13:36:21.060515 25258 net.cpp:129] Top shape: 100 4096 (409600)
I0429 13:36:21.060521 25258 net.cpp:137] Memory required for data: 829886400
I0429 13:36:21.060529 25258 layer_factory.hpp:77] Creating layer drop7
I0429 13:36:21.060540 25258 net.cpp:84] Creating Layer drop7
I0429 13:36:21.060547 25258 net.cpp:406] drop7 <- fc7
I0429 13:36:21.060556 25258 net.cpp:367] drop7 -> fc7 (in-place)
I0429 13:36:21.060598 25258 net.cpp:122] Setting up drop7
I0429 13:36:21.060609 25258 net.cpp:129] Top shape: 100 4096 (409600)
I0429 13:36:21.060662 25258 net.cpp:137] Memory required for data: 831524800
I0429 13:36:21.060672 25258 layer_factory.hpp:77] Creating layer fc8
I0429 13:36:21.060686 25258 net.cpp:84] Creating Layer fc8
I0429 13:36:21.060694 25258 net.cpp:406] fc8 <- fc7
I0429 13:36:21.060704 25258 net.cpp:380] fc8 -> fc8
I0429 13:36:21.061146 25258 net.cpp:122] Setting up fc8
I0429 13:36:21.061158 25258 net.cpp:129] Top shape: 100 5 (500)
I0429 13:36:21.061168 25258 net.cpp:137] Memory required for data: 831526800
I0429 13:36:21.061185 25258 layer_factory.hpp:77] Creating layer loss
I0429 13:36:21.061203 25258 net.cpp:84] Creating Layer loss
I0429 13:36:21.061210 25258 net.cpp:406] loss <- fc8
I0429 13:36:21.061220 25258 net.cpp:406] loss <- label
I0429 13:36:21.061233 25258 net.cpp:380] loss -> loss
I0429 13:36:21.061256 25258 layer_factory.hpp:77] Creating layer loss
I0429 13:36:21.062510 25258 net.cpp:122] Setting up loss
I0429 13:36:21.062539 25258 net.cpp:129] Top shape: (1)
I0429 13:36:21.062549 25258 net.cpp:132]     with loss weight 1
I0429 13:36:21.062572 25258 net.cpp:137] Memory required for data: 831526804
I0429 13:36:21.062579 25258 net.cpp:198] loss needs backward computation.
I0429 13:36:21.062608 25258 net.cpp:198] fc8 needs backward computation.
I0429 13:36:21.062614 25258 net.cpp:198] drop7 needs backward computation.
I0429 13:36:21.062619 25258 net.cpp:198] relu7 needs backward computation.
I0429 13:36:21.062625 25258 net.cpp:198] fc7 needs backward computation.
I0429 13:36:21.062633 25258 net.cpp:198] drop6 needs backward computation.
I0429 13:36:21.062638 25258 net.cpp:198] relu6 needs backward computation.
I0429 13:36:21.062644 25258 net.cpp:198] fc6 needs backward computation.
I0429 13:36:21.062661 25258 net.cpp:198] pool5 needs backward computation.
I0429 13:36:21.062675 25258 net.cpp:198] relu5 needs backward computation.
I0429 13:36:21.062681 25258 net.cpp:198] conv5 needs backward computation.
I0429 13:36:21.062687 25258 net.cpp:198] relu4 needs backward computation.
I0429 13:36:21.062692 25258 net.cpp:198] conv4 needs backward computation.
I0429 13:36:21.062700 25258 net.cpp:198] relu3 needs backward computation.
I0429 13:36:21.062706 25258 net.cpp:198] conv3 needs backward computation.
I0429 13:36:21.062716 25258 net.cpp:198] pool2 needs backward computation.
I0429 13:36:21.062731 25258 net.cpp:198] norm2 needs backward computation.
I0429 13:36:21.062742 25258 net.cpp:198] relu2 needs backward computation.
I0429 13:36:21.062748 25258 net.cpp:198] conv2 needs backward computation.
I0429 13:36:21.062754 25258 net.cpp:198] pool1 needs backward computation.
I0429 13:36:21.062760 25258 net.cpp:198] norm1 needs backward computation.
I0429 13:36:21.062768 25258 net.cpp:198] relu1 needs backward computation.
I0429 13:36:21.062779 25258 net.cpp:198] conv1 needs backward computation.
I0429 13:36:21.062795 25258 net.cpp:200] data does not need backward computation.
I0429 13:36:21.062805 25258 net.cpp:242] This network produces output loss
I0429 13:36:21.062829 25258 net.cpp:255] Network initialization done.
I0429 13:36:21.063518 25258 solver.cpp:190] Creating test net (#0) specified by net file: alex.train_val.prototxt
I0429 13:36:21.063621 25258 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0429 13:36:21.064064 25258 net.cpp:51] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "retina256/retina256_train_mean.binaryproto"
  }
  data_param {
    source: "retina256/retina256_test_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_top_1"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_top_1"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy_top_2"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_top_2"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 2
  }
}
layer {
  name: "accuracy_top_3"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy_top_3"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 3
  }
}
I0429 13:36:21.064362 25258 layer_factory.hpp:77] Creating layer data
I0429 13:36:21.064460 25258 db_lmdb.cpp:35] Opened lmdb retina256/retina256_test_lmdb
I0429 13:36:21.064486 25258 net.cpp:84] Creating Layer data
I0429 13:36:21.064504 25258 net.cpp:380] data -> data
I0429 13:36:21.064522 25258 net.cpp:380] data -> label
I0429 13:36:21.064533 25258 data_transformer.cpp:25] Loading mean file from: retina256/retina256_train_mean.binaryproto
I0429 13:36:21.068269 25258 data_layer.cpp:45] output data size: 64,3,227,227
I0429 13:36:21.175107 25258 net.cpp:122] Setting up data
I0429 13:36:21.175137 25258 net.cpp:129] Top shape: 64 3 227 227 (9893568)
I0429 13:36:21.175143 25258 net.cpp:129] Top shape: 64 (64)
I0429 13:36:21.175146 25258 net.cpp:137] Memory required for data: 39574528
I0429 13:36:21.175154 25258 layer_factory.hpp:77] Creating layer label_data_1_split
I0429 13:36:21.175168 25258 net.cpp:84] Creating Layer label_data_1_split
I0429 13:36:21.175173 25258 net.cpp:406] label_data_1_split <- label
I0429 13:36:21.175182 25258 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0429 13:36:21.175192 25258 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0429 13:36:21.175199 25258 net.cpp:380] label_data_1_split -> label_data_1_split_2
I0429 13:36:21.175206 25258 net.cpp:380] label_data_1_split -> label_data_1_split_3
I0429 13:36:21.175299 25258 net.cpp:122] Setting up label_data_1_split
I0429 13:36:21.175307 25258 net.cpp:129] Top shape: 64 (64)
I0429 13:36:21.175313 25258 net.cpp:129] Top shape: 64 (64)
I0429 13:36:21.175318 25258 net.cpp:129] Top shape: 64 (64)
I0429 13:36:21.175321 25258 net.cpp:129] Top shape: 64 (64)
I0429 13:36:21.175325 25258 net.cpp:137] Memory required for data: 39575552
I0429 13:36:21.175330 25258 layer_factory.hpp:77] Creating layer conv1
I0429 13:36:21.175343 25258 net.cpp:84] Creating Layer conv1
I0429 13:36:21.175348 25258 net.cpp:406] conv1 <- data
I0429 13:36:21.175355 25258 net.cpp:380] conv1 -> conv1
I0429 13:36:21.176735 25258 net.cpp:122] Setting up conv1
I0429 13:36:21.176750 25258 net.cpp:129] Top shape: 64 96 55 55 (18585600)
I0429 13:36:21.176754 25258 net.cpp:137] Memory required for data: 113917952
I0429 13:36:21.176766 25258 layer_factory.hpp:77] Creating layer relu1
I0429 13:36:21.176777 25258 net.cpp:84] Creating Layer relu1
I0429 13:36:21.176782 25258 net.cpp:406] relu1 <- conv1
I0429 13:36:21.176787 25258 net.cpp:367] relu1 -> conv1 (in-place)
I0429 13:36:21.180086 25258 net.cpp:122] Setting up relu1
I0429 13:36:21.180110 25258 net.cpp:129] Top shape: 64 96 55 55 (18585600)
I0429 13:36:21.180119 25258 net.cpp:137] Memory required for data: 188260352
I0429 13:36:21.180126 25258 layer_factory.hpp:77] Creating layer norm1
I0429 13:36:21.180142 25258 net.cpp:84] Creating Layer norm1
I0429 13:36:21.180153 25258 net.cpp:406] norm1 <- conv1
I0429 13:36:21.180164 25258 net.cpp:380] norm1 -> norm1
I0429 13:36:21.180403 25258 net.cpp:122] Setting up norm1
I0429 13:36:21.180414 25258 net.cpp:129] Top shape: 64 96 55 55 (18585600)
I0429 13:36:21.180419 25258 net.cpp:137] Memory required for data: 262602752
I0429 13:36:21.180423 25258 layer_factory.hpp:77] Creating layer pool1
I0429 13:36:21.180431 25258 net.cpp:84] Creating Layer pool1
I0429 13:36:21.180435 25258 net.cpp:406] pool1 <- norm1
I0429 13:36:21.180441 25258 net.cpp:380] pool1 -> pool1
I0429 13:36:21.180480 25258 net.cpp:122] Setting up pool1
I0429 13:36:21.180500 25258 net.cpp:129] Top shape: 64 96 27 27 (4478976)
I0429 13:36:21.180565 25258 net.cpp:137] Memory required for data: 280518656
I0429 13:36:21.180573 25258 layer_factory.hpp:77] Creating layer conv2
I0429 13:36:21.180588 25258 net.cpp:84] Creating Layer conv2
I0429 13:36:21.180594 25258 net.cpp:406] conv2 <- pool1
I0429 13:36:21.180609 25258 net.cpp:380] conv2 -> conv2
I0429 13:36:21.186303 25258 net.cpp:122] Setting up conv2
I0429 13:36:21.186339 25258 net.cpp:129] Top shape: 64 256 27 27 (11943936)
I0429 13:36:21.186344 25258 net.cpp:137] Memory required for data: 328294400
I0429 13:36:21.186359 25258 layer_factory.hpp:77] Creating layer relu2
I0429 13:36:21.186373 25258 net.cpp:84] Creating Layer relu2
I0429 13:36:21.186378 25258 net.cpp:406] relu2 <- conv2
I0429 13:36:21.186385 25258 net.cpp:367] relu2 -> conv2 (in-place)
I0429 13:36:21.186544 25258 net.cpp:122] Setting up relu2
I0429 13:36:21.186553 25258 net.cpp:129] Top shape: 64 256 27 27 (11943936)
I0429 13:36:21.186558 25258 net.cpp:137] Memory required for data: 376070144
I0429 13:36:21.186561 25258 layer_factory.hpp:77] Creating layer norm2
I0429 13:36:21.186573 25258 net.cpp:84] Creating Layer norm2
I0429 13:36:21.186578 25258 net.cpp:406] norm2 <- conv2
I0429 13:36:21.186585 25258 net.cpp:380] norm2 -> norm2
I0429 13:36:21.186766 25258 net.cpp:122] Setting up norm2
I0429 13:36:21.186782 25258 net.cpp:129] Top shape: 64 256 27 27 (11943936)
I0429 13:36:21.186790 25258 net.cpp:137] Memory required for data: 423845888
I0429 13:36:21.186796 25258 layer_factory.hpp:77] Creating layer pool2
I0429 13:36:21.186806 25258 net.cpp:84] Creating Layer pool2
I0429 13:36:21.186812 25258 net.cpp:406] pool2 <- norm2
I0429 13:36:21.186822 25258 net.cpp:380] pool2 -> pool2
I0429 13:36:21.186866 25258 net.cpp:122] Setting up pool2
I0429 13:36:21.186872 25258 net.cpp:129] Top shape: 64 256 13 13 (2768896)
I0429 13:36:21.186877 25258 net.cpp:137] Memory required for data: 434921472
I0429 13:36:21.186880 25258 layer_factory.hpp:77] Creating layer conv3
I0429 13:36:21.186893 25258 net.cpp:84] Creating Layer conv3
I0429 13:36:21.186898 25258 net.cpp:406] conv3 <- pool2
I0429 13:36:21.186906 25258 net.cpp:380] conv3 -> conv3
I0429 13:36:21.201256 25258 net.cpp:122] Setting up conv3
I0429 13:36:21.201292 25258 net.cpp:129] Top shape: 64 384 13 13 (4153344)
I0429 13:36:21.201297 25258 net.cpp:137] Memory required for data: 451534848
I0429 13:36:21.201314 25258 layer_factory.hpp:77] Creating layer relu3
I0429 13:36:21.201328 25258 net.cpp:84] Creating Layer relu3
I0429 13:36:21.201333 25258 net.cpp:406] relu3 <- conv3
I0429 13:36:21.201340 25258 net.cpp:367] relu3 -> conv3 (in-place)
I0429 13:36:21.202147 25258 net.cpp:122] Setting up relu3
I0429 13:36:21.202174 25258 net.cpp:129] Top shape: 64 384 13 13 (4153344)
I0429 13:36:21.202181 25258 net.cpp:137] Memory required for data: 468148224
I0429 13:36:21.202188 25258 layer_factory.hpp:77] Creating layer conv4
I0429 13:36:21.202208 25258 net.cpp:84] Creating Layer conv4
I0429 13:36:21.202216 25258 net.cpp:406] conv4 <- conv3
I0429 13:36:21.202227 25258 net.cpp:380] conv4 -> conv4
I0429 13:36:21.221180 25258 net.cpp:122] Setting up conv4
I0429 13:36:21.221223 25258 net.cpp:129] Top shape: 64 384 13 13 (4153344)
I0429 13:36:21.221230 25258 net.cpp:137] Memory required for data: 484761600
I0429 13:36:21.221246 25258 layer_factory.hpp:77] Creating layer relu4
I0429 13:36:21.221257 25258 net.cpp:84] Creating Layer relu4
I0429 13:36:21.221264 25258 net.cpp:406] relu4 <- conv4
I0429 13:36:21.221276 25258 net.cpp:367] relu4 -> conv4 (in-place)
I0429 13:36:21.222102 25258 net.cpp:122] Setting up relu4
I0429 13:36:21.222122 25258 net.cpp:129] Top shape: 64 384 13 13 (4153344)
I0429 13:36:21.222128 25258 net.cpp:137] Memory required for data: 501374976
I0429 13:36:21.222136 25258 layer_factory.hpp:77] Creating layer conv5
I0429 13:36:21.222152 25258 net.cpp:84] Creating Layer conv5
I0429 13:36:21.222158 25258 net.cpp:406] conv5 <- conv4
I0429 13:36:21.222168 25258 net.cpp:380] conv5 -> conv5
I0429 13:36:21.232313 25258 net.cpp:122] Setting up conv5
I0429 13:36:21.232368 25258 net.cpp:129] Top shape: 64 256 13 13 (2768896)
I0429 13:36:21.232394 25258 net.cpp:137] Memory required for data: 512450560
I0429 13:36:21.232424 25258 layer_factory.hpp:77] Creating layer relu5
I0429 13:36:21.232440 25258 net.cpp:84] Creating Layer relu5
I0429 13:36:21.232447 25258 net.cpp:406] relu5 <- conv5
I0429 13:36:21.232460 25258 net.cpp:367] relu5 -> conv5 (in-place)
I0429 13:36:21.233319 25258 net.cpp:122] Setting up relu5
I0429 13:36:21.233341 25258 net.cpp:129] Top shape: 64 256 13 13 (2768896)
I0429 13:36:21.233347 25258 net.cpp:137] Memory required for data: 523526144
I0429 13:36:21.233353 25258 layer_factory.hpp:77] Creating layer pool5
I0429 13:36:21.233369 25258 net.cpp:84] Creating Layer pool5
I0429 13:36:21.233376 25258 net.cpp:406] pool5 <- conv5
I0429 13:36:21.233386 25258 net.cpp:380] pool5 -> pool5
I0429 13:36:21.233464 25258 net.cpp:122] Setting up pool5
I0429 13:36:21.233479 25258 net.cpp:129] Top shape: 64 256 6 6 (589824)
I0429 13:36:21.233485 25258 net.cpp:137] Memory required for data: 525885440
I0429 13:36:21.233491 25258 layer_factory.hpp:77] Creating layer fc6
I0429 13:36:21.233503 25258 net.cpp:84] Creating Layer fc6
I0429 13:36:21.233510 25258 net.cpp:406] fc6 <- pool5
I0429 13:36:21.233522 25258 net.cpp:380] fc6 -> fc6
I0429 13:36:21.590605 25258 net.cpp:122] Setting up fc6
I0429 13:36:21.590644 25258 net.cpp:129] Top shape: 64 4096 (262144)
I0429 13:36:21.590651 25258 net.cpp:137] Memory required for data: 526934016
I0429 13:36:21.590667 25258 layer_factory.hpp:77] Creating layer relu6
I0429 13:36:21.590679 25258 net.cpp:84] Creating Layer relu6
I0429 13:36:21.590687 25258 net.cpp:406] relu6 <- fc6
I0429 13:36:21.590700 25258 net.cpp:367] relu6 -> fc6 (in-place)
I0429 13:36:21.590965 25258 net.cpp:122] Setting up relu6
I0429 13:36:21.590976 25258 net.cpp:129] Top shape: 64 4096 (262144)
I0429 13:36:21.590982 25258 net.cpp:137] Memory required for data: 527982592
I0429 13:36:21.590988 25258 layer_factory.hpp:77] Creating layer drop6
I0429 13:36:21.590999 25258 net.cpp:84] Creating Layer drop6
I0429 13:36:21.591006 25258 net.cpp:406] drop6 <- fc6
I0429 13:36:21.591015 25258 net.cpp:367] drop6 -> fc6 (in-place)
I0429 13:36:21.591048 25258 net.cpp:122] Setting up drop6
I0429 13:36:21.591058 25258 net.cpp:129] Top shape: 64 4096 (262144)
I0429 13:36:21.591063 25258 net.cpp:137] Memory required for data: 529031168
I0429 13:36:21.591068 25258 layer_factory.hpp:77] Creating layer fc7
I0429 13:36:21.591084 25258 net.cpp:84] Creating Layer fc7
I0429 13:36:21.591090 25258 net.cpp:406] fc7 <- fc6
I0429 13:36:21.591100 25258 net.cpp:380] fc7 -> fc7
I0429 13:36:21.740499 25258 net.cpp:122] Setting up fc7
I0429 13:36:21.740530 25258 net.cpp:129] Top shape: 64 4096 (262144)
I0429 13:36:21.740535 25258 net.cpp:137] Memory required for data: 530079744
I0429 13:36:21.740546 25258 layer_factory.hpp:77] Creating layer relu7
I0429 13:36:21.740556 25258 net.cpp:84] Creating Layer relu7
I0429 13:36:21.740561 25258 net.cpp:406] relu7 <- fc7
I0429 13:36:21.740571 25258 net.cpp:367] relu7 -> fc7 (in-place)
I0429 13:36:21.740779 25258 net.cpp:122] Setting up relu7
I0429 13:36:21.740788 25258 net.cpp:129] Top shape: 64 4096 (262144)
I0429 13:36:21.740792 25258 net.cpp:137] Memory required for data: 531128320
I0429 13:36:21.740798 25258 layer_factory.hpp:77] Creating layer drop7
I0429 13:36:21.740808 25258 net.cpp:84] Creating Layer drop7
I0429 13:36:21.740813 25258 net.cpp:406] drop7 <- fc7
I0429 13:36:21.740821 25258 net.cpp:367] drop7 -> fc7 (in-place)
I0429 13:36:21.740846 25258 net.cpp:122] Setting up drop7
I0429 13:36:21.740852 25258 net.cpp:129] Top shape: 64 4096 (262144)
I0429 13:36:21.740856 25258 net.cpp:137] Memory required for data: 532176896
I0429 13:36:21.740860 25258 layer_factory.hpp:77] Creating layer fc8
I0429 13:36:21.740870 25258 net.cpp:84] Creating Layer fc8
I0429 13:36:21.740876 25258 net.cpp:406] fc8 <- fc7
I0429 13:36:21.740886 25258 net.cpp:380] fc8 -> fc8
I0429 13:36:21.741135 25258 net.cpp:122] Setting up fc8
I0429 13:36:21.741143 25258 net.cpp:129] Top shape: 64 5 (320)
I0429 13:36:21.741155 25258 net.cpp:137] Memory required for data: 532178176
I0429 13:36:21.741194 25258 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0429 13:36:21.741204 25258 net.cpp:84] Creating Layer fc8_fc8_0_split
I0429 13:36:21.741215 25258 net.cpp:406] fc8_fc8_0_split <- fc8
I0429 13:36:21.741230 25258 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0429 13:36:21.741242 25258 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0429 13:36:21.741251 25258 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_2
I0429 13:36:21.741262 25258 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_3
I0429 13:36:21.741328 25258 net.cpp:122] Setting up fc8_fc8_0_split
I0429 13:36:21.741336 25258 net.cpp:129] Top shape: 64 5 (320)
I0429 13:36:21.741344 25258 net.cpp:129] Top shape: 64 5 (320)
I0429 13:36:21.741353 25258 net.cpp:129] Top shape: 64 5 (320)
I0429 13:36:21.741359 25258 net.cpp:129] Top shape: 64 5 (320)
I0429 13:36:21.741365 25258 net.cpp:137] Memory required for data: 532183296
I0429 13:36:21.741374 25258 layer_factory.hpp:77] Creating layer loss
I0429 13:36:21.741384 25258 net.cpp:84] Creating Layer loss
I0429 13:36:21.741389 25258 net.cpp:406] loss <- fc8_fc8_0_split_0
I0429 13:36:21.741396 25258 net.cpp:406] loss <- label_data_1_split_0
I0429 13:36:21.741403 25258 net.cpp:380] loss -> loss
I0429 13:36:21.741416 25258 layer_factory.hpp:77] Creating layer loss
I0429 13:36:21.742473 25258 net.cpp:122] Setting up loss
I0429 13:36:21.742491 25258 net.cpp:129] Top shape: (1)
I0429 13:36:21.742497 25258 net.cpp:132]     with loss weight 1
I0429 13:36:21.742514 25258 net.cpp:137] Memory required for data: 532183300
I0429 13:36:21.742521 25258 layer_factory.hpp:77] Creating layer accuracy_top_1
I0429 13:36:21.742534 25258 net.cpp:84] Creating Layer accuracy_top_1
I0429 13:36:21.742542 25258 net.cpp:406] accuracy_top_1 <- fc8_fc8_0_split_1
I0429 13:36:21.742552 25258 net.cpp:406] accuracy_top_1 <- label_data_1_split_1
I0429 13:36:21.742564 25258 net.cpp:380] accuracy_top_1 -> accuracy_top_1
I0429 13:36:21.742579 25258 net.cpp:122] Setting up accuracy_top_1
I0429 13:36:21.742588 25258 net.cpp:129] Top shape: (1)
I0429 13:36:21.742594 25258 net.cpp:137] Memory required for data: 532183304
I0429 13:36:21.742601 25258 layer_factory.hpp:77] Creating layer accuracy_top_2
I0429 13:36:21.742611 25258 net.cpp:84] Creating Layer accuracy_top_2
I0429 13:36:21.742619 25258 net.cpp:406] accuracy_top_2 <- fc8_fc8_0_split_2
I0429 13:36:21.742626 25258 net.cpp:406] accuracy_top_2 <- label_data_1_split_2
I0429 13:36:21.742637 25258 net.cpp:380] accuracy_top_2 -> accuracy_top_2
I0429 13:36:21.742650 25258 net.cpp:122] Setting up accuracy_top_2
I0429 13:36:21.742658 25258 net.cpp:129] Top shape: (1)
I0429 13:36:21.742666 25258 net.cpp:137] Memory required for data: 532183308
I0429 13:36:21.742672 25258 layer_factory.hpp:77] Creating layer accuracy_top_3
I0429 13:36:21.742681 25258 net.cpp:84] Creating Layer accuracy_top_3
I0429 13:36:21.742691 25258 net.cpp:406] accuracy_top_3 <- fc8_fc8_0_split_3
I0429 13:36:21.742698 25258 net.cpp:406] accuracy_top_3 <- label_data_1_split_3
I0429 13:36:21.742707 25258 net.cpp:380] accuracy_top_3 -> accuracy_top_3
I0429 13:36:21.742719 25258 net.cpp:122] Setting up accuracy_top_3
I0429 13:36:21.742727 25258 net.cpp:129] Top shape: (1)
I0429 13:36:21.742733 25258 net.cpp:137] Memory required for data: 532183312
I0429 13:36:21.742740 25258 net.cpp:200] accuracy_top_3 does not need backward computation.
I0429 13:36:21.742748 25258 net.cpp:200] accuracy_top_2 does not need backward computation.
I0429 13:36:21.742756 25258 net.cpp:200] accuracy_top_1 does not need backward computation.
I0429 13:36:21.742763 25258 net.cpp:198] loss needs backward computation.
I0429 13:36:21.742771 25258 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0429 13:36:21.742777 25258 net.cpp:198] fc8 needs backward computation.
I0429 13:36:21.742784 25258 net.cpp:198] drop7 needs backward computation.
I0429 13:36:21.742790 25258 net.cpp:198] relu7 needs backward computation.
I0429 13:36:21.742801 25258 net.cpp:198] fc7 needs backward computation.
I0429 13:36:21.742839 25258 net.cpp:198] drop6 needs backward computation.
I0429 13:36:21.742847 25258 net.cpp:198] relu6 needs backward computation.
I0429 13:36:21.742854 25258 net.cpp:198] fc6 needs backward computation.
I0429 13:36:21.742861 25258 net.cpp:198] pool5 needs backward computation.
I0429 13:36:21.742868 25258 net.cpp:198] relu5 needs backward computation.
I0429 13:36:21.742875 25258 net.cpp:198] conv5 needs backward computation.
I0429 13:36:21.742883 25258 net.cpp:198] relu4 needs backward computation.
I0429 13:36:21.742890 25258 net.cpp:198] conv4 needs backward computation.
I0429 13:36:21.742899 25258 net.cpp:198] relu3 needs backward computation.
I0429 13:36:21.742907 25258 net.cpp:198] conv3 needs backward computation.
I0429 13:36:21.742914 25258 net.cpp:198] pool2 needs backward computation.
I0429 13:36:21.742920 25258 net.cpp:198] norm2 needs backward computation.
I0429 13:36:21.742928 25258 net.cpp:198] relu2 needs backward computation.
I0429 13:36:21.742933 25258 net.cpp:198] conv2 needs backward computation.
I0429 13:36:21.742941 25258 net.cpp:198] pool1 needs backward computation.
I0429 13:36:21.742949 25258 net.cpp:198] norm1 needs backward computation.
I0429 13:36:21.742956 25258 net.cpp:198] relu1 needs backward computation.
I0429 13:36:21.742962 25258 net.cpp:198] conv1 needs backward computation.
I0429 13:36:21.742971 25258 net.cpp:200] label_data_1_split does not need backward computation.
I0429 13:36:21.742980 25258 net.cpp:200] data does not need backward computation.
I0429 13:36:21.742985 25258 net.cpp:242] This network produces output accuracy_top_1
I0429 13:36:21.742993 25258 net.cpp:242] This network produces output accuracy_top_2
I0429 13:36:21.743001 25258 net.cpp:242] This network produces output accuracy_top_3
I0429 13:36:21.743007 25258 net.cpp:242] This network produces output loss
I0429 13:36:21.743037 25258 net.cpp:255] Network initialization done.
I0429 13:36:21.743191 25258 solver.cpp:57] Solver scaffolding done.
I0429 13:36:21.743850 25258 caffe.cpp:239] Starting Optimization
I0429 13:36:21.743865 25258 solver.cpp:293] Solving AlexNet
I0429 13:36:21.743872 25258 solver.cpp:294] Learning Rate Policy: step
I0429 13:36:21.749167 25258 solver.cpp:351] Iteration 0, Testing net (#0)
I0429 13:36:21.868196 25258 blocking_queue.cpp:49] Waiting for data
I0429 13:36:31.336642 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.213437
I0429 13:36:31.336693 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.400234
I0429 13:36:31.336704 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.600156
I0429 13:36:31.336719 25258 solver.cpp:418]     Test net output #3: loss = 1.61024 (* 1 = 1.61024 loss)
I0429 13:36:31.419486 25258 solver.cpp:239] Iteration 0 (0 iter/s, 9.67526s/20 iters), loss = 1.62364
I0429 13:36:31.425846 25258 solver.cpp:258]     Train net output #0: loss = 1.62364 (* 1 = 1.62364 loss)
I0429 13:36:31.425891 25258 sgd_solver.cpp:112] Iteration 0, lr = 0.01
I0429 13:36:32.996281 25258 solver.cpp:239] Iteration 20 (12.7359 iter/s, 1.57036s/20 iters), loss = 1.61436
I0429 13:36:33.001665 25258 solver.cpp:258]     Train net output #0: loss = 1.61436 (* 1 = 1.61436 loss)
I0429 13:36:33.001832 25258 sgd_solver.cpp:112] Iteration 20, lr = 0.01
I0429 13:36:34.621938 25258 solver.cpp:239] Iteration 40 (12.3437 iter/s, 1.62026s/20 iters), loss = 1.60263
I0429 13:36:34.621999 25258 solver.cpp:258]     Train net output #0: loss = 1.60263 (* 1 = 1.60263 loss)
I0429 13:36:34.622009 25258 sgd_solver.cpp:112] Iteration 40, lr = 0.01
I0429 13:36:36.285037 25258 solver.cpp:239] Iteration 60 (12.0267 iter/s, 1.66296s/20 iters), loss = 1.62582
I0429 13:36:36.285117 25258 solver.cpp:258]     Train net output #0: loss = 1.62582 (* 1 = 1.62582 loss)
I0429 13:36:36.285130 25258 sgd_solver.cpp:112] Iteration 60, lr = 0.01
I0429 13:36:37.940790 25258 solver.cpp:239] Iteration 80 (12.0802 iter/s, 1.65561s/20 iters), loss = 1.61039
I0429 13:36:37.940845 25258 solver.cpp:258]     Train net output #0: loss = 1.61039 (* 1 = 1.61039 loss)
I0429 13:36:37.940863 25258 sgd_solver.cpp:112] Iteration 80, lr = 0.01
I0429 13:36:39.650665 25258 solver.cpp:239] Iteration 100 (11.6976 iter/s, 1.70975s/20 iters), loss = 1.57417
I0429 13:36:39.650727 25258 solver.cpp:258]     Train net output #0: loss = 1.57417 (* 1 = 1.57417 loss)
I0429 13:36:39.650739 25258 sgd_solver.cpp:112] Iteration 100, lr = 0.01
I0429 13:36:41.242009 25258 solver.cpp:239] Iteration 120 (12.569 iter/s, 1.59122s/20 iters), loss = 1.61032
I0429 13:36:41.246803 25258 solver.cpp:258]     Train net output #0: loss = 1.61032 (* 1 = 1.61032 loss)
I0429 13:36:41.246827 25258 sgd_solver.cpp:112] Iteration 120, lr = 0.01
I0429 13:36:42.890162 25258 solver.cpp:239] Iteration 140 (12.1706 iter/s, 1.6433s/20 iters), loss = 1.62678
I0429 13:36:42.890249 25258 solver.cpp:258]     Train net output #0: loss = 1.62678 (* 1 = 1.62678 loss)
I0429 13:36:42.890264 25258 sgd_solver.cpp:112] Iteration 140, lr = 0.01
I0429 13:36:44.532930 25258 solver.cpp:239] Iteration 160 (12.1758 iter/s, 1.6426s/20 iters), loss = 1.58652
I0429 13:36:44.533016 25258 solver.cpp:258]     Train net output #0: loss = 1.58652 (* 1 = 1.58652 loss)
I0429 13:36:44.533035 25258 sgd_solver.cpp:112] Iteration 160, lr = 0.01
I0429 13:36:46.251868 25258 solver.cpp:239] Iteration 180 (11.6362 iter/s, 1.71878s/20 iters), loss = 1.57883
I0429 13:36:46.252118 25258 solver.cpp:258]     Train net output #0: loss = 1.57883 (* 1 = 1.57883 loss)
I0429 13:36:46.252135 25258 sgd_solver.cpp:112] Iteration 180, lr = 0.01
I0429 13:36:48.093518 25258 solver.cpp:239] Iteration 200 (10.8617 iter/s, 1.84133s/20 iters), loss = 1.60402
I0429 13:36:48.098302 25258 solver.cpp:258]     Train net output #0: loss = 1.60402 (* 1 = 1.60402 loss)
I0429 13:36:48.098333 25258 sgd_solver.cpp:112] Iteration 200, lr = 0.01
I0429 13:36:50.648484 25258 solver.cpp:239] Iteration 220 (7.84283 iter/s, 2.5501s/20 iters), loss = 1.60216
I0429 13:36:50.648563 25258 solver.cpp:258]     Train net output #0: loss = 1.60216 (* 1 = 1.60216 loss)
I0429 13:36:50.648577 25258 sgd_solver.cpp:112] Iteration 220, lr = 0.01
I0429 13:36:52.551182 25258 solver.cpp:239] Iteration 240 (10.5123 iter/s, 1.90254s/20 iters), loss = 1.61315
I0429 13:36:52.551259 25258 solver.cpp:258]     Train net output #0: loss = 1.61315 (* 1 = 1.61315 loss)
I0429 13:36:52.551272 25258 sgd_solver.cpp:112] Iteration 240, lr = 0.01
I0429 13:36:53.320680 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_250.caffemodel
I0429 13:37:47.408267 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_250.solverstate
I0429 13:37:48.155374 25258 solver.cpp:351] Iteration 250, Testing net (#0)
I0429 13:37:48.415238 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:38:00.999838 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.242578
I0429 13:38:00.999887 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.444453
I0429 13:38:00.999897 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.625234
I0429 13:38:00.999909 25258 solver.cpp:418]     Test net output #3: loss = 1.61062 (* 1 = 1.61062 loss)
I0429 13:38:02.289372 25258 solver.cpp:239] Iteration 260 (0.286796 iter/s, 69.7359s/20 iters), loss = 1.61241
I0429 13:38:02.289433 25258 solver.cpp:258]     Train net output #0: loss = 1.61241 (* 1 = 1.61241 loss)
I0429 13:38:02.289445 25258 sgd_solver.cpp:112] Iteration 260, lr = 0.01
I0429 13:38:05.325752 25258 solver.cpp:239] Iteration 280 (6.58729 iter/s, 3.03615s/20 iters), loss = 1.60138
I0429 13:38:05.335539 25258 solver.cpp:258]     Train net output #0: loss = 1.60138 (* 1 = 1.60138 loss)
I0429 13:38:05.335583 25258 sgd_solver.cpp:112] Iteration 280, lr = 0.01
I0429 13:38:08.222481 25258 solver.cpp:239] Iteration 300 (6.92789 iter/s, 2.88688s/20 iters), loss = 1.5988
I0429 13:38:08.222555 25258 solver.cpp:258]     Train net output #0: loss = 1.5988 (* 1 = 1.5988 loss)
I0429 13:38:08.222573 25258 sgd_solver.cpp:112] Iteration 300, lr = 0.01
I0429 13:38:11.670532 25258 solver.cpp:239] Iteration 320 (5.8007 iter/s, 3.44786s/20 iters), loss = 1.6278
I0429 13:38:11.670599 25258 solver.cpp:258]     Train net output #0: loss = 1.6278 (* 1 = 1.6278 loss)
I0429 13:38:11.670612 25258 sgd_solver.cpp:112] Iteration 320, lr = 0.01
I0429 13:38:14.653095 25258 solver.cpp:239] Iteration 340 (6.70604 iter/s, 2.98239s/20 iters), loss = 1.57773
I0429 13:38:14.653157 25258 solver.cpp:258]     Train net output #0: loss = 1.57773 (* 1 = 1.57773 loss)
I0429 13:38:14.653172 25258 sgd_solver.cpp:112] Iteration 340, lr = 0.01
I0429 13:38:18.206651 25258 solver.cpp:239] Iteration 360 (5.62846 iter/s, 3.55337s/20 iters), loss = 1.6477
I0429 13:38:18.206933 25258 solver.cpp:258]     Train net output #0: loss = 1.6477 (* 1 = 1.6477 loss)
I0429 13:38:18.206948 25258 sgd_solver.cpp:112] Iteration 360, lr = 0.01
I0429 13:38:21.269490 25258 solver.cpp:239] Iteration 380 (6.53071 iter/s, 3.06245s/20 iters), loss = 1.62392
I0429 13:38:21.269544 25258 solver.cpp:258]     Train net output #0: loss = 1.62392 (* 1 = 1.62392 loss)
I0429 13:38:21.269557 25258 sgd_solver.cpp:112] Iteration 380, lr = 0.01
I0429 13:38:25.252074 25258 solver.cpp:239] Iteration 400 (5.02211 iter/s, 3.98239s/20 iters), loss = 1.602
I0429 13:38:25.252142 25258 solver.cpp:258]     Train net output #0: loss = 1.602 (* 1 = 1.602 loss)
I0429 13:38:25.252154 25258 sgd_solver.cpp:112] Iteration 400, lr = 0.01
I0429 13:38:29.355062 25258 solver.cpp:239] Iteration 420 (4.87475 iter/s, 4.10278s/20 iters), loss = 1.60381
I0429 13:38:29.355116 25258 solver.cpp:258]     Train net output #0: loss = 1.60381 (* 1 = 1.60381 loss)
I0429 13:38:29.355126 25258 sgd_solver.cpp:112] Iteration 420, lr = 0.01
I0429 13:38:33.312724 25258 solver.cpp:239] Iteration 440 (5.05373 iter/s, 3.95747s/20 iters), loss = 1.58573
I0429 13:38:33.312786 25258 solver.cpp:258]     Train net output #0: loss = 1.58573 (* 1 = 1.58573 loss)
I0429 13:38:33.312800 25258 sgd_solver.cpp:112] Iteration 440, lr = 0.01
I0429 13:38:36.607112 25258 solver.cpp:239] Iteration 460 (6.07125 iter/s, 3.29421s/20 iters), loss = 1.59139
I0429 13:38:36.607162 25258 solver.cpp:258]     Train net output #0: loss = 1.59139 (* 1 = 1.59139 loss)
I0429 13:38:36.607174 25258 sgd_solver.cpp:112] Iteration 460, lr = 0.01
I0429 13:38:41.016891 25258 solver.cpp:239] Iteration 480 (4.53558 iter/s, 4.40958s/20 iters), loss = 1.58392
I0429 13:38:41.016958 25258 solver.cpp:258]     Train net output #0: loss = 1.58392 (* 1 = 1.58392 loss)
I0429 13:38:41.016973 25258 sgd_solver.cpp:112] Iteration 480, lr = 0.01
I0429 13:38:45.430027 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_500.caffemodel
I0429 13:39:19.151681 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_500.solverstate
I0429 13:39:19.468391 25258 solver.cpp:351] Iteration 500, Testing net (#0)
I0429 13:39:20.000463 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:39:33.035959 25258 blocking_queue.cpp:49] Waiting for data
I0429 13:39:38.312378 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.247656
I0429 13:39:38.312431 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.462969
I0429 13:39:38.312448 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.685234
I0429 13:39:38.312467 25258 solver.cpp:418]     Test net output #3: loss = 1.58857 (* 1 = 1.58857 loss)
I0429 13:39:38.386492 25258 solver.cpp:239] Iteration 500 (0.348628 iter/s, 57.3678s/20 iters), loss = 1.57454
I0429 13:39:38.389948 25258 solver.cpp:258]     Train net output #0: loss = 1.57454 (* 1 = 1.57454 loss)
I0429 13:39:38.389991 25258 sgd_solver.cpp:112] Iteration 500, lr = 0.01
I0429 13:39:41.130189 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:39:41.294857 25258 solver.cpp:239] Iteration 520 (6.88519 iter/s, 2.90479s/20 iters), loss = 1.62206
I0429 13:39:41.302825 25258 solver.cpp:258]     Train net output #0: loss = 1.62206 (* 1 = 1.62206 loss)
I0429 13:39:41.303040 25258 sgd_solver.cpp:112] Iteration 520, lr = 0.01
I0429 13:39:43.275378 25258 solver.cpp:239] Iteration 540 (10.139 iter/s, 1.97257s/20 iters), loss = 1.61488
I0429 13:39:43.281014 25258 solver.cpp:258]     Train net output #0: loss = 1.61488 (* 1 = 1.61488 loss)
I0429 13:39:43.281081 25258 sgd_solver.cpp:112] Iteration 540, lr = 0.01
I0429 13:39:45.857188 25258 solver.cpp:239] Iteration 560 (7.7636 iter/s, 2.57612s/20 iters), loss = 1.61155
I0429 13:39:45.857244 25258 solver.cpp:258]     Train net output #0: loss = 1.61155 (* 1 = 1.61155 loss)
I0429 13:39:45.857254 25258 sgd_solver.cpp:112] Iteration 560, lr = 0.01
I0429 13:39:50.887159 25258 solver.cpp:239] Iteration 580 (3.97634 iter/s, 5.02975s/20 iters), loss = 1.59012
I0429 13:39:50.888242 25258 solver.cpp:258]     Train net output #0: loss = 1.59012 (* 1 = 1.59012 loss)
I0429 13:39:50.888262 25258 sgd_solver.cpp:112] Iteration 580, lr = 0.01
I0429 13:39:56.231335 25258 solver.cpp:239] Iteration 600 (3.74327 iter/s, 5.34292s/20 iters), loss = 1.54648
I0429 13:39:56.238910 25258 solver.cpp:258]     Train net output #0: loss = 1.54648 (* 1 = 1.54648 loss)
I0429 13:39:56.239003 25258 sgd_solver.cpp:112] Iteration 600, lr = 0.01
I0429 13:40:00.282306 25258 solver.cpp:239] Iteration 620 (4.9464 iter/s, 4.04334s/20 iters), loss = 1.54969
I0429 13:40:00.282362 25258 solver.cpp:258]     Train net output #0: loss = 1.54969 (* 1 = 1.54969 loss)
I0429 13:40:00.282372 25258 sgd_solver.cpp:112] Iteration 620, lr = 0.01
I0429 13:40:03.847741 25258 solver.cpp:239] Iteration 640 (5.6097 iter/s, 3.56525s/20 iters), loss = 1.57421
I0429 13:40:03.852589 25258 solver.cpp:258]     Train net output #0: loss = 1.57421 (* 1 = 1.57421 loss)
I0429 13:40:03.852630 25258 sgd_solver.cpp:112] Iteration 640, lr = 0.01
I0429 13:40:07.809651 25258 solver.cpp:239] Iteration 660 (5.05439 iter/s, 3.95696s/20 iters), loss = 1.61244
I0429 13:40:07.809715 25258 solver.cpp:258]     Train net output #0: loss = 1.61244 (* 1 = 1.61244 loss)
I0429 13:40:07.809725 25258 sgd_solver.cpp:112] Iteration 660, lr = 0.01
I0429 13:40:12.799304 25258 solver.cpp:239] Iteration 680 (4.00847 iter/s, 4.98943s/20 iters), loss = 1.53025
I0429 13:40:12.804152 25258 solver.cpp:258]     Train net output #0: loss = 1.53025 (* 1 = 1.53025 loss)
I0429 13:40:12.804198 25258 sgd_solver.cpp:112] Iteration 680, lr = 0.01
I0429 13:40:17.230077 25258 solver.cpp:239] Iteration 700 (4.51897 iter/s, 4.42579s/20 iters), loss = 1.58006
I0429 13:40:17.237015 25258 solver.cpp:258]     Train net output #0: loss = 1.58006 (* 1 = 1.58006 loss)
I0429 13:40:17.237130 25258 sgd_solver.cpp:112] Iteration 700, lr = 0.01
I0429 13:40:22.139997 25258 solver.cpp:239] Iteration 720 (4.07924 iter/s, 4.90287s/20 iters), loss = 1.58697
I0429 13:40:22.145311 25258 solver.cpp:258]     Train net output #0: loss = 1.58697 (* 1 = 1.58697 loss)
I0429 13:40:22.145355 25258 sgd_solver.cpp:112] Iteration 720, lr = 0.01
I0429 13:40:28.764991 25258 solver.cpp:239] Iteration 740 (3.02137 iter/s, 6.61951s/20 iters), loss = 1.59052
I0429 13:40:28.765055 25258 solver.cpp:258]     Train net output #0: loss = 1.59052 (* 1 = 1.59052 loss)
I0429 13:40:28.765071 25258 sgd_solver.cpp:112] Iteration 740, lr = 0.01
I0429 13:40:31.419633 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_750.caffemodel
I0429 13:40:52.711079 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_750.solverstate
I0429 13:40:53.042855 25258 solver.cpp:351] Iteration 750, Testing net (#0)
I0429 13:40:53.650079 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:41:11.872097 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.249844
I0429 13:41:11.872153 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.441563
I0429 13:41:11.872161 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.642031
I0429 13:41:11.872175 25258 solver.cpp:418]     Test net output #3: loss = 1.60136 (* 1 = 1.60136 loss)
I0429 13:41:13.821230 25258 solver.cpp:239] Iteration 760 (0.443907 iter/s, 45.0545s/20 iters), loss = 1.60169
I0429 13:41:13.821346 25258 solver.cpp:258]     Train net output #0: loss = 1.60169 (* 1 = 1.60169 loss)
I0429 13:41:13.821374 25258 sgd_solver.cpp:112] Iteration 760, lr = 0.01
I0429 13:41:19.410789 25258 solver.cpp:239] Iteration 780 (3.57829 iter/s, 5.58926s/20 iters), loss = 1.59559
I0429 13:41:19.415776 25258 solver.cpp:258]     Train net output #0: loss = 1.59559 (* 1 = 1.59559 loss)
I0429 13:41:19.415818 25258 sgd_solver.cpp:112] Iteration 780, lr = 0.01
I0429 13:41:24.530377 25258 solver.cpp:239] Iteration 800 (3.91048 iter/s, 5.11446s/20 iters), loss = 1.6166
I0429 13:41:24.530591 25258 solver.cpp:258]     Train net output #0: loss = 1.6166 (* 1 = 1.6166 loss)
I0429 13:41:24.530606 25258 sgd_solver.cpp:112] Iteration 800, lr = 0.01
I0429 13:41:28.589303 25258 solver.cpp:239] Iteration 820 (4.92784 iter/s, 4.05857s/20 iters), loss = 1.57795
I0429 13:41:28.594110 25258 solver.cpp:258]     Train net output #0: loss = 1.57795 (* 1 = 1.57795 loss)
I0429 13:41:28.594136 25258 sgd_solver.cpp:112] Iteration 820, lr = 0.01
I0429 13:41:32.130885 25258 solver.cpp:239] Iteration 840 (5.65502 iter/s, 3.53668s/20 iters), loss = 1.58764
I0429 13:41:32.130951 25258 solver.cpp:258]     Train net output #0: loss = 1.58764 (* 1 = 1.58764 loss)
I0429 13:41:32.130967 25258 sgd_solver.cpp:112] Iteration 840, lr = 0.01
I0429 13:41:35.528707 25258 solver.cpp:239] Iteration 860 (5.88645 iter/s, 3.39763s/20 iters), loss = 1.56261
I0429 13:41:35.533524 25258 solver.cpp:258]     Train net output #0: loss = 1.56261 (* 1 = 1.56261 loss)
I0429 13:41:35.533571 25258 sgd_solver.cpp:112] Iteration 860, lr = 0.01
I0429 13:41:39.837968 25258 solver.cpp:239] Iteration 880 (4.64649 iter/s, 4.30433s/20 iters), loss = 1.63721
I0429 13:41:39.842773 25258 solver.cpp:258]     Train net output #0: loss = 1.63721 (* 1 = 1.63721 loss)
I0429 13:41:39.842803 25258 sgd_solver.cpp:112] Iteration 880, lr = 0.01
I0429 13:41:44.595715 25258 solver.cpp:239] Iteration 900 (4.20805 iter/s, 4.7528s/20 iters), loss = 1.57505
I0429 13:41:44.600625 25258 solver.cpp:258]     Train net output #0: loss = 1.57505 (* 1 = 1.57505 loss)
I0429 13:41:44.600661 25258 sgd_solver.cpp:112] Iteration 900, lr = 0.01
I0429 13:41:49.186928 25258 solver.cpp:239] Iteration 920 (4.36117 iter/s, 4.58592s/20 iters), loss = 1.58754
I0429 13:41:49.187000 25258 solver.cpp:258]     Train net output #0: loss = 1.58754 (* 1 = 1.58754 loss)
I0429 13:41:49.187011 25258 sgd_solver.cpp:112] Iteration 920, lr = 0.01
I0429 13:41:54.048064 25258 solver.cpp:239] Iteration 940 (4.11446 iter/s, 4.8609s/20 iters), loss = 1.58678
I0429 13:41:54.052858 25258 solver.cpp:258]     Train net output #0: loss = 1.58678 (* 1 = 1.58678 loss)
I0429 13:41:54.052888 25258 sgd_solver.cpp:112] Iteration 940, lr = 0.01
I0429 13:41:58.517035 25258 solver.cpp:239] Iteration 960 (4.48024 iter/s, 4.46405s/20 iters), loss = 1.57339
I0429 13:41:58.523216 25258 solver.cpp:258]     Train net output #0: loss = 1.57339 (* 1 = 1.57339 loss)
I0429 13:41:58.523241 25258 sgd_solver.cpp:112] Iteration 960, lr = 0.01
I0429 13:42:03.363566 25258 solver.cpp:239] Iteration 980 (4.13205 iter/s, 4.84021s/20 iters), loss = 1.53405
I0429 13:42:03.368382 25258 solver.cpp:258]     Train net output #0: loss = 1.53405 (* 1 = 1.53405 loss)
I0429 13:42:03.368412 25258 sgd_solver.cpp:112] Iteration 980, lr = 0.01
I0429 13:42:08.134791 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_1000.caffemodel
I0429 13:43:00.444859 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_1000.solverstate
I0429 13:43:00.819686 25258 solver.cpp:351] Iteration 1000, Testing net (#0)
I0429 13:43:01.322703 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:43:11.905694 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.289922
I0429 13:43:11.905797 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.507187
I0429 13:43:11.905827 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.702031
I0429 13:43:11.905850 25258 solver.cpp:418]     Test net output #3: loss = 1.56319 (* 1 = 1.56319 loss)
I0429 13:43:12.054374 25258 solver.cpp:239] Iteration 1000 (0.291189 iter/s, 68.684s/20 iters), loss = 1.51569
I0429 13:43:12.054464 25258 solver.cpp:258]     Train net output #0: loss = 1.51569 (* 1 = 1.51569 loss)
I0429 13:43:12.054476 25258 sgd_solver.cpp:112] Iteration 1000, lr = 0.01
I0429 13:43:14.951659 25258 solver.cpp:239] Iteration 1020 (6.9087 iter/s, 2.8949s/20 iters), loss = 1.55861
I0429 13:43:14.951720 25258 solver.cpp:258]     Train net output #0: loss = 1.55861 (* 1 = 1.55861 loss)
I0429 13:43:14.951732 25258 sgd_solver.cpp:112] Iteration 1020, lr = 0.01
I0429 13:43:17.679141 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:43:17.905040 25258 solver.cpp:239] Iteration 1040 (6.77231 iter/s, 2.9532s/20 iters), loss = 1.59611
I0429 13:43:17.910639 25258 solver.cpp:258]     Train net output #0: loss = 1.59611 (* 1 = 1.59611 loss)
I0429 13:43:17.910704 25258 sgd_solver.cpp:112] Iteration 1040, lr = 0.01
I0429 13:43:21.277896 25258 solver.cpp:239] Iteration 1060 (5.9397 iter/s, 3.36717s/20 iters), loss = 1.58857
I0429 13:43:21.283298 25258 solver.cpp:258]     Train net output #0: loss = 1.58857 (* 1 = 1.58857 loss)
I0429 13:43:21.283349 25258 sgd_solver.cpp:112] Iteration 1060, lr = 0.01
I0429 13:43:24.117235 25258 solver.cpp:239] Iteration 1080 (7.0575 iter/s, 2.83387s/20 iters), loss = 1.55323
I0429 13:43:24.122023 25258 solver.cpp:258]     Train net output #0: loss = 1.55323 (* 1 = 1.55323 loss)
I0429 13:43:24.122045 25258 sgd_solver.cpp:112] Iteration 1080, lr = 0.01
I0429 13:43:28.793861 25258 solver.cpp:239] Iteration 1100 (4.2811 iter/s, 4.67169s/20 iters), loss = 1.56403
I0429 13:43:28.798671 25258 solver.cpp:258]     Train net output #0: loss = 1.56403 (* 1 = 1.56403 loss)
I0429 13:43:28.798696 25258 sgd_solver.cpp:112] Iteration 1100, lr = 0.01
I0429 13:43:32.638759 25258 solver.cpp:239] Iteration 1120 (5.20837 iter/s, 3.83997s/20 iters), loss = 1.50056
I0429 13:43:32.643610 25258 solver.cpp:258]     Train net output #0: loss = 1.50056 (* 1 = 1.50056 loss)
I0429 13:43:32.643645 25258 sgd_solver.cpp:112] Iteration 1120, lr = 0.01
I0429 13:43:35.004943 25258 solver.cpp:239] Iteration 1140 (8.46996 iter/s, 2.36129s/20 iters), loss = 1.49789
I0429 13:43:35.009773 25258 solver.cpp:258]     Train net output #0: loss = 1.49789 (* 1 = 1.49789 loss)
I0429 13:43:35.009798 25258 sgd_solver.cpp:112] Iteration 1140, lr = 0.01
I0429 13:43:40.863121 25258 solver.cpp:239] Iteration 1160 (3.41696 iter/s, 5.85316s/20 iters), loss = 1.58144
I0429 13:43:40.869812 25258 solver.cpp:258]     Train net output #0: loss = 1.58144 (* 1 = 1.58144 loss)
I0429 13:43:40.869844 25258 sgd_solver.cpp:112] Iteration 1160, lr = 0.01
I0429 13:43:45.769574 25258 solver.cpp:239] Iteration 1180 (4.08195 iter/s, 4.89962s/20 iters), loss = 1.56741
I0429 13:43:45.769631 25258 solver.cpp:258]     Train net output #0: loss = 1.56741 (* 1 = 1.56741 loss)
I0429 13:43:45.769642 25258 sgd_solver.cpp:112] Iteration 1180, lr = 0.01
I0429 13:43:52.000183 25258 solver.cpp:239] Iteration 1200 (3.21009 iter/s, 6.23036s/20 iters), loss = 1.53748
I0429 13:43:52.004992 25258 solver.cpp:258]     Train net output #0: loss = 1.53748 (* 1 = 1.53748 loss)
I0429 13:43:52.005017 25258 sgd_solver.cpp:112] Iteration 1200, lr = 0.01
I0429 13:43:56.548310 25258 solver.cpp:239] Iteration 1220 (4.4022 iter/s, 4.54318s/20 iters), loss = 1.56374
I0429 13:43:56.553117 25258 solver.cpp:258]     Train net output #0: loss = 1.56374 (* 1 = 1.56374 loss)
I0429 13:43:56.553159 25258 sgd_solver.cpp:112] Iteration 1220, lr = 0.01
I0429 13:43:59.360023 25258 blocking_queue.cpp:49] Waiting for data
I0429 13:44:02.113911 25258 solver.cpp:239] Iteration 1240 (3.59672 iter/s, 5.56062s/20 iters), loss = 1.5515
I0429 13:44:02.122725 25258 solver.cpp:258]     Train net output #0: loss = 1.5515 (* 1 = 1.5515 loss)
I0429 13:44:02.122761 25258 sgd_solver.cpp:112] Iteration 1240, lr = 0.01
I0429 13:44:04.735528 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_1250.caffemodel
I0429 13:45:07.275954 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_1250.solverstate
I0429 13:45:07.639950 25258 solver.cpp:351] Iteration 1250, Testing net (#0)
I0429 13:45:08.257860 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:45:17.672062 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.289766
I0429 13:45:17.672107 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.505781
I0429 13:45:17.672119 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.712656
I0429 13:45:17.672133 25258 solver.cpp:418]     Test net output #3: loss = 1.55798 (* 1 = 1.55798 loss)
I0429 13:45:18.729602 25258 solver.cpp:239] Iteration 1260 (0.261081 iter/s, 76.6046s/20 iters), loss = 1.57988
I0429 13:45:18.735373 25258 solver.cpp:258]     Train net output #0: loss = 1.57988 (* 1 = 1.57988 loss)
I0429 13:45:18.735401 25258 sgd_solver.cpp:112] Iteration 1260, lr = 0.01
I0429 13:45:22.172286 25258 solver.cpp:239] Iteration 1280 (5.81934 iter/s, 3.43681s/20 iters), loss = 1.53706
I0429 13:45:22.177110 25258 solver.cpp:258]     Train net output #0: loss = 1.53706 (* 1 = 1.53706 loss)
I0429 13:45:22.177157 25258 sgd_solver.cpp:112] Iteration 1280, lr = 0.01
I0429 13:45:26.807171 25258 solver.cpp:239] Iteration 1300 (4.31971 iter/s, 4.62994s/20 iters), loss = 1.57107
I0429 13:45:26.812049 25258 solver.cpp:258]     Train net output #0: loss = 1.57107 (* 1 = 1.57107 loss)
I0429 13:45:26.812081 25258 sgd_solver.cpp:112] Iteration 1300, lr = 0.01
I0429 13:45:31.413022 25258 solver.cpp:239] Iteration 1320 (4.34703 iter/s, 4.60084s/20 iters), loss = 1.60126
I0429 13:45:31.417891 25258 solver.cpp:258]     Train net output #0: loss = 1.60126 (* 1 = 1.60126 loss)
I0429 13:45:31.417932 25258 sgd_solver.cpp:112] Iteration 1320, lr = 0.01
I0429 13:45:36.278990 25258 solver.cpp:239] Iteration 1340 (4.11617 iter/s, 4.85888s/20 iters), loss = 1.57249
I0429 13:45:36.281829 25258 solver.cpp:258]     Train net output #0: loss = 1.57249 (* 1 = 1.57249 loss)
I0429 13:45:36.281863 25258 sgd_solver.cpp:112] Iteration 1340, lr = 0.01
I0429 13:45:41.364408 25258 solver.cpp:239] Iteration 1360 (3.93513 iter/s, 5.08243s/20 iters), loss = 1.57357
I0429 13:45:41.369781 25258 solver.cpp:258]     Train net output #0: loss = 1.57357 (* 1 = 1.57357 loss)
I0429 13:45:41.369808 25258 sgd_solver.cpp:112] Iteration 1360, lr = 0.01
I0429 13:45:46.505365 25258 solver.cpp:239] Iteration 1380 (3.89447 iter/s, 5.13549s/20 iters), loss = 1.52394
I0429 13:45:46.510196 25258 solver.cpp:258]     Train net output #0: loss = 1.52394 (* 1 = 1.52394 loss)
I0429 13:45:46.510227 25258 sgd_solver.cpp:112] Iteration 1380, lr = 0.01
I0429 13:45:52.188560 25258 solver.cpp:239] Iteration 1400 (3.52224 iter/s, 5.6782s/20 iters), loss = 1.61295
I0429 13:45:52.193374 25258 solver.cpp:258]     Train net output #0: loss = 1.61295 (* 1 = 1.61295 loss)
I0429 13:45:52.193406 25258 sgd_solver.cpp:112] Iteration 1400, lr = 0.01
I0429 13:45:57.014137 25258 solver.cpp:239] Iteration 1420 (4.15098 iter/s, 4.81814s/20 iters), loss = 1.54125
I0429 13:45:57.016486 25258 solver.cpp:258]     Train net output #0: loss = 1.54125 (* 1 = 1.54125 loss)
I0429 13:45:57.016520 25258 sgd_solver.cpp:112] Iteration 1420, lr = 0.01
I0429 13:46:02.456073 25258 solver.cpp:239] Iteration 1440 (3.67713 iter/s, 5.43902s/20 iters), loss = 1.54445
I0429 13:46:02.460638 25258 solver.cpp:258]     Train net output #0: loss = 1.54445 (* 1 = 1.54445 loss)
I0429 13:46:02.460667 25258 sgd_solver.cpp:112] Iteration 1440, lr = 0.01
I0429 13:46:08.248996 25258 solver.cpp:239] Iteration 1460 (3.45532 iter/s, 5.78818s/20 iters), loss = 1.57291
I0429 13:46:08.253815 25258 solver.cpp:258]     Train net output #0: loss = 1.57291 (* 1 = 1.57291 loss)
I0429 13:46:08.253849 25258 sgd_solver.cpp:112] Iteration 1460, lr = 0.01
I0429 13:46:13.159211 25258 solver.cpp:239] Iteration 1480 (4.07726 iter/s, 4.90525s/20 iters), loss = 1.56526
I0429 13:46:13.164016 25258 solver.cpp:258]     Train net output #0: loss = 1.56526 (* 1 = 1.56526 loss)
I0429 13:46:13.164041 25258 sgd_solver.cpp:112] Iteration 1480, lr = 0.01
I0429 13:46:18.215672 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_1500.caffemodel
I0429 13:47:05.414186 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_1500.solverstate
I0429 13:47:05.763520 25258 solver.cpp:351] Iteration 1500, Testing net (#0)
I0429 13:47:06.555613 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:47:15.162854 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.291719
I0429 13:47:15.162915 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.504062
I0429 13:47:15.162925 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.703516
I0429 13:47:15.162937 25258 solver.cpp:418]     Test net output #3: loss = 1.55551 (* 1 = 1.55551 loss)
I0429 13:47:15.295542 25258 solver.cpp:239] Iteration 1500 (0.321917 iter/s, 62.1278s/20 iters), loss = 1.52641
I0429 13:47:15.296710 25258 solver.cpp:258]     Train net output #0: loss = 1.52641 (* 1 = 1.52641 loss)
I0429 13:47:15.296756 25258 sgd_solver.cpp:112] Iteration 1500, lr = 0.01
I0429 13:47:18.467850 25258 solver.cpp:239] Iteration 1520 (6.30706 iter/s, 3.17105s/20 iters), loss = 1.51205
I0429 13:47:18.467917 25258 solver.cpp:258]     Train net output #0: loss = 1.51205 (* 1 = 1.51205 loss)
I0429 13:47:18.467931 25258 sgd_solver.cpp:112] Iteration 1520, lr = 0.01
I0429 13:47:23.029343 25258 solver.cpp:239] Iteration 1540 (4.38473 iter/s, 4.56128s/20 iters), loss = 1.51935
I0429 13:47:23.029402 25258 solver.cpp:258]     Train net output #0: loss = 1.51935 (* 1 = 1.51935 loss)
I0429 13:47:23.029412 25258 sgd_solver.cpp:112] Iteration 1540, lr = 0.01
I0429 13:47:26.541472 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:47:27.269896 25258 solver.cpp:239] Iteration 1560 (4.71659 iter/s, 4.24035s/20 iters), loss = 1.55763
I0429 13:47:27.274832 25258 solver.cpp:258]     Train net output #0: loss = 1.55763 (* 1 = 1.55763 loss)
I0429 13:47:27.274871 25258 sgd_solver.cpp:112] Iteration 1560, lr = 0.01
I0429 13:47:32.174497 25258 solver.cpp:239] Iteration 1580 (4.08203 iter/s, 4.89952s/20 iters), loss = 1.55848
I0429 13:47:32.179280 25258 solver.cpp:258]     Train net output #0: loss = 1.55848 (* 1 = 1.55848 loss)
I0429 13:47:32.179309 25258 sgd_solver.cpp:112] Iteration 1580, lr = 0.01
I0429 13:47:37.547310 25258 solver.cpp:239] Iteration 1600 (3.72587 iter/s, 5.36787s/20 iters), loss = 1.56874
I0429 13:47:37.552134 25258 solver.cpp:258]     Train net output #0: loss = 1.56874 (* 1 = 1.56874 loss)
I0429 13:47:37.552156 25258 sgd_solver.cpp:112] Iteration 1600, lr = 0.01
I0429 13:47:41.581979 25258 solver.cpp:239] Iteration 1620 (4.96312 iter/s, 4.02972s/20 iters), loss = 1.4996
I0429 13:47:41.586791 25258 solver.cpp:258]     Train net output #0: loss = 1.4996 (* 1 = 1.4996 loss)
I0429 13:47:41.586823 25258 sgd_solver.cpp:112] Iteration 1620, lr = 0.01
I0429 13:47:47.185566 25258 solver.cpp:239] Iteration 1640 (3.57232 iter/s, 5.59861s/20 iters), loss = 1.51117
I0429 13:47:47.190379 25258 solver.cpp:258]     Train net output #0: loss = 1.51117 (* 1 = 1.51117 loss)
I0429 13:47:47.190418 25258 sgd_solver.cpp:112] Iteration 1640, lr = 0.01
I0429 13:47:51.578691 25258 solver.cpp:239] Iteration 1660 (4.55769 iter/s, 4.38819s/20 iters), loss = 1.48926
I0429 13:47:51.583542 25258 solver.cpp:258]     Train net output #0: loss = 1.48926 (* 1 = 1.48926 loss)
I0429 13:47:51.583577 25258 sgd_solver.cpp:112] Iteration 1660, lr = 0.01
I0429 13:47:56.890808 25258 solver.cpp:239] Iteration 1680 (3.76853 iter/s, 5.30711s/20 iters), loss = 1.57052
I0429 13:47:56.895638 25258 solver.cpp:258]     Train net output #0: loss = 1.57052 (* 1 = 1.57052 loss)
I0429 13:47:56.895674 25258 sgd_solver.cpp:112] Iteration 1680, lr = 0.01
I0429 13:48:02.483522 25258 solver.cpp:239] Iteration 1700 (3.57927 iter/s, 5.58772s/20 iters), loss = 1.56647
I0429 13:48:02.489821 25258 solver.cpp:258]     Train net output #0: loss = 1.56647 (* 1 = 1.56647 loss)
I0429 13:48:02.489868 25258 sgd_solver.cpp:112] Iteration 1700, lr = 0.01
I0429 13:48:08.258684 25258 solver.cpp:239] Iteration 1720 (3.46698 iter/s, 5.76871s/20 iters), loss = 1.53658
I0429 13:48:08.263487 25258 solver.cpp:258]     Train net output #0: loss = 1.53658 (* 1 = 1.53658 loss)
I0429 13:48:08.263612 25258 sgd_solver.cpp:112] Iteration 1720, lr = 0.01
I0429 13:48:13.902333 25258 solver.cpp:239] Iteration 1740 (3.54694 iter/s, 5.63866s/20 iters), loss = 1.54293
I0429 13:48:13.907155 25258 solver.cpp:258]     Train net output #0: loss = 1.54293 (* 1 = 1.54293 loss)
I0429 13:48:13.907202 25258 sgd_solver.cpp:112] Iteration 1740, lr = 0.01
I0429 13:48:15.416467 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_1750.caffemodel
I0429 13:49:21.475145 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_1750.solverstate
I0429 13:49:21.827229 25258 solver.cpp:351] Iteration 1750, Testing net (#0)
I0429 13:49:22.649559 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:49:29.821269 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.314687
I0429 13:49:29.821328 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.545078
I0429 13:49:29.821349 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.737031
I0429 13:49:29.821370 25258 solver.cpp:418]     Test net output #3: loss = 1.52675 (* 1 = 1.52675 loss)
I0429 13:49:30.691272 25258 solver.cpp:239] Iteration 1760 (0.260478 iter/s, 76.7819s/20 iters), loss = 1.52673
I0429 13:49:30.696069 25258 solver.cpp:258]     Train net output #0: loss = 1.52673 (* 1 = 1.52673 loss)
I0429 13:49:30.696104 25258 sgd_solver.cpp:112] Iteration 1760, lr = 0.01
I0429 13:49:32.937760 25258 solver.cpp:239] Iteration 1780 (8.9221 iter/s, 2.24162s/20 iters), loss = 1.55664
I0429 13:49:32.942553 25258 solver.cpp:258]     Train net output #0: loss = 1.55664 (* 1 = 1.55664 loss)
I0429 13:49:32.942593 25258 sgd_solver.cpp:112] Iteration 1780, lr = 0.01
I0429 13:49:35.118158 25258 solver.cpp:239] Iteration 1800 (9.19315 iter/s, 2.17553s/20 iters), loss = 1.52222
I0429 13:49:35.122953 25258 solver.cpp:258]     Train net output #0: loss = 1.52222 (* 1 = 1.52222 loss)
I0429 13:49:35.122977 25258 sgd_solver.cpp:112] Iteration 1800, lr = 0.01
I0429 13:49:37.720783 25258 solver.cpp:239] Iteration 1820 (7.69901 iter/s, 2.59774s/20 iters), loss = 1.55601
I0429 13:49:37.726558 25258 solver.cpp:258]     Train net output #0: loss = 1.55601 (* 1 = 1.55601 loss)
I0429 13:49:37.729812 25258 sgd_solver.cpp:112] Iteration 1820, lr = 0.01
I0429 13:49:41.112251 25258 solver.cpp:239] Iteration 1840 (5.90738 iter/s, 3.3856s/20 iters), loss = 1.59901
I0429 13:49:41.117178 25258 solver.cpp:258]     Train net output #0: loss = 1.59901 (* 1 = 1.59901 loss)
I0429 13:49:41.117223 25258 sgd_solver.cpp:112] Iteration 1840, lr = 0.01
I0429 13:49:41.819226 25258 blocking_queue.cpp:49] Waiting for data
I0429 13:49:44.763922 25258 solver.cpp:239] Iteration 1860 (5.48449 iter/s, 3.64665s/20 iters), loss = 1.5687
I0429 13:49:44.768734 25258 solver.cpp:258]     Train net output #0: loss = 1.5687 (* 1 = 1.5687 loss)
I0429 13:49:44.768761 25258 sgd_solver.cpp:112] Iteration 1860, lr = 0.01
I0429 13:49:48.633997 25258 solver.cpp:239] Iteration 1880 (5.17444 iter/s, 3.86515s/20 iters), loss = 1.57773
I0429 13:49:48.638828 25258 solver.cpp:258]     Train net output #0: loss = 1.57773 (* 1 = 1.57773 loss)
I0429 13:49:48.638871 25258 sgd_solver.cpp:112] Iteration 1880, lr = 0.01
I0429 13:49:52.802703 25258 solver.cpp:239] Iteration 1900 (4.80335 iter/s, 4.16376s/20 iters), loss = 1.52535
I0429 13:49:52.807515 25258 solver.cpp:258]     Train net output #0: loss = 1.52535 (* 1 = 1.52535 loss)
I0429 13:49:52.807538 25258 sgd_solver.cpp:112] Iteration 1900, lr = 0.01
I0429 13:49:57.023814 25258 solver.cpp:239] Iteration 1920 (4.74364 iter/s, 4.21618s/20 iters), loss = 1.60628
I0429 13:49:57.029184 25258 solver.cpp:258]     Train net output #0: loss = 1.60628 (* 1 = 1.60628 loss)
I0429 13:49:57.029215 25258 sgd_solver.cpp:112] Iteration 1920, lr = 0.01
I0429 13:50:01.813024 25258 solver.cpp:239] Iteration 1940 (4.18087 iter/s, 4.78369s/20 iters), loss = 1.50643
I0429 13:50:01.817831 25258 solver.cpp:258]     Train net output #0: loss = 1.50643 (* 1 = 1.50643 loss)
I0429 13:50:01.817885 25258 sgd_solver.cpp:112] Iteration 1940, lr = 0.01
I0429 13:50:07.445236 25258 solver.cpp:239] Iteration 1960 (3.55414 iter/s, 5.62724s/20 iters), loss = 1.52128
I0429 13:50:07.451086 25258 solver.cpp:258]     Train net output #0: loss = 1.52128 (* 1 = 1.52128 loss)
I0429 13:50:07.451118 25258 sgd_solver.cpp:112] Iteration 1960, lr = 0.01
I0429 13:50:11.614140 25258 solver.cpp:239] Iteration 1980 (4.8043 iter/s, 4.16294s/20 iters), loss = 1.49294
I0429 13:50:11.619086 25258 solver.cpp:258]     Train net output #0: loss = 1.49294 (* 1 = 1.49294 loss)
I0429 13:50:11.619127 25258 sgd_solver.cpp:112] Iteration 1980, lr = 0.01
I0429 13:50:18.938825 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_2000.caffemodel
I0429 13:51:28.732214 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_2000.solverstate
I0429 13:51:29.066560 25258 solver.cpp:351] Iteration 2000, Testing net (#0)
I0429 13:51:29.600508 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:51:34.183369 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.306875
I0429 13:51:34.183418 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.528359
I0429 13:51:34.183428 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.730078
I0429 13:51:34.183440 25258 solver.cpp:418]     Test net output #3: loss = 1.53209 (* 1 = 1.53209 loss)
I0429 13:51:34.261895 25258 solver.cpp:239] Iteration 2000 (0.242012 iter/s, 82.6404s/20 iters), loss = 1.57222
I0429 13:51:34.262008 25258 solver.cpp:258]     Train net output #0: loss = 1.57222 (* 1 = 1.57222 loss)
I0429 13:51:34.262037 25258 sgd_solver.cpp:112] Iteration 2000, lr = 0.01
I0429 13:51:36.117763 25258 solver.cpp:239] Iteration 2020 (10.7777 iter/s, 1.85569s/20 iters), loss = 1.45238
I0429 13:51:36.117830 25258 solver.cpp:258]     Train net output #0: loss = 1.45238 (* 1 = 1.45238 loss)
I0429 13:51:36.117846 25258 sgd_solver.cpp:112] Iteration 2020, lr = 0.01
I0429 13:51:38.202832 25258 solver.cpp:239] Iteration 2040 (9.59267 iter/s, 2.08492s/20 iters), loss = 1.54035
I0429 13:51:38.207677 25258 solver.cpp:258]     Train net output #0: loss = 1.54035 (* 1 = 1.54035 loss)
I0429 13:51:38.207708 25258 sgd_solver.cpp:112] Iteration 2040, lr = 0.01
I0429 13:51:41.030325 25258 solver.cpp:239] Iteration 2060 (7.08576 iter/s, 2.82256s/20 iters), loss = 1.50386
I0429 13:51:41.035109 25258 solver.cpp:258]     Train net output #0: loss = 1.50386 (* 1 = 1.50386 loss)
I0429 13:51:41.035145 25258 sgd_solver.cpp:112] Iteration 2060, lr = 0.01
I0429 13:51:43.715412 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:51:44.086783 25258 solver.cpp:239] Iteration 2080 (6.55396 iter/s, 3.05159s/20 iters), loss = 1.49823
I0429 13:51:44.091593 25258 solver.cpp:258]     Train net output #0: loss = 1.49823 (* 1 = 1.49823 loss)
I0429 13:51:44.091626 25258 sgd_solver.cpp:112] Iteration 2080, lr = 0.01
I0429 13:51:47.567296 25258 solver.cpp:239] Iteration 2100 (5.75442 iter/s, 3.47559s/20 iters), loss = 1.51549
I0429 13:51:47.572108 25258 solver.cpp:258]     Train net output #0: loss = 1.51549 (* 1 = 1.51549 loss)
I0429 13:51:47.572146 25258 sgd_solver.cpp:112] Iteration 2100, lr = 0.01
I0429 13:51:50.857947 25258 solver.cpp:239] Iteration 2120 (6.0869 iter/s, 3.28574s/20 iters), loss = 1.51192
I0429 13:51:50.862707 25258 solver.cpp:258]     Train net output #0: loss = 1.51192 (* 1 = 1.51192 loss)
I0429 13:51:50.862740 25258 sgd_solver.cpp:112] Iteration 2120, lr = 0.01
I0429 13:51:55.064376 25258 solver.cpp:239] Iteration 2140 (4.76015 iter/s, 4.20155s/20 iters), loss = 1.49583
I0429 13:51:55.069205 25258 solver.cpp:258]     Train net output #0: loss = 1.49583 (* 1 = 1.49583 loss)
I0429 13:51:55.069250 25258 sgd_solver.cpp:112] Iteration 2140, lr = 0.01
I0429 13:51:59.329473 25258 solver.cpp:239] Iteration 2160 (4.69467 iter/s, 4.26015s/20 iters), loss = 1.48703
I0429 13:51:59.334282 25258 solver.cpp:258]     Train net output #0: loss = 1.48703 (* 1 = 1.48703 loss)
I0429 13:51:59.334311 25258 sgd_solver.cpp:112] Iteration 2160, lr = 0.01
I0429 13:52:04.077317 25258 solver.cpp:239] Iteration 2180 (4.21684 iter/s, 4.74289s/20 iters), loss = 1.46209
I0429 13:52:04.082118 25258 solver.cpp:258]     Train net output #0: loss = 1.46209 (* 1 = 1.46209 loss)
I0429 13:52:04.082162 25258 sgd_solver.cpp:112] Iteration 2180, lr = 0.01
I0429 13:52:07.592793 25258 solver.cpp:239] Iteration 2200 (5.69708 iter/s, 3.51057s/20 iters), loss = 1.52228
I0429 13:52:07.597574 25258 solver.cpp:258]     Train net output #0: loss = 1.52228 (* 1 = 1.52228 loss)
I0429 13:52:07.597609 25258 sgd_solver.cpp:112] Iteration 2200, lr = 0.01
I0429 13:52:14.564462 25258 solver.cpp:239] Iteration 2220 (2.87081 iter/s, 6.96668s/20 iters), loss = 1.53493
I0429 13:52:14.569478 25258 solver.cpp:258]     Train net output #0: loss = 1.53493 (* 1 = 1.53493 loss)
I0429 13:52:14.569514 25258 sgd_solver.cpp:112] Iteration 2220, lr = 0.01
I0429 13:52:23.737504 25258 solver.cpp:239] Iteration 2240 (2.18156 iter/s, 9.16775s/20 iters), loss = 1.56508
I0429 13:52:23.743587 25258 solver.cpp:258]     Train net output #0: loss = 1.56508 (* 1 = 1.56508 loss)
I0429 13:52:23.743629 25258 sgd_solver.cpp:112] Iteration 2240, lr = 0.01
I0429 13:52:28.835235 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_2250.caffemodel
I0429 13:53:28.591886 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_2250.solverstate
I0429 13:53:28.937528 25258 solver.cpp:351] Iteration 2250, Testing net (#0)
I0429 13:53:29.625768 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:53:34.177001 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.321094
I0429 13:53:34.177060 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.549531
I0429 13:53:34.177074 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.742422
I0429 13:53:34.177089 25258 solver.cpp:418]     Test net output #3: loss = 1.50247 (* 1 = 1.50247 loss)
I0429 13:53:35.125782 25258 solver.cpp:239] Iteration 2260 (0.28019 iter/s, 71.3801s/20 iters), loss = 1.52856
I0429 13:53:35.125874 25258 solver.cpp:258]     Train net output #0: loss = 1.52856 (* 1 = 1.52856 loss)
I0429 13:53:35.125890 25258 sgd_solver.cpp:112] Iteration 2260, lr = 0.01
I0429 13:53:36.921119 25258 solver.cpp:239] Iteration 2280 (11.141 iter/s, 1.79517s/20 iters), loss = 1.4736
I0429 13:53:36.921195 25258 solver.cpp:258]     Train net output #0: loss = 1.4736 (* 1 = 1.4736 loss)
I0429 13:53:36.921213 25258 sgd_solver.cpp:112] Iteration 2280, lr = 0.01
I0429 13:53:39.006474 25258 solver.cpp:239] Iteration 2300 (9.5914 iter/s, 2.0852s/20 iters), loss = 1.59498
I0429 13:53:39.011644 25258 solver.cpp:258]     Train net output #0: loss = 1.59498 (* 1 = 1.59498 loss)
I0429 13:53:39.011675 25258 sgd_solver.cpp:112] Iteration 2300, lr = 0.01
I0429 13:53:41.393574 25258 solver.cpp:239] Iteration 2320 (8.39681 iter/s, 2.38186s/20 iters), loss = 1.49416
I0429 13:53:41.398429 25258 solver.cpp:258]     Train net output #0: loss = 1.49416 (* 1 = 1.49416 loss)
I0429 13:53:41.399240 25258 sgd_solver.cpp:112] Iteration 2320, lr = 0.01
I0429 13:53:44.384820 25258 solver.cpp:239] Iteration 2340 (6.69726 iter/s, 2.9863s/20 iters), loss = 1.51617
I0429 13:53:44.389645 25258 solver.cpp:258]     Train net output #0: loss = 1.51617 (* 1 = 1.51617 loss)
I0429 13:53:44.389678 25258 sgd_solver.cpp:112] Iteration 2340, lr = 0.01
I0429 13:53:47.587134 25258 solver.cpp:239] Iteration 2360 (6.25509 iter/s, 3.1974s/20 iters), loss = 1.58256
I0429 13:53:47.587211 25258 solver.cpp:258]     Train net output #0: loss = 1.58256 (* 1 = 1.58256 loss)
I0429 13:53:47.587224 25258 sgd_solver.cpp:112] Iteration 2360, lr = 0.01
I0429 13:53:50.721797 25258 solver.cpp:239] Iteration 2380 (6.38067 iter/s, 3.13447s/20 iters), loss = 1.53667
I0429 13:53:50.726688 25258 solver.cpp:258]     Train net output #0: loss = 1.53667 (* 1 = 1.53667 loss)
I0429 13:53:50.726725 25258 sgd_solver.cpp:112] Iteration 2380, lr = 0.01
I0429 13:53:55.085391 25258 solver.cpp:239] Iteration 2400 (4.58865 iter/s, 4.35858s/20 iters), loss = 1.50825
I0429 13:53:55.090210 25258 solver.cpp:258]     Train net output #0: loss = 1.50825 (* 1 = 1.50825 loss)
I0429 13:53:55.090246 25258 sgd_solver.cpp:112] Iteration 2400, lr = 0.01
I0429 13:53:59.284802 25258 solver.cpp:239] Iteration 2420 (4.76818 iter/s, 4.19447s/20 iters), loss = 1.50276
I0429 13:53:59.289623 25258 solver.cpp:258]     Train net output #0: loss = 1.50276 (* 1 = 1.50276 loss)
I0429 13:53:59.289646 25258 sgd_solver.cpp:112] Iteration 2420, lr = 0.01
I0429 13:54:04.846455 25258 solver.cpp:239] Iteration 2440 (3.59928 iter/s, 5.55666s/20 iters), loss = 1.5464
I0429 13:54:04.851644 25258 solver.cpp:258]     Train net output #0: loss = 1.5464 (* 1 = 1.5464 loss)
I0429 13:54:04.851678 25258 sgd_solver.cpp:112] Iteration 2440, lr = 0.01
I0429 13:54:09.413156 25258 solver.cpp:239] Iteration 2460 (4.38464 iter/s, 4.56137s/20 iters), loss = 1.50215
I0429 13:54:09.417966 25258 solver.cpp:258]     Train net output #0: loss = 1.50215 (* 1 = 1.50215 loss)
I0429 13:54:09.417999 25258 sgd_solver.cpp:112] Iteration 2460, lr = 0.01
I0429 13:54:16.690244 25258 solver.cpp:239] Iteration 2480 (2.75025 iter/s, 7.27206s/20 iters), loss = 1.47983
I0429 13:54:16.695211 25258 solver.cpp:258]     Train net output #0: loss = 1.47983 (* 1 = 1.47983 loss)
I0429 13:54:16.695256 25258 sgd_solver.cpp:112] Iteration 2480, lr = 0.01
I0429 13:54:25.731791 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_2500.caffemodel
I0429 13:55:18.797125 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_2500.solverstate
I0429 13:55:19.130352 25258 solver.cpp:351] Iteration 2500, Testing net (#0)
I0429 13:55:19.898938 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:55:24.305256 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.332422
I0429 13:55:24.305323 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.559453
I0429 13:55:24.305332 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.752578
I0429 13:55:24.305346 25258 solver.cpp:418]     Test net output #3: loss = 1.49263 (* 1 = 1.49263 loss)
I0429 13:55:24.379266 25258 solver.cpp:239] Iteration 2500 (0.295499 iter/s, 67.6821s/20 iters), loss = 1.53041
I0429 13:55:24.382910 25258 solver.cpp:258]     Train net output #0: loss = 1.53041 (* 1 = 1.53041 loss)
I0429 13:55:24.382977 25258 sgd_solver.cpp:112] Iteration 2500, lr = 0.01
I0429 13:55:26.084914 25258 solver.cpp:239] Iteration 2520 (11.7509 iter/s, 1.70199s/20 iters), loss = 1.54034
I0429 13:55:26.091297 25258 solver.cpp:258]     Train net output #0: loss = 1.54034 (* 1 = 1.54034 loss)
I0429 13:55:26.091344 25258 sgd_solver.cpp:112] Iteration 2520, lr = 0.01
I0429 13:55:27.966459 25258 solver.cpp:239] Iteration 2540 (10.657 iter/s, 1.8767s/20 iters), loss = 1.41455
I0429 13:55:27.966534 25258 solver.cpp:258]     Train net output #0: loss = 1.41455 (* 1 = 1.41455 loss)
I0429 13:55:27.966550 25258 sgd_solver.cpp:112] Iteration 2540, lr = 0.01
I0429 13:55:29.971591 25258 solver.cpp:239] Iteration 2560 (9.97511 iter/s, 2.00499s/20 iters), loss = 1.50668
I0429 13:55:29.976346 25258 solver.cpp:258]     Train net output #0: loss = 1.50668 (* 1 = 1.50668 loss)
I0429 13:55:29.976368 25258 sgd_solver.cpp:112] Iteration 2560, lr = 0.01
I0429 13:55:32.623159 25258 solver.cpp:239] Iteration 2580 (7.55651 iter/s, 2.64673s/20 iters), loss = 1.45214
I0429 13:55:32.628727 25258 solver.cpp:258]     Train net output #0: loss = 1.45214 (* 1 = 1.45214 loss)
I0429 13:55:32.628768 25258 sgd_solver.cpp:112] Iteration 2580, lr = 0.01
I0429 13:55:36.366173 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:55:36.628942 25258 solver.cpp:239] Iteration 2600 (4.99987 iter/s, 4.0001s/20 iters), loss = 1.4709
I0429 13:55:36.629000 25258 solver.cpp:258]     Train net output #0: loss = 1.4709 (* 1 = 1.4709 loss)
I0429 13:55:36.629015 25258 sgd_solver.cpp:112] Iteration 2600, lr = 0.01
I0429 13:55:37.627276 25258 blocking_queue.cpp:49] Waiting for data
I0429 13:55:39.854405 25258 solver.cpp:239] Iteration 2620 (6.20099 iter/s, 3.22529s/20 iters), loss = 1.5002
I0429 13:55:39.854470 25258 solver.cpp:258]     Train net output #0: loss = 1.5002 (* 1 = 1.5002 loss)
I0429 13:55:39.854481 25258 sgd_solver.cpp:112] Iteration 2620, lr = 0.01
I0429 13:55:43.565917 25258 solver.cpp:239] Iteration 2640 (5.38893 iter/s, 3.71131s/20 iters), loss = 1.47985
I0429 13:55:43.565980 25258 solver.cpp:258]     Train net output #0: loss = 1.47985 (* 1 = 1.47985 loss)
I0429 13:55:43.565992 25258 sgd_solver.cpp:112] Iteration 2640, lr = 0.01
I0429 13:55:47.275017 25258 solver.cpp:239] Iteration 2660 (5.39341 iter/s, 3.70823s/20 iters), loss = 1.47405
I0429 13:55:47.275070 25258 solver.cpp:258]     Train net output #0: loss = 1.47405 (* 1 = 1.47405 loss)
I0429 13:55:47.275081 25258 sgd_solver.cpp:112] Iteration 2660, lr = 0.01
I0429 13:55:51.661080 25258 solver.cpp:239] Iteration 2680 (4.56011 iter/s, 4.38586s/20 iters), loss = 1.53304
I0429 13:55:51.661800 25258 solver.cpp:258]     Train net output #0: loss = 1.53304 (* 1 = 1.53304 loss)
I0429 13:55:51.661819 25258 sgd_solver.cpp:112] Iteration 2680, lr = 0.01
I0429 13:55:55.125623 25258 solver.cpp:239] Iteration 2700 (5.77415 iter/s, 3.46371s/20 iters), loss = 1.43964
I0429 13:55:55.130554 25258 solver.cpp:258]     Train net output #0: loss = 1.43964 (* 1 = 1.43964 loss)
I0429 13:55:55.130604 25258 sgd_solver.cpp:112] Iteration 2700, lr = 0.01
I0429 13:56:01.508608 25258 solver.cpp:239] Iteration 2720 (3.13583 iter/s, 6.37789s/20 iters), loss = 1.40793
I0429 13:56:01.513423 25258 solver.cpp:258]     Train net output #0: loss = 1.40793 (* 1 = 1.40793 loss)
I0429 13:56:01.513464 25258 sgd_solver.cpp:112] Iteration 2720, lr = 0.01
I0429 13:56:05.703299 25258 solver.cpp:239] Iteration 2740 (4.77355 iter/s, 4.18975s/20 iters), loss = 1.43516
I0429 13:56:05.708688 25258 solver.cpp:258]     Train net output #0: loss = 1.43516 (* 1 = 1.43516 loss)
I0429 13:56:05.708757 25258 sgd_solver.cpp:112] Iteration 2740, lr = 0.01
I0429 13:56:08.257992 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_2750.caffemodel
I0429 13:56:39.773074 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_2750.solverstate
I0429 13:56:40.144089 25258 solver.cpp:351] Iteration 2750, Testing net (#0)
I0429 13:56:40.880647 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:56:46.326145 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.342109
I0429 13:56:46.326192 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.581172
I0429 13:56:46.326203 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.763672
I0429 13:56:46.326225 25258 solver.cpp:418]     Test net output #3: loss = 1.48215 (* 1 = 1.48215 loss)
I0429 13:56:48.131994 25258 solver.cpp:239] Iteration 2760 (0.471452 iter/s, 42.4221s/20 iters), loss = 1.48317
I0429 13:56:48.136858 25258 solver.cpp:258]     Train net output #0: loss = 1.48317 (* 1 = 1.48317 loss)
I0429 13:56:48.136900 25258 sgd_solver.cpp:112] Iteration 2760, lr = 0.01
I0429 13:56:53.568131 25258 solver.cpp:239] Iteration 2780 (3.68248 iter/s, 5.43113s/20 iters), loss = 1.48646
I0429 13:56:53.568193 25258 solver.cpp:258]     Train net output #0: loss = 1.48646 (* 1 = 1.48646 loss)
I0429 13:56:53.568205 25258 sgd_solver.cpp:112] Iteration 2780, lr = 0.01
I0429 13:56:58.496063 25258 solver.cpp:239] Iteration 2800 (4.05869 iter/s, 4.9277s/20 iters), loss = 1.42423
I0429 13:56:58.496146 25258 solver.cpp:258]     Train net output #0: loss = 1.42423 (* 1 = 1.42423 loss)
I0429 13:56:58.496163 25258 sgd_solver.cpp:112] Iteration 2800, lr = 0.01
I0429 13:57:03.637754 25258 solver.cpp:239] Iteration 2820 (3.88996 iter/s, 5.14144s/20 iters), loss = 1.62764
I0429 13:57:03.637833 25258 solver.cpp:258]     Train net output #0: loss = 1.62764 (* 1 = 1.62764 loss)
I0429 13:57:03.637852 25258 sgd_solver.cpp:112] Iteration 2820, lr = 0.01
I0429 13:57:08.339854 25258 solver.cpp:239] Iteration 2840 (4.25363 iter/s, 4.70187s/20 iters), loss = 1.48058
I0429 13:57:08.339918 25258 solver.cpp:258]     Train net output #0: loss = 1.48058 (* 1 = 1.48058 loss)
I0429 13:57:08.339941 25258 sgd_solver.cpp:112] Iteration 2840, lr = 0.01
I0429 13:57:13.021404 25258 solver.cpp:239] Iteration 2860 (4.27229 iter/s, 4.68133s/20 iters), loss = 1.47151
I0429 13:57:13.022548 25258 solver.cpp:258]     Train net output #0: loss = 1.47151 (* 1 = 1.47151 loss)
I0429 13:57:13.022562 25258 sgd_solver.cpp:112] Iteration 2860, lr = 0.01
I0429 13:57:18.257856 25258 solver.cpp:239] Iteration 2880 (3.82033 iter/s, 5.23515s/20 iters), loss = 1.53312
I0429 13:57:18.257916 25258 solver.cpp:258]     Train net output #0: loss = 1.53312 (* 1 = 1.53312 loss)
I0429 13:57:18.257930 25258 sgd_solver.cpp:112] Iteration 2880, lr = 0.01
I0429 13:57:23.175129 25258 solver.cpp:239] Iteration 2900 (4.06748 iter/s, 4.91705s/20 iters), loss = 1.47726
I0429 13:57:23.175181 25258 solver.cpp:258]     Train net output #0: loss = 1.47726 (* 1 = 1.47726 loss)
I0429 13:57:23.175192 25258 sgd_solver.cpp:112] Iteration 2900, lr = 0.01
I0429 13:57:28.124702 25258 solver.cpp:239] Iteration 2920 (4.04093 iter/s, 4.94936s/20 iters), loss = 1.43417
I0429 13:57:28.124760 25258 solver.cpp:258]     Train net output #0: loss = 1.43417 (* 1 = 1.43417 loss)
I0429 13:57:28.124771 25258 sgd_solver.cpp:112] Iteration 2920, lr = 0.01
I0429 13:57:33.486928 25258 solver.cpp:239] Iteration 2940 (3.72996 iter/s, 5.36199s/20 iters), loss = 1.44039
I0429 13:57:33.491999 25258 solver.cpp:258]     Train net output #0: loss = 1.44039 (* 1 = 1.44039 loss)
I0429 13:57:33.492043 25258 sgd_solver.cpp:112] Iteration 2940, lr = 0.01
I0429 13:57:36.724164 25258 solver.cpp:239] Iteration 2960 (6.18801 iter/s, 3.23206s/20 iters), loss = 1.48844
I0429 13:57:36.729604 25258 solver.cpp:258]     Train net output #0: loss = 1.48844 (* 1 = 1.48844 loss)
I0429 13:57:36.729652 25258 sgd_solver.cpp:112] Iteration 2960, lr = 0.01
I0429 13:57:43.001870 25258 solver.cpp:239] Iteration 2980 (3.18873 iter/s, 6.2721s/20 iters), loss = 1.44663
I0429 13:57:43.001938 25258 solver.cpp:258]     Train net output #0: loss = 1.44663 (* 1 = 1.44663 loss)
I0429 13:57:43.001955 25258 sgd_solver.cpp:112] Iteration 2980, lr = 0.01
I0429 13:57:47.940227 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_3000.caffemodel
I0429 13:58:25.135665 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_3000.solverstate
I0429 13:58:25.454141 25258 solver.cpp:351] Iteration 3000, Testing net (#0)
I0429 13:58:26.428675 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:58:32.024076 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.3325
I0429 13:58:32.024122 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.566094
I0429 13:58:32.024132 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.756641
I0429 13:58:32.024142 25258 solver.cpp:418]     Test net output #3: loss = 1.48399 (* 1 = 1.48399 loss)
I0429 13:58:32.106813 25258 solver.cpp:239] Iteration 3000 (0.407304 iter/s, 49.1034s/20 iters), loss = 1.49206
I0429 13:58:32.110294 25258 solver.cpp:258]     Train net output #0: loss = 1.49206 (* 1 = 1.49206 loss)
I0429 13:58:32.110327 25258 sgd_solver.cpp:112] Iteration 3000, lr = 0.01
I0429 13:58:37.329260 25258 solver.cpp:239] Iteration 3020 (3.83229 iter/s, 5.21881s/20 iters), loss = 1.46868
I0429 13:58:37.329336 25258 solver.cpp:258]     Train net output #0: loss = 1.46868 (* 1 = 1.46868 loss)
I0429 13:58:37.329350 25258 sgd_solver.cpp:112] Iteration 3020, lr = 0.01
I0429 13:58:43.285243 25258 solver.cpp:239] Iteration 3040 (3.35812 iter/s, 5.95571s/20 iters), loss = 1.48148
I0429 13:58:43.290169 25258 solver.cpp:258]     Train net output #0: loss = 1.48148 (* 1 = 1.48148 loss)
I0429 13:58:43.290215 25258 sgd_solver.cpp:112] Iteration 3040, lr = 0.01
I0429 13:58:48.136792 25258 solver.cpp:239] Iteration 3060 (4.1267 iter/s, 4.84649s/20 iters), loss = 1.40746
I0429 13:58:48.136847 25258 solver.cpp:258]     Train net output #0: loss = 1.40746 (* 1 = 1.40746 loss)
I0429 13:58:48.136857 25258 sgd_solver.cpp:112] Iteration 3060, lr = 0.01
I0429 13:58:53.554109 25258 solver.cpp:239] Iteration 3080 (3.69202 iter/s, 5.41708s/20 iters), loss = 1.46517
I0429 13:58:53.563457 25258 solver.cpp:258]     Train net output #0: loss = 1.46517 (* 1 = 1.46517 loss)
I0429 13:58:53.563500 25258 sgd_solver.cpp:112] Iteration 3080, lr = 0.01
I0429 13:58:58.369015 25258 solver.cpp:239] Iteration 3100 (4.16196 iter/s, 4.80543s/20 iters), loss = 1.44601
I0429 13:58:58.369302 25258 solver.cpp:258]     Train net output #0: loss = 1.44601 (* 1 = 1.44601 loss)
I0429 13:58:58.369320 25258 sgd_solver.cpp:112] Iteration 3100, lr = 0.01
I0429 13:59:02.379611 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 13:59:03.145479 25258 solver.cpp:239] Iteration 3120 (4.18758 iter/s, 4.77602s/20 iters), loss = 1.45171
I0429 13:59:03.145545 25258 solver.cpp:258]     Train net output #0: loss = 1.45171 (* 1 = 1.45171 loss)
I0429 13:59:03.145557 25258 sgd_solver.cpp:112] Iteration 3120, lr = 0.01
I0429 13:59:08.391407 25258 solver.cpp:239] Iteration 3140 (3.81265 iter/s, 5.2457s/20 iters), loss = 1.48036
I0429 13:59:08.391474 25258 solver.cpp:258]     Train net output #0: loss = 1.48036 (* 1 = 1.48036 loss)
I0429 13:59:08.391487 25258 sgd_solver.cpp:112] Iteration 3140, lr = 0.01
I0429 13:59:13.883139 25258 solver.cpp:239] Iteration 3160 (3.642 iter/s, 5.49148s/20 iters), loss = 1.47095
I0429 13:59:13.888226 25258 solver.cpp:258]     Train net output #0: loss = 1.47095 (* 1 = 1.47095 loss)
I0429 13:59:13.888293 25258 sgd_solver.cpp:112] Iteration 3160, lr = 0.01
I0429 13:59:18.915324 25258 solver.cpp:239] Iteration 3180 (3.97852 iter/s, 5.02699s/20 iters), loss = 1.46884
I0429 13:59:18.915383 25258 solver.cpp:258]     Train net output #0: loss = 1.46884 (* 1 = 1.46884 loss)
I0429 13:59:18.915395 25258 sgd_solver.cpp:112] Iteration 3180, lr = 0.01
I0429 13:59:24.717773 25258 solver.cpp:239] Iteration 3200 (3.44698 iter/s, 5.80219s/20 iters), loss = 1.49192
I0429 13:59:24.729782 25258 solver.cpp:258]     Train net output #0: loss = 1.49192 (* 1 = 1.49192 loss)
I0429 13:59:24.729823 25258 sgd_solver.cpp:112] Iteration 3200, lr = 0.01
I0429 13:59:30.396736 25258 solver.cpp:239] Iteration 3220 (3.52934 iter/s, 5.66678s/20 iters), loss = 1.39431
I0429 13:59:30.401659 25258 solver.cpp:258]     Train net output #0: loss = 1.39431 (* 1 = 1.39431 loss)
I0429 13:59:30.401698 25258 sgd_solver.cpp:112] Iteration 3220, lr = 0.01
I0429 13:59:35.734673 25258 solver.cpp:239] Iteration 3240 (3.75033 iter/s, 5.33287s/20 iters), loss = 1.41205
I0429 13:59:35.734757 25258 solver.cpp:258]     Train net output #0: loss = 1.41205 (* 1 = 1.41205 loss)
I0429 13:59:35.734776 25258 sgd_solver.cpp:112] Iteration 3240, lr = 0.01
I0429 13:59:38.425139 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_3250.caffemodel
I0429 13:59:58.971951 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_3250.solverstate
I0429 13:59:59.280164 25258 solver.cpp:351] Iteration 3250, Testing net (#0)
I0429 14:00:00.938959 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:00:09.243091 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.359141
I0429 14:00:09.243141 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.597656
I0429 14:00:09.243152 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.77375
I0429 14:00:09.243165 25258 solver.cpp:418]     Test net output #3: loss = 1.44355 (* 1 = 1.44355 loss)
I0429 14:00:10.811722 25258 solver.cpp:239] Iteration 3260 (0.570192 iter/s, 35.0759s/20 iters), loss = 1.4479
I0429 14:00:10.816540 25258 solver.cpp:258]     Train net output #0: loss = 1.4479 (* 1 = 1.4479 loss)
I0429 14:00:10.816581 25258 sgd_solver.cpp:112] Iteration 3260, lr = 0.01
I0429 14:00:16.079252 25258 solver.cpp:239] Iteration 3280 (3.80043 iter/s, 5.26256s/20 iters), loss = 1.46184
I0429 14:00:16.084067 25258 solver.cpp:258]     Train net output #0: loss = 1.46184 (* 1 = 1.46184 loss)
I0429 14:00:16.084101 25258 sgd_solver.cpp:112] Iteration 3280, lr = 0.01
I0429 14:00:21.334048 25258 solver.cpp:239] Iteration 3300 (3.80965 iter/s, 5.24983s/20 iters), loss = 1.47275
I0429 14:00:21.338850 25258 solver.cpp:258]     Train net output #0: loss = 1.47275 (* 1 = 1.47275 loss)
I0429 14:00:21.338877 25258 sgd_solver.cpp:112] Iteration 3300, lr = 0.01
I0429 14:00:27.056643 25258 solver.cpp:239] Iteration 3320 (3.49795 iter/s, 5.71763s/20 iters), loss = 1.43446
I0429 14:00:27.061450 25258 solver.cpp:258]     Train net output #0: loss = 1.43446 (* 1 = 1.43446 loss)
I0429 14:00:27.061473 25258 sgd_solver.cpp:112] Iteration 3320, lr = 0.01
I0429 14:00:32.397390 25258 solver.cpp:239] Iteration 3340 (3.74828 iter/s, 5.33578s/20 iters), loss = 1.48716
I0429 14:00:32.402308 25258 solver.cpp:258]     Train net output #0: loss = 1.48716 (* 1 = 1.48716 loss)
I0429 14:00:32.402340 25258 sgd_solver.cpp:112] Iteration 3340, lr = 0.01
I0429 14:00:37.887095 25258 solver.cpp:239] Iteration 3360 (3.64655 iter/s, 5.48463s/20 iters), loss = 1.40973
I0429 14:00:37.891901 25258 solver.cpp:258]     Train net output #0: loss = 1.40973 (* 1 = 1.40973 loss)
I0429 14:00:37.891932 25258 sgd_solver.cpp:112] Iteration 3360, lr = 0.01
I0429 14:00:43.371479 25258 solver.cpp:239] Iteration 3380 (3.65002 iter/s, 5.47941s/20 iters), loss = 1.42931
I0429 14:00:43.376278 25258 solver.cpp:258]     Train net output #0: loss = 1.42931 (* 1 = 1.42931 loss)
I0429 14:00:43.376305 25258 sgd_solver.cpp:112] Iteration 3380, lr = 0.01
I0429 14:00:46.548226 25258 solver.cpp:239] Iteration 3400 (6.30738 iter/s, 3.17089s/20 iters), loss = 1.47616
I0429 14:00:46.552115 25258 solver.cpp:258]     Train net output #0: loss = 1.47616 (* 1 = 1.47616 loss)
I0429 14:00:46.552163 25258 sgd_solver.cpp:112] Iteration 3400, lr = 0.01
I0429 14:00:52.645647 25258 solver.cpp:239] Iteration 3420 (3.28226 iter/s, 6.09336s/20 iters), loss = 1.4515
I0429 14:00:52.650508 25258 solver.cpp:258]     Train net output #0: loss = 1.4515 (* 1 = 1.4515 loss)
I0429 14:00:52.650537 25258 sgd_solver.cpp:112] Iteration 3420, lr = 0.01
I0429 14:00:59.011919 25258 solver.cpp:239] Iteration 3440 (3.14405 iter/s, 6.36123s/20 iters), loss = 1.41313
I0429 14:00:59.017885 25258 solver.cpp:258]     Train net output #0: loss = 1.41313 (* 1 = 1.41313 loss)
I0429 14:00:59.017938 25258 sgd_solver.cpp:112] Iteration 3440, lr = 0.01
I0429 14:01:03.421881 25258 solver.cpp:239] Iteration 3460 (4.54143 iter/s, 4.40389s/20 iters), loss = 1.45579
I0429 14:01:03.426707 25258 solver.cpp:258]     Train net output #0: loss = 1.45579 (* 1 = 1.45579 loss)
I0429 14:01:03.426728 25258 sgd_solver.cpp:112] Iteration 3460, lr = 0.01
I0429 14:01:08.956980 25258 solver.cpp:239] Iteration 3480 (3.61657 iter/s, 5.5301s/20 iters), loss = 1.53767
I0429 14:01:08.962007 25258 solver.cpp:258]     Train net output #0: loss = 1.53767 (* 1 = 1.53767 loss)
I0429 14:01:08.962035 25258 sgd_solver.cpp:112] Iteration 3480, lr = 0.01
I0429 14:01:14.719131 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_3500.caffemodel
I0429 14:02:11.469051 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_3500.solverstate
I0429 14:02:11.831243 25258 solver.cpp:351] Iteration 3500, Testing net (#0)
I0429 14:02:12.821357 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:02:14.319672 25258 blocking_queue.cpp:49] Waiting for data
I0429 14:02:17.443970 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.357109
I0429 14:02:17.444022 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.600234
I0429 14:02:17.444038 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.78
I0429 14:02:17.444052 25258 solver.cpp:418]     Test net output #3: loss = 1.43743 (* 1 = 1.43743 loss)
I0429 14:02:17.559041 25258 solver.cpp:239] Iteration 3500 (0.291566 iter/s, 68.595s/20 iters), loss = 1.40956
I0429 14:02:17.559121 25258 solver.cpp:258]     Train net output #0: loss = 1.40956 (* 1 = 1.40956 loss)
I0429 14:02:17.559139 25258 sgd_solver.cpp:112] Iteration 3500, lr = 0.01
I0429 14:02:20.499886 25258 solver.cpp:239] Iteration 3520 (6.80119 iter/s, 2.94066s/20 iters), loss = 1.45263
I0429 14:02:20.499958 25258 solver.cpp:258]     Train net output #0: loss = 1.45263 (* 1 = 1.45263 loss)
I0429 14:02:20.499987 25258 sgd_solver.cpp:112] Iteration 3520, lr = 0.01
I0429 14:02:23.647570 25258 solver.cpp:239] Iteration 3540 (6.35426 iter/s, 3.14749s/20 iters), loss = 1.388
I0429 14:02:23.652415 25258 solver.cpp:258]     Train net output #0: loss = 1.388 (* 1 = 1.388 loss)
I0429 14:02:23.652458 25258 sgd_solver.cpp:112] Iteration 3540, lr = 0.01
I0429 14:02:28.037509 25258 solver.cpp:239] Iteration 3560 (4.56103 iter/s, 4.38497s/20 iters), loss = 1.41084
I0429 14:02:28.042291 25258 solver.cpp:258]     Train net output #0: loss = 1.41084 (* 1 = 1.41084 loss)
I0429 14:02:28.042325 25258 sgd_solver.cpp:112] Iteration 3560, lr = 0.01
I0429 14:02:32.504936 25258 solver.cpp:239] Iteration 3580 (4.48179 iter/s, 4.4625s/20 iters), loss = 1.37655
I0429 14:02:32.510025 25258 solver.cpp:258]     Train net output #0: loss = 1.37655 (* 1 = 1.37655 loss)
I0429 14:02:32.510071 25258 sgd_solver.cpp:112] Iteration 3580, lr = 0.01
I0429 14:02:37.583777 25258 solver.cpp:239] Iteration 3600 (3.94196 iter/s, 5.07362s/20 iters), loss = 1.35618
I0429 14:02:37.588722 25258 solver.cpp:258]     Train net output #0: loss = 1.35618 (* 1 = 1.35618 loss)
I0429 14:02:37.588765 25258 sgd_solver.cpp:112] Iteration 3600, lr = 0.01
I0429 14:02:42.306800 25258 solver.cpp:239] Iteration 3620 (4.23914 iter/s, 4.71794s/20 iters), loss = 1.41984
I0429 14:02:42.313005 25258 solver.cpp:258]     Train net output #0: loss = 1.41984 (* 1 = 1.41984 loss)
I0429 14:02:42.313058 25258 sgd_solver.cpp:112] Iteration 3620, lr = 0.01
I0429 14:02:46.346320 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:02:47.306988 25258 solver.cpp:239] Iteration 3640 (4.00493 iter/s, 4.99384s/20 iters), loss = 1.39801
I0429 14:02:47.311807 25258 solver.cpp:258]     Train net output #0: loss = 1.39801 (* 1 = 1.39801 loss)
I0429 14:02:47.311842 25258 sgd_solver.cpp:112] Iteration 3640, lr = 0.01
I0429 14:02:52.671231 25258 solver.cpp:239] Iteration 3660 (3.73187 iter/s, 5.35925s/20 iters), loss = 1.43942
I0429 14:02:52.676276 25258 solver.cpp:258]     Train net output #0: loss = 1.43942 (* 1 = 1.43942 loss)
I0429 14:02:52.676334 25258 sgd_solver.cpp:112] Iteration 3660, lr = 0.01
I0429 14:02:58.813774 25258 solver.cpp:239] Iteration 3680 (3.25876 iter/s, 6.1373s/20 iters), loss = 1.46086
I0429 14:02:58.818598 25258 solver.cpp:258]     Train net output #0: loss = 1.46086 (* 1 = 1.46086 loss)
I0429 14:02:58.818644 25258 sgd_solver.cpp:112] Iteration 3680, lr = 0.01
I0429 14:03:02.659565 25258 solver.cpp:239] Iteration 3700 (5.20716 iter/s, 3.84087s/20 iters), loss = 1.42786
I0429 14:03:02.664381 25258 solver.cpp:258]     Train net output #0: loss = 1.42786 (* 1 = 1.42786 loss)
I0429 14:03:02.664417 25258 sgd_solver.cpp:112] Iteration 3700, lr = 0.01
I0429 14:03:08.346472 25258 solver.cpp:239] Iteration 3720 (3.51996 iter/s, 5.68189s/20 iters), loss = 1.51634
I0429 14:03:08.351877 25258 solver.cpp:258]     Train net output #0: loss = 1.51634 (* 1 = 1.51634 loss)
I0429 14:03:08.351904 25258 sgd_solver.cpp:112] Iteration 3720, lr = 0.01
I0429 14:03:13.980348 25258 solver.cpp:239] Iteration 3740 (3.55347 iter/s, 5.6283s/20 iters), loss = 1.35895
I0429 14:03:13.985204 25258 solver.cpp:258]     Train net output #0: loss = 1.35895 (* 1 = 1.35895 loss)
I0429 14:03:13.985237 25258 sgd_solver.cpp:112] Iteration 3740, lr = 0.01
I0429 14:03:16.221410 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_3750.caffemodel
I0429 14:03:44.189456 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_3750.solverstate
I0429 14:03:44.532557 25258 solver.cpp:351] Iteration 3750, Testing net (#0)
I0429 14:03:45.794152 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:03:53.308696 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.373516
I0429 14:03:53.308761 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.620781
I0429 14:03:53.308779 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.798203
I0429 14:03:53.308799 25258 solver.cpp:418]     Test net output #3: loss = 1.41069 (* 1 = 1.41069 loss)
I0429 14:03:56.318367 25258 solver.cpp:239] Iteration 3760 (0.472456 iter/s, 42.3319s/20 iters), loss = 1.42028
I0429 14:03:56.323128 25258 solver.cpp:258]     Train net output #0: loss = 1.42028 (* 1 = 1.42028 loss)
I0429 14:03:56.323159 25258 sgd_solver.cpp:112] Iteration 3760, lr = 0.01
I0429 14:04:00.481446 25258 solver.cpp:239] Iteration 3780 (4.80978 iter/s, 4.15819s/20 iters), loss = 1.39806
I0429 14:04:00.486271 25258 solver.cpp:258]     Train net output #0: loss = 1.39806 (* 1 = 1.39806 loss)
I0429 14:04:00.486304 25258 sgd_solver.cpp:112] Iteration 3780, lr = 0.01
I0429 14:04:05.583638 25258 solver.cpp:239] Iteration 3800 (3.92522 iter/s, 5.09526s/20 iters), loss = 1.35132
I0429 14:04:05.583715 25258 solver.cpp:258]     Train net output #0: loss = 1.35132 (* 1 = 1.35132 loss)
I0429 14:04:05.583734 25258 sgd_solver.cpp:112] Iteration 3800, lr = 0.01
I0429 14:04:09.823290 25258 solver.cpp:239] Iteration 3820 (4.71769 iter/s, 4.23937s/20 iters), loss = 1.45614
I0429 14:04:09.829387 25258 solver.cpp:258]     Train net output #0: loss = 1.45614 (* 1 = 1.45614 loss)
I0429 14:04:09.829432 25258 sgd_solver.cpp:112] Iteration 3820, lr = 0.01
I0429 14:04:15.963217 25258 solver.cpp:239] Iteration 3840 (3.26069 iter/s, 6.13367s/20 iters), loss = 1.41115
I0429 14:04:15.968027 25258 solver.cpp:258]     Train net output #0: loss = 1.41115 (* 1 = 1.41115 loss)
I0429 14:04:15.968050 25258 sgd_solver.cpp:112] Iteration 3840, lr = 0.01
I0429 14:04:21.822603 25258 solver.cpp:239] Iteration 3860 (3.41624 iter/s, 5.85439s/20 iters), loss = 1.44004
I0429 14:04:21.827422 25258 solver.cpp:258]     Train net output #0: loss = 1.44004 (* 1 = 1.44004 loss)
I0429 14:04:21.827458 25258 sgd_solver.cpp:112] Iteration 3860, lr = 0.01
I0429 14:04:27.110900 25258 solver.cpp:239] Iteration 3880 (3.7855 iter/s, 5.28332s/20 iters), loss = 1.34701
I0429 14:04:27.115802 25258 solver.cpp:258]     Train net output #0: loss = 1.34701 (* 1 = 1.34701 loss)
I0429 14:04:27.115836 25258 sgd_solver.cpp:112] Iteration 3880, lr = 0.01
I0429 14:04:32.560415 25258 solver.cpp:239] Iteration 3900 (3.67346 iter/s, 5.44446s/20 iters), loss = 1.40572
I0429 14:04:32.565582 25258 solver.cpp:258]     Train net output #0: loss = 1.40572 (* 1 = 1.40572 loss)
I0429 14:04:32.565634 25258 sgd_solver.cpp:112] Iteration 3900, lr = 0.01
I0429 14:04:37.608225 25258 solver.cpp:239] Iteration 3920 (3.96626 iter/s, 5.04253s/20 iters), loss = 1.46655
I0429 14:04:37.608310 25258 solver.cpp:258]     Train net output #0: loss = 1.46655 (* 1 = 1.46655 loss)
I0429 14:04:37.608325 25258 sgd_solver.cpp:112] Iteration 3920, lr = 0.01
I0429 14:04:44.085746 25258 solver.cpp:239] Iteration 3940 (3.08774 iter/s, 6.47723s/20 iters), loss = 1.4446
I0429 14:04:44.090693 25258 solver.cpp:258]     Train net output #0: loss = 1.4446 (* 1 = 1.4446 loss)
I0429 14:04:44.090765 25258 sgd_solver.cpp:112] Iteration 3940, lr = 0.01
I0429 14:04:48.603304 25258 solver.cpp:239] Iteration 3960 (4.43211 iter/s, 4.51252s/20 iters), loss = 1.34258
I0429 14:04:48.608199 25258 solver.cpp:258]     Train net output #0: loss = 1.34258 (* 1 = 1.34258 loss)
I0429 14:04:48.608224 25258 sgd_solver.cpp:112] Iteration 3960, lr = 0.01
I0429 14:04:54.697849 25258 solver.cpp:239] Iteration 3980 (3.28436 iter/s, 6.08947s/20 iters), loss = 1.41465
I0429 14:04:54.697926 25258 solver.cpp:258]     Train net output #0: loss = 1.41465 (* 1 = 1.41465 loss)
I0429 14:04:54.697942 25258 sgd_solver.cpp:112] Iteration 3980, lr = 0.01
I0429 14:04:58.963296 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_4000.caffemodel
I0429 14:05:21.114204 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_4000.solverstate
I0429 14:05:21.566586 25258 solver.cpp:351] Iteration 4000, Testing net (#0)
I0429 14:05:22.978651 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:05:31.266506 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.367813
I0429 14:05:31.266561 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.614375
I0429 14:05:31.266588 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.792031
I0429 14:05:31.266604 25258 solver.cpp:418]     Test net output #3: loss = 1.42131 (* 1 = 1.42131 loss)
I0429 14:05:31.561607 25258 solver.cpp:239] Iteration 4000 (0.542555 iter/s, 36.8626s/20 iters), loss = 1.50949
I0429 14:05:31.561664 25258 solver.cpp:258]     Train net output #0: loss = 1.50949 (* 1 = 1.50949 loss)
I0429 14:05:31.561677 25258 sgd_solver.cpp:112] Iteration 4000, lr = 0.01
I0429 14:05:41.310824 25258 solver.cpp:239] Iteration 4020 (2.05202 iter/s, 9.7465s/20 iters), loss = 1.32781
I0429 14:05:41.315735 25258 solver.cpp:258]     Train net output #0: loss = 1.32781 (* 1 = 1.32781 loss)
I0429 14:05:41.315791 25258 sgd_solver.cpp:112] Iteration 4020, lr = 0.01
I0429 14:05:52.987545 25258 solver.cpp:239] Iteration 4040 (1.71358 iter/s, 11.6715s/20 iters), loss = 1.42694
I0429 14:05:52.994917 25258 solver.cpp:258]     Train net output #0: loss = 1.42694 (* 1 = 1.42694 loss)
I0429 14:05:52.994997 25258 sgd_solver.cpp:112] Iteration 4040, lr = 0.01
I0429 14:05:58.318742 25258 solver.cpp:239] Iteration 4060 (3.75677 iter/s, 5.32372s/20 iters), loss = 1.33057
I0429 14:05:58.324965 25258 solver.cpp:258]     Train net output #0: loss = 1.33057 (* 1 = 1.33057 loss)
I0429 14:05:58.325011 25258 sgd_solver.cpp:112] Iteration 4060, lr = 0.01
I0429 14:06:03.857224 25258 solver.cpp:239] Iteration 4080 (3.61527 iter/s, 5.5321s/20 iters), loss = 1.34826
I0429 14:06:03.862730 25258 solver.cpp:258]     Train net output #0: loss = 1.34826 (* 1 = 1.34826 loss)
I0429 14:06:03.862774 25258 sgd_solver.cpp:112] Iteration 4080, lr = 0.01
I0429 14:06:10.181942 25258 solver.cpp:239] Iteration 4100 (3.16504 iter/s, 6.31905s/20 iters), loss = 1.36597
I0429 14:06:10.182015 25258 solver.cpp:258]     Train net output #0: loss = 1.36597 (* 1 = 1.36597 loss)
I0429 14:06:10.182029 25258 sgd_solver.cpp:112] Iteration 4100, lr = 0.01
I0429 14:06:16.276974 25258 solver.cpp:239] Iteration 4120 (3.2815 iter/s, 6.09477s/20 iters), loss = 1.34533
I0429 14:06:16.282188 25258 solver.cpp:258]     Train net output #0: loss = 1.34533 (* 1 = 1.34533 loss)
I0429 14:06:16.282248 25258 sgd_solver.cpp:112] Iteration 4120, lr = 0.01
I0429 14:06:21.522230 25258 solver.cpp:239] Iteration 4140 (3.81688 iter/s, 5.23989s/20 iters), loss = 1.39997
I0429 14:06:21.522327 25258 solver.cpp:258]     Train net output #0: loss = 1.39997 (* 1 = 1.39997 loss)
I0429 14:06:21.522348 25258 sgd_solver.cpp:112] Iteration 4140, lr = 0.01
I0429 14:06:26.663209 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:06:27.770681 25258 solver.cpp:239] Iteration 4160 (3.20094 iter/s, 6.24816s/20 iters), loss = 1.41093
I0429 14:06:27.776942 25258 solver.cpp:258]     Train net output #0: loss = 1.41093 (* 1 = 1.41093 loss)
I0429 14:06:27.776990 25258 sgd_solver.cpp:112] Iteration 4160, lr = 0.01
I0429 14:06:32.667310 25258 solver.cpp:239] Iteration 4180 (4.08978 iter/s, 4.89023s/20 iters), loss = 1.33049
I0429 14:06:32.673807 25258 solver.cpp:258]     Train net output #0: loss = 1.33049 (* 1 = 1.33049 loss)
I0429 14:06:32.673868 25258 sgd_solver.cpp:112] Iteration 4180, lr = 0.01
I0429 14:06:38.295405 25258 solver.cpp:239] Iteration 4200 (3.55776 iter/s, 5.62152s/20 iters), loss = 1.37189
I0429 14:06:38.295523 25258 solver.cpp:258]     Train net output #0: loss = 1.37189 (* 1 = 1.37189 loss)
I0429 14:06:38.295543 25258 sgd_solver.cpp:112] Iteration 4200, lr = 0.01
I0429 14:06:43.700189 25258 solver.cpp:239] Iteration 4220 (3.70065 iter/s, 5.40446s/20 iters), loss = 1.39012
I0429 14:06:43.700403 25258 solver.cpp:258]     Train net output #0: loss = 1.39012 (* 1 = 1.39012 loss)
I0429 14:06:43.700423 25258 sgd_solver.cpp:112] Iteration 4220, lr = 0.01
I0429 14:06:49.352051 25258 solver.cpp:239] Iteration 4240 (3.53891 iter/s, 5.65146s/20 iters), loss = 1.48063
I0429 14:06:49.357800 25258 solver.cpp:258]     Train net output #0: loss = 1.48063 (* 1 = 1.48063 loss)
I0429 14:06:49.357859 25258 sgd_solver.cpp:112] Iteration 4240, lr = 0.01
I0429 14:06:52.243472 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_4250.caffemodel
I0429 14:07:33.080745 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_4250.solverstate
I0429 14:07:33.530825 25258 solver.cpp:351] Iteration 4250, Testing net (#0)
I0429 14:07:35.357273 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:07:43.183189 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.379609
I0429 14:07:43.183231 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.629453
I0429 14:07:43.183238 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.803984
I0429 14:07:43.183248 25258 solver.cpp:418]     Test net output #3: loss = 1.39224 (* 1 = 1.39224 loss)
I0429 14:07:44.411805 25258 solver.cpp:239] Iteration 4260 (0.363289 iter/s, 55.0525s/20 iters), loss = 1.32333
I0429 14:07:44.411886 25258 solver.cpp:258]     Train net output #0: loss = 1.32333 (* 1 = 1.32333 loss)
I0429 14:07:44.411900 25258 sgd_solver.cpp:112] Iteration 4260, lr = 0.01
I0429 14:07:48.782665 25258 solver.cpp:239] Iteration 4280 (4.57599 iter/s, 4.37064s/20 iters), loss = 1.31933
I0429 14:07:48.787540 25258 solver.cpp:258]     Train net output #0: loss = 1.31933 (* 1 = 1.31933 loss)
I0429 14:07:48.787595 25258 sgd_solver.cpp:112] Iteration 4280, lr = 0.01
I0429 14:07:53.140749 25258 solver.cpp:239] Iteration 4300 (4.59445 iter/s, 4.35308s/20 iters), loss = 1.36712
I0429 14:07:53.146752 25258 solver.cpp:258]     Train net output #0: loss = 1.36712 (* 1 = 1.36712 loss)
I0429 14:07:53.146811 25258 sgd_solver.cpp:112] Iteration 4300, lr = 0.01
I0429 14:07:56.251425 25258 solver.cpp:239] Iteration 4320 (6.44311 iter/s, 3.10409s/20 iters), loss = 1.43119
I0429 14:07:56.251505 25258 solver.cpp:258]     Train net output #0: loss = 1.43119 (* 1 = 1.43119 loss)
I0429 14:07:56.251524 25258 sgd_solver.cpp:112] Iteration 4320, lr = 0.01
I0429 14:08:04.443083 25258 solver.cpp:239] Iteration 4340 (2.44197 iter/s, 8.19012s/20 iters), loss = 1.44403
I0429 14:08:04.447468 25258 solver.cpp:258]     Train net output #0: loss = 1.44403 (* 1 = 1.44403 loss)
I0429 14:08:04.447510 25258 sgd_solver.cpp:112] Iteration 4340, lr = 0.01
I0429 14:08:18.076766 25258 solver.cpp:239] Iteration 4360 (1.46747 iter/s, 13.6289s/20 iters), loss = 1.40642
I0429 14:08:18.083061 25258 solver.cpp:258]     Train net output #0: loss = 1.40642 (* 1 = 1.40642 loss)
I0429 14:08:18.083174 25258 sgd_solver.cpp:112] Iteration 4360, lr = 0.01
I0429 14:08:30.186880 25258 solver.cpp:239] Iteration 4380 (1.65241 iter/s, 12.1035s/20 iters), loss = 1.47785
I0429 14:08:30.192106 25258 solver.cpp:258]     Train net output #0: loss = 1.47785 (* 1 = 1.47785 loss)
I0429 14:08:30.192142 25258 sgd_solver.cpp:112] Iteration 4380, lr = 0.01
I0429 14:08:39.576534 25258 solver.cpp:239] Iteration 4400 (2.13125 iter/s, 9.38418s/20 iters), loss = 1.29627
I0429 14:08:39.581331 25258 solver.cpp:258]     Train net output #0: loss = 1.29627 (* 1 = 1.29627 loss)
I0429 14:08:39.581353 25258 sgd_solver.cpp:112] Iteration 4400, lr = 0.01
I0429 14:08:41.083756 25258 blocking_queue.cpp:49] Waiting for data
I0429 14:08:45.031201 25258 solver.cpp:239] Iteration 4420 (3.66992 iter/s, 5.44971s/20 iters), loss = 1.32299
I0429 14:08:45.036038 25258 solver.cpp:258]     Train net output #0: loss = 1.32299 (* 1 = 1.32299 loss)
I0429 14:08:45.036073 25258 sgd_solver.cpp:112] Iteration 4420, lr = 0.01
I0429 14:08:51.166779 25258 solver.cpp:239] Iteration 4440 (3.26234 iter/s, 6.13057s/20 iters), loss = 1.4574
I0429 14:08:51.172336 25258 solver.cpp:258]     Train net output #0: loss = 1.4574 (* 1 = 1.4574 loss)
I0429 14:08:51.172394 25258 sgd_solver.cpp:112] Iteration 4440, lr = 0.01
I0429 14:08:57.053398 25258 solver.cpp:239] Iteration 4460 (3.40083 iter/s, 5.88092s/20 iters), loss = 1.40801
I0429 14:08:57.058853 25258 solver.cpp:258]     Train net output #0: loss = 1.40801 (* 1 = 1.40801 loss)
I0429 14:08:57.058899 25258 sgd_solver.cpp:112] Iteration 4460, lr = 0.01
I0429 14:09:03.393427 25258 solver.cpp:239] Iteration 4480 (3.15735 iter/s, 6.33442s/20 iters), loss = 1.33722
I0429 14:09:03.393510 25258 solver.cpp:258]     Train net output #0: loss = 1.33722 (* 1 = 1.33722 loss)
I0429 14:09:03.393523 25258 sgd_solver.cpp:112] Iteration 4480, lr = 0.01
I0429 14:09:08.539777 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_4500.caffemodel
I0429 14:09:22.424993 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_4500.solverstate
I0429 14:09:22.814404 25258 solver.cpp:351] Iteration 4500, Testing net (#0)
I0429 14:09:25.374347 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:09:33.666391 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.403359
I0429 14:09:33.666473 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.647656
I0429 14:09:33.666488 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.823828
I0429 14:09:33.666504 25258 solver.cpp:418]     Test net output #3: loss = 1.34982 (* 1 = 1.34982 loss)
I0429 14:09:33.754284 25258 solver.cpp:239] Iteration 4500 (0.658764 iter/s, 30.3599s/20 iters), loss = 1.28837
I0429 14:09:33.763254 25258 solver.cpp:258]     Train net output #0: loss = 1.28837 (* 1 = 1.28837 loss)
I0429 14:09:33.763329 25258 sgd_solver.cpp:112] Iteration 4500, lr = 0.01
I0429 14:09:38.690862 25258 solver.cpp:239] Iteration 4520 (4.05886 iter/s, 4.9275s/20 iters), loss = 1.481
I0429 14:09:38.698284 25258 solver.cpp:258]     Train net output #0: loss = 1.481 (* 1 = 1.481 loss)
I0429 14:09:38.698343 25258 sgd_solver.cpp:112] Iteration 4520, lr = 0.01
I0429 14:09:43.220655 25258 solver.cpp:239] Iteration 4540 (4.42256 iter/s, 4.52227s/20 iters), loss = 1.36868
I0429 14:09:43.227833 25258 solver.cpp:258]     Train net output #0: loss = 1.36868 (* 1 = 1.36868 loss)
I0429 14:09:43.227893 25258 sgd_solver.cpp:112] Iteration 4540, lr = 0.01
I0429 14:09:48.613819 25258 solver.cpp:239] Iteration 4560 (3.71344 iter/s, 5.38585s/20 iters), loss = 1.38652
I0429 14:09:48.619295 25258 solver.cpp:258]     Train net output #0: loss = 1.38652 (* 1 = 1.38652 loss)
I0429 14:09:48.619334 25258 sgd_solver.cpp:112] Iteration 4560, lr = 0.01
I0429 14:09:53.615037 25258 solver.cpp:239] Iteration 4580 (4.00351 iter/s, 4.99561s/20 iters), loss = 1.31568
I0429 14:09:53.615629 25258 solver.cpp:258]     Train net output #0: loss = 1.31568 (* 1 = 1.31568 loss)
I0429 14:09:53.615649 25258 sgd_solver.cpp:112] Iteration 4580, lr = 0.01
I0429 14:10:00.359632 25258 solver.cpp:239] Iteration 4600 (2.96569 iter/s, 6.7438s/20 iters), loss = 1.36048
I0429 14:10:00.364856 25258 solver.cpp:258]     Train net output #0: loss = 1.36048 (* 1 = 1.36048 loss)
I0429 14:10:00.364887 25258 sgd_solver.cpp:112] Iteration 4600, lr = 0.01
I0429 14:10:05.897225 25258 solver.cpp:239] Iteration 4620 (3.61519 iter/s, 5.53222s/20 iters), loss = 1.29854
I0429 14:10:05.905690 25258 solver.cpp:258]     Train net output #0: loss = 1.29854 (* 1 = 1.29854 loss)
I0429 14:10:05.905782 25258 sgd_solver.cpp:112] Iteration 4620, lr = 0.01
I0429 14:10:11.278913 25258 solver.cpp:239] Iteration 4640 (3.72226 iter/s, 5.37308s/20 iters), loss = 1.32212
I0429 14:10:11.278973 25258 solver.cpp:258]     Train net output #0: loss = 1.32212 (* 1 = 1.32212 loss)
I0429 14:10:11.278985 25258 sgd_solver.cpp:112] Iteration 4640, lr = 0.01
I0429 14:10:16.731560 25258 solver.cpp:239] Iteration 4660 (3.6681 iter/s, 5.45241s/20 iters), loss = 1.38465
I0429 14:10:16.736346 25258 solver.cpp:258]     Train net output #0: loss = 1.38465 (* 1 = 1.38465 loss)
I0429 14:10:16.736376 25258 sgd_solver.cpp:112] Iteration 4660, lr = 0.01
I0429 14:10:20.420416 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:10:20.886229 25258 solver.cpp:239] Iteration 4680 (4.81955 iter/s, 4.14976s/20 iters), loss = 1.39686
I0429 14:10:20.891054 25258 solver.cpp:258]     Train net output #0: loss = 1.39686 (* 1 = 1.39686 loss)
I0429 14:10:20.891083 25258 sgd_solver.cpp:112] Iteration 4680, lr = 0.01
I0429 14:10:25.589627 25258 solver.cpp:239] Iteration 4700 (4.25674 iter/s, 4.69844s/20 iters), loss = 1.37244
I0429 14:10:25.594635 25258 solver.cpp:258]     Train net output #0: loss = 1.37244 (* 1 = 1.37244 loss)
I0429 14:10:25.594672 25258 sgd_solver.cpp:112] Iteration 4700, lr = 0.01
I0429 14:10:38.782307 25258 solver.cpp:239] Iteration 4720 (1.51661 iter/s, 13.1873s/20 iters), loss = 1.29707
I0429 14:10:38.789026 25258 solver.cpp:258]     Train net output #0: loss = 1.29707 (* 1 = 1.29707 loss)
I0429 14:10:38.789067 25258 sgd_solver.cpp:112] Iteration 4720, lr = 0.01
I0429 14:10:50.003945 25258 solver.cpp:239] Iteration 4740 (1.78339 iter/s, 11.2146s/20 iters), loss = 1.31797
I0429 14:10:50.009047 25258 solver.cpp:258]     Train net output #0: loss = 1.31797 (* 1 = 1.31797 loss)
I0429 14:10:50.009088 25258 sgd_solver.cpp:112] Iteration 4740, lr = 0.01
I0429 14:10:54.439081 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_4750.caffemodel
I0429 14:11:51.857657 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_4750.solverstate
I0429 14:11:52.228647 25258 solver.cpp:351] Iteration 4750, Testing net (#0)
I0429 14:11:53.797057 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:11:57.677247 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.412266
I0429 14:11:57.677304 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.6575
I0429 14:11:57.677316 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.826797
I0429 14:11:57.677331 25258 solver.cpp:418]     Test net output #3: loss = 1.33752 (* 1 = 1.33752 loss)
I0429 14:11:58.915609 25258 solver.cpp:239] Iteration 4760 (0.290256 iter/s, 68.9046s/20 iters), loss = 1.43146
I0429 14:11:58.915665 25258 solver.cpp:258]     Train net output #0: loss = 1.43146 (* 1 = 1.43146 loss)
I0429 14:11:58.917261 25258 sgd_solver.cpp:112] Iteration 4760, lr = 0.01
I0429 14:12:01.053622 25258 solver.cpp:239] Iteration 4780 (9.35935 iter/s, 2.1369s/20 iters), loss = 1.28192
I0429 14:12:01.053699 25258 solver.cpp:258]     Train net output #0: loss = 1.28192 (* 1 = 1.28192 loss)
I0429 14:12:01.053756 25258 sgd_solver.cpp:112] Iteration 4780, lr = 0.01
I0429 14:12:03.480329 25258 solver.cpp:239] Iteration 4800 (8.24219 iter/s, 2.42654s/20 iters), loss = 1.3447
I0429 14:12:03.485131 25258 solver.cpp:258]     Train net output #0: loss = 1.3447 (* 1 = 1.3447 loss)
I0429 14:12:03.485157 25258 sgd_solver.cpp:112] Iteration 4800, lr = 0.01
I0429 14:12:06.989487 25258 solver.cpp:239] Iteration 4820 (5.70735 iter/s, 3.50425s/20 iters), loss = 1.36297
I0429 14:12:06.994367 25258 solver.cpp:258]     Train net output #0: loss = 1.36297 (* 1 = 1.36297 loss)
I0429 14:12:06.994413 25258 sgd_solver.cpp:112] Iteration 4820, lr = 0.01
I0429 14:12:10.831450 25258 solver.cpp:239] Iteration 4840 (5.21242 iter/s, 3.83699s/20 iters), loss = 1.38027
I0429 14:12:10.837086 25258 solver.cpp:258]     Train net output #0: loss = 1.38027 (* 1 = 1.38027 loss)
I0429 14:12:10.837111 25258 sgd_solver.cpp:112] Iteration 4840, lr = 0.01
I0429 14:12:15.106173 25258 solver.cpp:239] Iteration 4860 (4.68499 iter/s, 4.26896s/20 iters), loss = 1.3953
I0429 14:12:15.106660 25258 solver.cpp:258]     Train net output #0: loss = 1.3953 (* 1 = 1.3953 loss)
I0429 14:12:15.106684 25258 sgd_solver.cpp:112] Iteration 4860, lr = 0.01
I0429 14:12:18.329846 25258 solver.cpp:239] Iteration 4880 (6.20526 iter/s, 3.22307s/20 iters), loss = 1.23265
I0429 14:12:18.334596 25258 solver.cpp:258]     Train net output #0: loss = 1.23265 (* 1 = 1.23265 loss)
I0429 14:12:18.334630 25258 sgd_solver.cpp:112] Iteration 4880, lr = 0.01
I0429 14:12:23.106603 25258 solver.cpp:239] Iteration 4900 (4.19124 iter/s, 4.77186s/20 iters), loss = 1.4152
I0429 14:12:23.110348 25258 solver.cpp:258]     Train net output #0: loss = 1.4152 (* 1 = 1.4152 loss)
I0429 14:12:23.110370 25258 sgd_solver.cpp:112] Iteration 4900, lr = 0.01
I0429 14:12:27.340346 25258 solver.cpp:239] Iteration 4920 (4.72827 iter/s, 4.22988s/20 iters), loss = 1.15932
I0429 14:12:27.345135 25258 solver.cpp:258]     Train net output #0: loss = 1.15932 (* 1 = 1.15932 loss)
I0429 14:12:27.345170 25258 sgd_solver.cpp:112] Iteration 4920, lr = 0.01
I0429 14:12:32.364136 25258 solver.cpp:239] Iteration 4940 (3.98498 iter/s, 5.01884s/20 iters), loss = 1.35146
I0429 14:12:32.368940 25258 solver.cpp:258]     Train net output #0: loss = 1.35146 (* 1 = 1.35146 loss)
I0429 14:12:32.368988 25258 sgd_solver.cpp:112] Iteration 4940, lr = 0.01
I0429 14:12:40.182096 25258 solver.cpp:239] Iteration 4960 (2.55986 iter/s, 7.81292s/20 iters), loss = 1.41346
I0429 14:12:40.186954 25258 solver.cpp:258]     Train net output #0: loss = 1.41346 (* 1 = 1.41346 loss)
I0429 14:12:40.186985 25258 sgd_solver.cpp:112] Iteration 4960, lr = 0.01
I0429 14:12:50.778229 25258 solver.cpp:239] Iteration 4980 (1.8884 iter/s, 10.591s/20 iters), loss = 1.25431
I0429 14:12:50.783361 25258 solver.cpp:258]     Train net output #0: loss = 1.25431 (* 1 = 1.25431 loss)
I0429 14:12:50.783390 25258 sgd_solver.cpp:112] Iteration 4980, lr = 0.01
I0429 14:13:00.396977 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_5000.caffemodel
I0429 14:13:11.505067 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_5000.solverstate
I0429 14:13:11.808370 25258 solver.cpp:351] Iteration 5000, Testing net (#0)
I0429 14:13:14.304885 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:13:19.540591 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.421953
I0429 14:13:19.540638 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.662891
I0429 14:13:19.540645 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.831484
I0429 14:13:19.540654 25258 solver.cpp:418]     Test net output #3: loss = 1.32669 (* 1 = 1.32669 loss)
I0429 14:13:19.642925 25258 solver.cpp:239] Iteration 5000 (0.693031 iter/s, 28.8587s/20 iters), loss = 1.33029
I0429 14:13:19.642987 25258 solver.cpp:258]     Train net output #0: loss = 1.33029 (* 1 = 1.33029 loss)
I0429 14:13:19.642999 25258 sgd_solver.cpp:112] Iteration 5000, lr = 0.01
I0429 14:13:24.806586 25258 solver.cpp:239] Iteration 5020 (3.87342 iter/s, 5.1634s/20 iters), loss = 1.25621
I0429 14:13:24.813333 25258 solver.cpp:258]     Train net output #0: loss = 1.25621 (* 1 = 1.25621 loss)
I0429 14:13:24.813385 25258 sgd_solver.cpp:112] Iteration 5020, lr = 0.01
I0429 14:13:29.429028 25258 solver.cpp:239] Iteration 5040 (4.33315 iter/s, 4.61558s/20 iters), loss = 1.4141
I0429 14:13:29.440754 25258 solver.cpp:258]     Train net output #0: loss = 1.4141 (* 1 = 1.4141 loss)
I0429 14:13:29.440798 25258 sgd_solver.cpp:112] Iteration 5040, lr = 0.01
I0429 14:13:35.151006 25258 solver.cpp:239] Iteration 5060 (3.50257 iter/s, 5.71009s/20 iters), loss = 1.26547
I0429 14:13:35.155966 25258 solver.cpp:258]     Train net output #0: loss = 1.26547 (* 1 = 1.26547 loss)
I0429 14:13:35.156000 25258 sgd_solver.cpp:112] Iteration 5060, lr = 0.01
I0429 14:13:41.266712 25258 solver.cpp:239] Iteration 5080 (3.27301 iter/s, 6.11058s/20 iters), loss = 1.31924
I0429 14:13:41.271519 25258 solver.cpp:258]     Train net output #0: loss = 1.31924 (* 1 = 1.31924 loss)
I0429 14:13:41.271549 25258 sgd_solver.cpp:112] Iteration 5080, lr = 0.01
I0429 14:13:47.170812 25258 solver.cpp:239] Iteration 5100 (3.39034 iter/s, 5.89912s/20 iters), loss = 1.22439
I0429 14:13:47.175730 25258 solver.cpp:258]     Train net output #0: loss = 1.22439 (* 1 = 1.22439 loss)
I0429 14:13:47.175765 25258 sgd_solver.cpp:112] Iteration 5100, lr = 0.01
I0429 14:13:52.620633 25258 solver.cpp:239] Iteration 5120 (3.67327 iter/s, 5.44474s/20 iters), loss = 1.3689
I0429 14:13:52.625437 25258 solver.cpp:258]     Train net output #0: loss = 1.3689 (* 1 = 1.3689 loss)
I0429 14:13:52.625468 25258 sgd_solver.cpp:112] Iteration 5120, lr = 0.01
I0429 14:13:58.444635 25258 solver.cpp:239] Iteration 5140 (3.437 iter/s, 5.81903s/20 iters), loss = 1.26138
I0429 14:13:58.449458 25258 solver.cpp:258]     Train net output #0: loss = 1.26138 (* 1 = 1.26138 loss)
I0429 14:13:58.449497 25258 sgd_solver.cpp:112] Iteration 5140, lr = 0.01
I0429 14:14:04.784829 25258 solver.cpp:239] Iteration 5160 (3.15697 iter/s, 6.33519s/20 iters), loss = 1.34788
I0429 14:14:04.789651 25258 solver.cpp:258]     Train net output #0: loss = 1.34788 (* 1 = 1.34788 loss)
I0429 14:14:04.789767 25258 sgd_solver.cpp:112] Iteration 5160, lr = 0.01
I0429 14:14:10.684401 25258 solver.cpp:239] Iteration 5180 (3.39301 iter/s, 5.89447s/20 iters), loss = 1.33327
I0429 14:14:10.690332 25258 solver.cpp:258]     Train net output #0: loss = 1.33327 (* 1 = 1.33327 loss)
I0429 14:14:10.690372 25258 sgd_solver.cpp:112] Iteration 5180, lr = 0.01
I0429 14:14:15.756371 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:14:16.536201 25258 solver.cpp:239] Iteration 5200 (3.42391 iter/s, 5.84127s/20 iters), loss = 1.28856
I0429 14:14:16.541816 25258 solver.cpp:258]     Train net output #0: loss = 1.28856 (* 1 = 1.28856 loss)
I0429 14:14:16.541851 25258 sgd_solver.cpp:112] Iteration 5200, lr = 0.01
I0429 14:14:23.145862 25258 solver.cpp:239] Iteration 5220 (3.02854 iter/s, 6.60385s/20 iters), loss = 1.34067
I0429 14:14:23.152300 25258 solver.cpp:258]     Train net output #0: loss = 1.34067 (* 1 = 1.34067 loss)
I0429 14:14:23.152372 25258 sgd_solver.cpp:112] Iteration 5220, lr = 0.01
I0429 14:14:28.148998 25258 solver.cpp:239] Iteration 5240 (4.00274 iter/s, 4.99658s/20 iters), loss = 1.28972
I0429 14:14:28.154008 25258 solver.cpp:258]     Train net output #0: loss = 1.28972 (* 1 = 1.28972 loss)
I0429 14:14:28.154060 25258 sgd_solver.cpp:112] Iteration 5240, lr = 0.01
I0429 14:14:30.704241 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_5250.caffemodel
I0429 14:14:57.514194 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_5250.solverstate
I0429 14:14:58.041944 25258 solver.cpp:351] Iteration 5250, Testing net (#0)
I0429 14:14:59.057077 25258 blocking_queue.cpp:49] Waiting for data
I0429 14:15:01.295492 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:15:10.124115 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.429922
I0429 14:15:10.124189 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.676797
I0429 14:15:10.124209 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.833594
I0429 14:15:10.124229 25258 solver.cpp:418]     Test net output #3: loss = 1.31233 (* 1 = 1.31233 loss)
I0429 14:15:13.888412 25258 solver.cpp:239] Iteration 5260 (0.43732 iter/s, 45.7331s/20 iters), loss = 1.30528
I0429 14:15:13.893806 25258 solver.cpp:258]     Train net output #0: loss = 1.30528 (* 1 = 1.30528 loss)
I0429 14:15:13.893841 25258 sgd_solver.cpp:112] Iteration 5260, lr = 0.01
I0429 14:15:21.707638 25258 solver.cpp:239] Iteration 5280 (2.55964 iter/s, 7.81359s/20 iters), loss = 1.42476
I0429 14:15:21.716051 25258 solver.cpp:258]     Train net output #0: loss = 1.42476 (* 1 = 1.42476 loss)
I0429 14:15:21.716085 25258 sgd_solver.cpp:112] Iteration 5280, lr = 0.01
I0429 14:15:27.185603 25258 solver.cpp:239] Iteration 5300 (3.65671 iter/s, 5.4694s/20 iters), loss = 1.23298
I0429 14:15:27.190409 25258 solver.cpp:258]     Train net output #0: loss = 1.23298 (* 1 = 1.23298 loss)
I0429 14:15:27.190443 25258 sgd_solver.cpp:112] Iteration 5300, lr = 0.01
I0429 14:15:32.843441 25258 solver.cpp:239] Iteration 5320 (3.53803 iter/s, 5.65287s/20 iters), loss = 1.24616
I0429 14:15:32.848333 25258 solver.cpp:258]     Train net output #0: loss = 1.24616 (* 1 = 1.24616 loss)
I0429 14:15:32.848374 25258 sgd_solver.cpp:112] Iteration 5320, lr = 0.01
I0429 14:15:38.412593 25258 solver.cpp:239] Iteration 5340 (3.59446 iter/s, 5.56411s/20 iters), loss = 1.28493
I0429 14:15:38.417690 25258 solver.cpp:258]     Train net output #0: loss = 1.28493 (* 1 = 1.28493 loss)
I0429 14:15:38.417806 25258 sgd_solver.cpp:112] Iteration 5340, lr = 0.01
I0429 14:15:45.149376 25258 solver.cpp:239] Iteration 5360 (2.9711 iter/s, 6.73151s/20 iters), loss = 1.30077
I0429 14:15:45.149448 25258 solver.cpp:258]     Train net output #0: loss = 1.30077 (* 1 = 1.30077 loss)
I0429 14:15:45.149467 25258 sgd_solver.cpp:112] Iteration 5360, lr = 0.01
I0429 14:15:49.675356 25258 solver.cpp:239] Iteration 5380 (4.41915 iter/s, 4.52576s/20 iters), loss = 1.4026
I0429 14:15:49.680160 25258 solver.cpp:258]     Train net output #0: loss = 1.4026 (* 1 = 1.4026 loss)
I0429 14:15:49.680186 25258 sgd_solver.cpp:112] Iteration 5380, lr = 0.01
I0429 14:15:56.149843 25258 solver.cpp:239] Iteration 5400 (3.09143 iter/s, 6.46949s/20 iters), loss = 1.23148
I0429 14:15:56.155777 25258 solver.cpp:258]     Train net output #0: loss = 1.23148 (* 1 = 1.23148 loss)
I0429 14:15:56.155850 25258 sgd_solver.cpp:112] Iteration 5400, lr = 0.01
I0429 14:16:02.271798 25258 solver.cpp:239] Iteration 5420 (3.27018 iter/s, 6.11587s/20 iters), loss = 1.36431
I0429 14:16:02.276656 25258 solver.cpp:258]     Train net output #0: loss = 1.36431 (* 1 = 1.36431 loss)
I0429 14:16:02.276710 25258 sgd_solver.cpp:112] Iteration 5420, lr = 0.01
I0429 14:16:08.339418 25258 solver.cpp:239] Iteration 5440 (3.29891 iter/s, 6.0626s/20 iters), loss = 1.10717
I0429 14:16:08.344662 25258 solver.cpp:258]     Train net output #0: loss = 1.10717 (* 1 = 1.10717 loss)
I0429 14:16:08.344691 25258 sgd_solver.cpp:112] Iteration 5440, lr = 0.01
I0429 14:16:13.758314 25258 solver.cpp:239] Iteration 5460 (3.69448 iter/s, 5.41348s/20 iters), loss = 1.28754
I0429 14:16:13.763213 25258 solver.cpp:258]     Train net output #0: loss = 1.28754 (* 1 = 1.28754 loss)
I0429 14:16:13.763257 25258 sgd_solver.cpp:112] Iteration 5460, lr = 0.01
I0429 14:16:19.550076 25258 solver.cpp:239] Iteration 5480 (3.4562 iter/s, 5.78671s/20 iters), loss = 1.3621
I0429 14:16:19.555001 25258 solver.cpp:258]     Train net output #0: loss = 1.3621 (* 1 = 1.3621 loss)
I0429 14:16:19.555032 25258 sgd_solver.cpp:112] Iteration 5480, lr = 0.01
I0429 14:16:24.653009 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_5500.caffemodel
I0429 14:16:54.793244 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_5500.solverstate
I0429 14:16:55.212564 25258 solver.cpp:351] Iteration 5500, Testing net (#0)
I0429 14:16:57.293339 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:17:03.006803 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.426562
I0429 14:17:03.006862 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.668203
I0429 14:17:03.006876 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.830859
I0429 14:17:03.006892 25258 solver.cpp:418]     Test net output #3: loss = 1.32176 (* 1 = 1.32176 loss)
I0429 14:17:03.198246 25258 solver.cpp:239] Iteration 5500 (0.458274 iter/s, 43.642s/20 iters), loss = 1.30422
I0429 14:17:03.198319 25258 solver.cpp:258]     Train net output #0: loss = 1.30422 (* 1 = 1.30422 loss)
I0429 14:17:03.198334 25258 sgd_solver.cpp:112] Iteration 5500, lr = 0.01
I0429 14:17:11.664918 25258 solver.cpp:239] Iteration 5520 (2.36233 iter/s, 8.4662s/20 iters), loss = 1.22326
I0429 14:17:11.664989 25258 solver.cpp:258]     Train net output #0: loss = 1.22326 (* 1 = 1.22326 loss)
I0429 14:17:11.665004 25258 sgd_solver.cpp:112] Iteration 5520, lr = 0.01
I0429 14:17:21.690521 25258 solver.cpp:239] Iteration 5540 (1.99497 iter/s, 10.0252s/20 iters), loss = 1.21932
I0429 14:17:21.695909 25258 solver.cpp:258]     Train net output #0: loss = 1.21932 (* 1 = 1.21932 loss)
I0429 14:17:21.695956 25258 sgd_solver.cpp:112] Iteration 5540, lr = 0.01
I0429 14:17:29.448019 25258 solver.cpp:239] Iteration 5560 (2.58001 iter/s, 7.75191s/20 iters), loss = 1.38421
I0429 14:17:29.455799 25258 solver.cpp:258]     Train net output #0: loss = 1.38421 (* 1 = 1.38421 loss)
I0429 14:17:29.455835 25258 sgd_solver.cpp:112] Iteration 5560, lr = 0.01
I0429 14:17:35.320051 25258 solver.cpp:239] Iteration 5580 (3.4106 iter/s, 5.86407s/20 iters), loss = 1.31001
I0429 14:17:35.320154 25258 solver.cpp:258]     Train net output #0: loss = 1.31001 (* 1 = 1.31001 loss)
I0429 14:17:35.320169 25258 sgd_solver.cpp:112] Iteration 5580, lr = 0.01
I0429 14:17:40.694852 25258 solver.cpp:239] Iteration 5600 (3.72126 iter/s, 5.37452s/20 iters), loss = 1.2775
I0429 14:17:40.699658 25258 solver.cpp:258]     Train net output #0: loss = 1.2775 (* 1 = 1.2775 loss)
I0429 14:17:40.699689 25258 sgd_solver.cpp:112] Iteration 5600, lr = 0.01
I0429 14:17:47.175891 25258 solver.cpp:239] Iteration 5620 (3.08831 iter/s, 6.47604s/20 iters), loss = 1.23737
I0429 14:17:47.180691 25258 solver.cpp:258]     Train net output #0: loss = 1.23737 (* 1 = 1.23737 loss)
I0429 14:17:47.180717 25258 sgd_solver.cpp:112] Iteration 5620, lr = 0.01
I0429 14:17:52.855207 25258 solver.cpp:239] Iteration 5640 (3.52464 iter/s, 5.67434s/20 iters), loss = 1.28692
I0429 14:17:52.860116 25258 solver.cpp:258]     Train net output #0: loss = 1.28692 (* 1 = 1.28692 loss)
I0429 14:17:52.860146 25258 sgd_solver.cpp:112] Iteration 5640, lr = 0.01
I0429 14:17:56.823352 25258 solver.cpp:239] Iteration 5660 (5.05214 iter/s, 3.95872s/20 iters), loss = 1.20676
I0429 14:17:56.823781 25258 solver.cpp:258]     Train net output #0: loss = 1.20676 (* 1 = 1.20676 loss)
I0429 14:17:56.823812 25258 sgd_solver.cpp:112] Iteration 5660, lr = 0.01
I0429 14:18:02.976660 25258 solver.cpp:239] Iteration 5680 (3.25061 iter/s, 6.1527s/20 iters), loss = 1.14762
I0429 14:18:02.981539 25258 solver.cpp:258]     Train net output #0: loss = 1.14762 (* 1 = 1.14762 loss)
I0429 14:18:02.981570 25258 sgd_solver.cpp:112] Iteration 5680, lr = 0.01
I0429 14:18:08.224793 25258 solver.cpp:239] Iteration 5700 (3.81695 iter/s, 5.23979s/20 iters), loss = 1.24509
I0429 14:18:08.226289 25258 solver.cpp:258]     Train net output #0: loss = 1.24509 (* 1 = 1.24509 loss)
I0429 14:18:08.226316 25258 sgd_solver.cpp:112] Iteration 5700, lr = 0.01
I0429 14:18:12.617602 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:18:13.699769 25258 solver.cpp:239] Iteration 5720 (3.65409 iter/s, 5.47332s/20 iters), loss = 1.22531
I0429 14:18:13.705088 25258 solver.cpp:258]     Train net output #0: loss = 1.22531 (* 1 = 1.22531 loss)
I0429 14:18:13.705132 25258 sgd_solver.cpp:112] Iteration 5720, lr = 0.01
I0429 14:18:19.200598 25258 solver.cpp:239] Iteration 5740 (3.63943 iter/s, 5.49537s/20 iters), loss = 1.30609
I0429 14:18:19.200670 25258 solver.cpp:258]     Train net output #0: loss = 1.30609 (* 1 = 1.30609 loss)
I0429 14:18:19.200686 25258 sgd_solver.cpp:112] Iteration 5740, lr = 0.01
I0429 14:18:21.622185 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_5750.caffemodel
I0429 14:18:49.158205 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_5750.solverstate
I0429 14:18:49.575314 25258 solver.cpp:351] Iteration 5750, Testing net (#0)
I0429 14:18:51.838820 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:18:57.194098 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.452969
I0429 14:18:57.194159 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.696563
I0429 14:18:57.194176 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.846953
I0429 14:18:57.194201 25258 solver.cpp:418]     Test net output #3: loss = 1.26493 (* 1 = 1.26493 loss)
I0429 14:18:58.987690 25258 solver.cpp:239] Iteration 5760 (0.502691 iter/s, 39.7859s/20 iters), loss = 1.18572
I0429 14:18:58.997061 25258 solver.cpp:258]     Train net output #0: loss = 1.18572 (* 1 = 1.18572 loss)
I0429 14:18:58.997117 25258 sgd_solver.cpp:112] Iteration 5760, lr = 0.01
I0429 14:19:04.321772 25258 solver.cpp:239] Iteration 5780 (3.7562 iter/s, 5.32453s/20 iters), loss = 1.25386
I0429 14:19:04.327214 25258 solver.cpp:258]     Train net output #0: loss = 1.25386 (* 1 = 1.25386 loss)
I0429 14:19:04.327283 25258 sgd_solver.cpp:112] Iteration 5780, lr = 0.01
I0429 14:19:10.062435 25258 solver.cpp:239] Iteration 5800 (3.4873 iter/s, 5.73509s/20 iters), loss = 1.44114
I0429 14:19:10.062505 25258 solver.cpp:258]     Train net output #0: loss = 1.44114 (* 1 = 1.44114 loss)
I0429 14:19:10.062520 25258 sgd_solver.cpp:112] Iteration 5800, lr = 0.01
I0429 14:19:14.582041 25258 solver.cpp:239] Iteration 5820 (4.42539 iter/s, 4.51937s/20 iters), loss = 1.24538
I0429 14:19:14.587715 25258 solver.cpp:258]     Train net output #0: loss = 1.24538 (* 1 = 1.24538 loss)
I0429 14:19:14.587769 25258 sgd_solver.cpp:112] Iteration 5820, lr = 0.01
I0429 14:19:24.617051 25258 solver.cpp:239] Iteration 5840 (1.99422 iter/s, 10.029s/20 iters), loss = 1.14845
I0429 14:19:24.623092 25258 solver.cpp:258]     Train net output #0: loss = 1.14845 (* 1 = 1.14845 loss)
I0429 14:19:24.623170 25258 sgd_solver.cpp:112] Iteration 5840, lr = 0.01
I0429 14:19:37.201738 25258 solver.cpp:239] Iteration 5860 (1.59004 iter/s, 12.5783s/20 iters), loss = 1.37528
I0429 14:19:37.207285 25258 solver.cpp:258]     Train net output #0: loss = 1.37528 (* 1 = 1.37528 loss)
I0429 14:19:37.207331 25258 sgd_solver.cpp:112] Iteration 5860, lr = 0.01
I0429 14:19:48.270581 25258 solver.cpp:239] Iteration 5880 (1.80784 iter/s, 11.063s/20 iters), loss = 1.26657
I0429 14:19:48.277886 25258 solver.cpp:258]     Train net output #0: loss = 1.26657 (* 1 = 1.26657 loss)
I0429 14:19:48.277950 25258 sgd_solver.cpp:112] Iteration 5880, lr = 0.01
I0429 14:19:55.170604 25258 solver.cpp:239] Iteration 5900 (2.90168 iter/s, 6.89255s/20 iters), loss = 1.28247
I0429 14:19:55.175726 25258 solver.cpp:258]     Train net output #0: loss = 1.28247 (* 1 = 1.28247 loss)
I0429 14:19:55.175761 25258 sgd_solver.cpp:112] Iteration 5900, lr = 0.01
I0429 14:20:00.655659 25258 solver.cpp:239] Iteration 5920 (3.64978 iter/s, 5.47978s/20 iters), loss = 1.24956
I0429 14:20:00.662204 25258 solver.cpp:258]     Train net output #0: loss = 1.24956 (* 1 = 1.24956 loss)
I0429 14:20:00.662266 25258 sgd_solver.cpp:112] Iteration 5920, lr = 0.01
I0429 14:20:06.884603 25258 solver.cpp:239] Iteration 5940 (3.21426 iter/s, 6.22227s/20 iters), loss = 1.42283
I0429 14:20:06.891183 25258 solver.cpp:258]     Train net output #0: loss = 1.42283 (* 1 = 1.42283 loss)
I0429 14:20:06.891240 25258 sgd_solver.cpp:112] Iteration 5940, lr = 0.01
I0429 14:20:12.971621 25258 solver.cpp:239] Iteration 5960 (3.28932 iter/s, 6.08028s/20 iters), loss = 1.09184
I0429 14:20:12.971698 25258 solver.cpp:258]     Train net output #0: loss = 1.09184 (* 1 = 1.09184 loss)
I0429 14:20:12.971711 25258 sgd_solver.cpp:112] Iteration 5960, lr = 0.01
I0429 14:20:18.848147 25258 solver.cpp:239] Iteration 5980 (3.40352 iter/s, 5.87626s/20 iters), loss = 1.22584
I0429 14:20:18.853296 25258 solver.cpp:258]     Train net output #0: loss = 1.22584 (* 1 = 1.22584 loss)
I0429 14:20:18.853332 25258 sgd_solver.cpp:112] Iteration 5980, lr = 0.01
I0429 14:20:24.534920 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_6000.caffemodel
I0429 14:21:07.291640 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_6000.solverstate
I0429 14:21:07.827245 25258 solver.cpp:351] Iteration 6000, Testing net (#0)
I0429 14:21:10.164981 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:21:12.046725 25258 blocking_queue.cpp:49] Waiting for data
I0429 14:21:14.225535 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.468281
I0429 14:21:14.225605 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.705156
I0429 14:21:14.225615 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.859844
I0429 14:21:14.225630 25258 solver.cpp:418]     Test net output #3: loss = 1.2364 (* 1 = 1.2364 loss)
I0429 14:21:14.335372 25258 solver.cpp:239] Iteration 6000 (0.360487 iter/s, 55.4805s/20 iters), loss = 1.2762
I0429 14:21:14.335439 25258 solver.cpp:258]     Train net output #0: loss = 1.2762 (* 1 = 1.2762 loss)
I0429 14:21:14.335456 25258 sgd_solver.cpp:112] Iteration 6000, lr = 0.01
I0429 14:21:18.736315 25258 solver.cpp:239] Iteration 6020 (4.5447 iter/s, 4.40073s/20 iters), loss = 1.12497
I0429 14:21:18.741644 25258 solver.cpp:258]     Train net output #0: loss = 1.12497 (* 1 = 1.12497 loss)
I0429 14:21:18.741698 25258 sgd_solver.cpp:112] Iteration 6020, lr = 0.01
I0429 14:21:23.963167 25258 solver.cpp:239] Iteration 6040 (3.83039 iter/s, 5.22139s/20 iters), loss = 1.20711
I0429 14:21:23.968298 25258 solver.cpp:258]     Train net output #0: loss = 1.20711 (* 1 = 1.20711 loss)
I0429 14:21:23.968339 25258 sgd_solver.cpp:112] Iteration 6040, lr = 0.01
I0429 14:21:28.586109 25258 solver.cpp:239] Iteration 6060 (4.33118 iter/s, 4.61768s/20 iters), loss = 1.19385
I0429 14:21:28.591293 25258 solver.cpp:258]     Train net output #0: loss = 1.19385 (* 1 = 1.19385 loss)
I0429 14:21:28.591342 25258 sgd_solver.cpp:112] Iteration 6060, lr = 0.01
I0429 14:21:34.560917 25258 solver.cpp:239] Iteration 6080 (3.35038 iter/s, 5.96946s/20 iters), loss = 1.30801
I0429 14:21:34.560995 25258 solver.cpp:258]     Train net output #0: loss = 1.30801 (* 1 = 1.30801 loss)
I0429 14:21:34.561013 25258 sgd_solver.cpp:112] Iteration 6080, lr = 0.01
I0429 14:21:41.514482 25258 solver.cpp:239] Iteration 6100 (2.87635 iter/s, 6.95326s/20 iters), loss = 1.38159
I0429 14:21:41.522847 25258 solver.cpp:258]     Train net output #0: loss = 1.38159 (* 1 = 1.38159 loss)
I0429 14:21:41.522899 25258 sgd_solver.cpp:112] Iteration 6100, lr = 0.01
I0429 14:21:47.669019 25258 solver.cpp:239] Iteration 6120 (3.25413 iter/s, 6.14605s/20 iters), loss = 1.27298
I0429 14:21:47.674268 25258 solver.cpp:258]     Train net output #0: loss = 1.27298 (* 1 = 1.27298 loss)
I0429 14:21:47.674306 25258 sgd_solver.cpp:112] Iteration 6120, lr = 0.01
I0429 14:21:54.085590 25258 solver.cpp:239] Iteration 6140 (3.11957 iter/s, 6.41114s/20 iters), loss = 1.20441
I0429 14:21:54.093145 25258 solver.cpp:258]     Train net output #0: loss = 1.20441 (* 1 = 1.20441 loss)
I0429 14:21:54.093183 25258 sgd_solver.cpp:112] Iteration 6140, lr = 0.01
I0429 14:22:05.921602 25258 solver.cpp:239] Iteration 6160 (1.69088 iter/s, 11.8281s/20 iters), loss = 1.24501
I0429 14:22:05.926915 25258 solver.cpp:258]     Train net output #0: loss = 1.24501 (* 1 = 1.24501 loss)
I0429 14:22:05.926950 25258 sgd_solver.cpp:112] Iteration 6160, lr = 0.01
I0429 14:22:20.647048 25258 solver.cpp:239] Iteration 6180 (1.35872 iter/s, 14.7197s/20 iters), loss = 1.19672
I0429 14:22:20.658689 25258 solver.cpp:258]     Train net output #0: loss = 1.19672 (* 1 = 1.19672 loss)
I0429 14:22:20.658715 25258 sgd_solver.cpp:112] Iteration 6180, lr = 0.01
I0429 14:22:31.663797 25258 solver.cpp:239] Iteration 6200 (1.81762 iter/s, 11.0034s/20 iters), loss = 1.11711
I0429 14:22:31.668855 25258 solver.cpp:258]     Train net output #0: loss = 1.11711 (* 1 = 1.11711 loss)
I0429 14:22:31.668958 25258 sgd_solver.cpp:112] Iteration 6200, lr = 0.01
I0429 14:22:37.717535 25258 solver.cpp:239] Iteration 6220 (3.30657 iter/s, 6.04857s/20 iters), loss = 1.27844
I0429 14:22:37.723284 25258 solver.cpp:258]     Train net output #0: loss = 1.27844 (* 1 = 1.27844 loss)
I0429 14:22:37.723338 25258 sgd_solver.cpp:112] Iteration 6220, lr = 0.01
I0429 14:22:43.492818 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:22:43.855913 25258 solver.cpp:239] Iteration 6240 (3.26132 iter/s, 6.13248s/20 iters), loss = 1.24483
I0429 14:22:43.855999 25258 solver.cpp:258]     Train net output #0: loss = 1.24483 (* 1 = 1.24483 loss)
I0429 14:22:43.856021 25258 sgd_solver.cpp:112] Iteration 6240, lr = 0.01
I0429 14:22:47.096715 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_6250.caffemodel
I0429 14:23:16.232697 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_6250.solverstate
I0429 14:23:16.591511 25258 solver.cpp:351] Iteration 6250, Testing net (#0)
I0429 14:23:19.033010 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:23:24.304049 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.475391
I0429 14:23:24.304102 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.717109
I0429 14:23:24.304112 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.870156
I0429 14:23:24.304124 25258 solver.cpp:418]     Test net output #3: loss = 1.21134 (* 1 = 1.21134 loss)
I0429 14:23:27.347452 25258 solver.cpp:239] Iteration 6260 (0.459873 iter/s, 43.4902s/20 iters), loss = 1.24748
I0429 14:23:27.353320 25258 solver.cpp:258]     Train net output #0: loss = 1.24748 (* 1 = 1.24748 loss)
I0429 14:23:27.353358 25258 sgd_solver.cpp:112] Iteration 6260, lr = 0.01
I0429 14:23:33.146034 25258 solver.cpp:239] Iteration 6280 (3.45271 iter/s, 5.79255s/20 iters), loss = 1.17826
I0429 14:23:33.151121 25258 solver.cpp:258]     Train net output #0: loss = 1.17826 (* 1 = 1.17826 loss)
I0429 14:23:33.151185 25258 sgd_solver.cpp:112] Iteration 6280, lr = 0.01
I0429 14:23:39.215107 25258 solver.cpp:239] Iteration 6300 (3.29825 iter/s, 6.06383s/20 iters), loss = 1.28125
I0429 14:23:39.215170 25258 solver.cpp:258]     Train net output #0: loss = 1.28125 (* 1 = 1.28125 loss)
I0429 14:23:39.215183 25258 sgd_solver.cpp:112] Iteration 6300, lr = 0.01
I0429 14:23:43.907517 25258 solver.cpp:239] Iteration 6320 (4.2624 iter/s, 4.69219s/20 iters), loss = 1.34678
I0429 14:23:43.907591 25258 solver.cpp:258]     Train net output #0: loss = 1.34678 (* 1 = 1.34678 loss)
I0429 14:23:43.907605 25258 sgd_solver.cpp:112] Iteration 6320, lr = 0.01
I0429 14:23:50.138866 25258 solver.cpp:239] Iteration 6340 (3.20972 iter/s, 6.23107s/20 iters), loss = 1.18314
I0429 14:23:50.146441 25258 solver.cpp:258]     Train net output #0: loss = 1.18314 (* 1 = 1.18314 loss)
I0429 14:23:50.146477 25258 sgd_solver.cpp:112] Iteration 6340, lr = 0.01
I0429 14:23:56.512100 25258 solver.cpp:239] Iteration 6360 (3.14197 iter/s, 6.36543s/20 iters), loss = 1.11311
I0429 14:23:56.519278 25258 solver.cpp:258]     Train net output #0: loss = 1.11311 (* 1 = 1.11311 loss)
I0429 14:23:56.519345 25258 sgd_solver.cpp:112] Iteration 6360, lr = 0.01
I0429 14:24:00.838946 25258 solver.cpp:239] Iteration 6380 (4.63009 iter/s, 4.31957s/20 iters), loss = 1.20956
I0429 14:24:00.843755 25258 solver.cpp:258]     Train net output #0: loss = 1.20956 (* 1 = 1.20956 loss)
I0429 14:24:00.843789 25258 sgd_solver.cpp:112] Iteration 6380, lr = 0.01
I0429 14:24:07.934949 25258 solver.cpp:239] Iteration 6400 (2.82048 iter/s, 7.09098s/20 iters), loss = 1.20711
I0429 14:24:07.935037 25258 solver.cpp:258]     Train net output #0: loss = 1.20711 (* 1 = 1.20711 loss)
I0429 14:24:07.935060 25258 sgd_solver.cpp:112] Iteration 6400, lr = 0.01
I0429 14:24:14.155478 25258 solver.cpp:239] Iteration 6420 (3.21531 iter/s, 6.22024s/20 iters), loss = 1.19562
I0429 14:24:14.160671 25258 solver.cpp:258]     Train net output #0: loss = 1.19562 (* 1 = 1.19562 loss)
I0429 14:24:14.160718 25258 sgd_solver.cpp:112] Iteration 6420, lr = 0.01
I0429 14:24:21.122043 25258 solver.cpp:239] Iteration 6440 (2.87307 iter/s, 6.96118s/20 iters), loss = 1.07531
I0429 14:24:21.133188 25258 solver.cpp:258]     Train net output #0: loss = 1.07531 (* 1 = 1.07531 loss)
I0429 14:24:21.133208 25258 sgd_solver.cpp:112] Iteration 6440, lr = 0.01
I0429 14:24:26.377660 25258 solver.cpp:239] Iteration 6460 (3.81366 iter/s, 5.24431s/20 iters), loss = 1.34476
I0429 14:24:26.389812 25258 solver.cpp:258]     Train net output #0: loss = 1.34476 (* 1 = 1.34476 loss)
I0429 14:24:26.389853 25258 sgd_solver.cpp:112] Iteration 6460, lr = 0.01
I0429 14:24:35.383713 25258 solver.cpp:239] Iteration 6480 (2.22379 iter/s, 8.99367s/20 iters), loss = 1.01776
I0429 14:24:35.389454 25258 solver.cpp:258]     Train net output #0: loss = 1.01776 (* 1 = 1.01776 loss)
I0429 14:24:35.389499 25258 sgd_solver.cpp:112] Iteration 6480, lr = 0.01
I0429 14:24:47.772788 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_6500.caffemodel
I0429 14:25:23.754205 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_6500.solverstate
I0429 14:25:24.114117 25258 solver.cpp:351] Iteration 6500, Testing net (#0)
I0429 14:25:26.639125 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:25:32.885177 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.465547
I0429 14:25:32.885244 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.707344
I0429 14:25:32.885259 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.859219
I0429 14:25:32.885283 25258 solver.cpp:418]     Test net output #3: loss = 1.23517 (* 1 = 1.23517 loss)
I0429 14:25:33.226866 25258 solver.cpp:239] Iteration 6500 (0.345806 iter/s, 57.8358s/20 iters), loss = 1.32032
I0429 14:25:33.226938 25258 solver.cpp:258]     Train net output #0: loss = 1.32032 (* 1 = 1.32032 loss)
I0429 14:25:33.226951 25258 sgd_solver.cpp:112] Iteration 6500, lr = 0.01
I0429 14:25:37.383324 25258 solver.cpp:239] Iteration 6520 (4.81204 iter/s, 4.15624s/20 iters), loss = 1.2233
I0429 14:25:37.388308 25258 solver.cpp:258]     Train net output #0: loss = 1.2233 (* 1 = 1.2233 loss)
I0429 14:25:37.388344 25258 sgd_solver.cpp:112] Iteration 6520, lr = 0.01
I0429 14:25:42.689421 25258 solver.cpp:239] Iteration 6540 (3.7729 iter/s, 5.30096s/20 iters), loss = 1.05761
I0429 14:25:42.694459 25258 solver.cpp:258]     Train net output #0: loss = 1.05761 (* 1 = 1.05761 loss)
I0429 14:25:42.694494 25258 sgd_solver.cpp:112] Iteration 6540, lr = 0.01
I0429 14:25:48.203104 25258 solver.cpp:239] Iteration 6560 (3.63076 iter/s, 5.50849s/20 iters), loss = 1.11624
I0429 14:25:48.208078 25258 solver.cpp:258]     Train net output #0: loss = 1.11624 (* 1 = 1.11624 loss)
I0429 14:25:48.208106 25258 sgd_solver.cpp:112] Iteration 6560, lr = 0.01
I0429 14:25:54.757040 25258 solver.cpp:239] Iteration 6580 (3.05401 iter/s, 6.54877s/20 iters), loss = 1.06947
I0429 14:25:54.762202 25258 solver.cpp:258]     Train net output #0: loss = 1.06947 (* 1 = 1.06947 loss)
I0429 14:25:54.762236 25258 sgd_solver.cpp:112] Iteration 6580, lr = 0.01
I0429 14:26:01.640375 25258 solver.cpp:239] Iteration 6600 (2.90783 iter/s, 6.87798s/20 iters), loss = 1.34236
I0429 14:26:01.645608 25258 solver.cpp:258]     Train net output #0: loss = 1.34236 (* 1 = 1.34236 loss)
I0429 14:26:01.645658 25258 sgd_solver.cpp:112] Iteration 6600, lr = 0.01
I0429 14:26:07.809134 25258 solver.cpp:239] Iteration 6620 (3.24501 iter/s, 6.16331s/20 iters), loss = 1.16485
I0429 14:26:07.816843 25258 solver.cpp:258]     Train net output #0: loss = 1.16485 (* 1 = 1.16485 loss)
I0429 14:26:07.816928 25258 sgd_solver.cpp:112] Iteration 6620, lr = 0.01
I0429 14:26:14.533082 25258 solver.cpp:239] Iteration 6640 (2.97792 iter/s, 6.7161s/20 iters), loss = 1.26396
I0429 14:26:14.544006 25258 solver.cpp:258]     Train net output #0: loss = 1.26396 (* 1 = 1.26396 loss)
I0429 14:26:14.544059 25258 sgd_solver.cpp:112] Iteration 6640, lr = 0.01
I0429 14:26:21.086283 25258 solver.cpp:239] Iteration 6660 (3.05713 iter/s, 6.54208s/20 iters), loss = 1.10791
I0429 14:26:21.094401 25258 solver.cpp:258]     Train net output #0: loss = 1.10791 (* 1 = 1.10791 loss)
I0429 14:26:21.094486 25258 sgd_solver.cpp:112] Iteration 6660, lr = 0.01
I0429 14:26:28.449739 25258 solver.cpp:239] Iteration 6680 (2.71917 iter/s, 7.35519s/20 iters), loss = 1.18165
I0429 14:26:28.453944 25258 solver.cpp:258]     Train net output #0: loss = 1.18165 (* 1 = 1.18165 loss)
I0429 14:26:28.453974 25258 sgd_solver.cpp:112] Iteration 6680, lr = 0.01
I0429 14:26:34.546363 25258 solver.cpp:239] Iteration 6700 (3.28285 iter/s, 6.09226s/20 iters), loss = 1.11104
I0429 14:26:34.551614 25258 solver.cpp:258]     Train net output #0: loss = 1.11104 (* 1 = 1.11104 loss)
I0429 14:26:34.551647 25258 sgd_solver.cpp:112] Iteration 6700, lr = 0.01
I0429 14:26:40.215790 25258 solver.cpp:239] Iteration 6720 (3.53107 iter/s, 5.66401s/20 iters), loss = 1.08165
I0429 14:26:40.221259 25258 solver.cpp:258]     Train net output #0: loss = 1.08165 (* 1 = 1.08165 loss)
I0429 14:26:40.221287 25258 sgd_solver.cpp:112] Iteration 6720, lr = 0.01
I0429 14:26:46.018524 25258 solver.cpp:239] Iteration 6740 (3.45002 iter/s, 5.79706s/20 iters), loss = 1.10078
I0429 14:26:46.025898 25258 solver.cpp:258]     Train net output #0: loss = 1.10078 (* 1 = 1.10078 loss)
I0429 14:26:46.025956 25258 sgd_solver.cpp:112] Iteration 6740, lr = 0.01
I0429 14:26:49.635903 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_6750.caffemodel
I0429 14:27:18.558406 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_6750.solverstate
I0429 14:27:18.894791 25258 solver.cpp:351] Iteration 6750, Testing net (#0)
I0429 14:27:23.790288 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:27:31.193964 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.505
I0429 14:27:31.194025 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.743672
I0429 14:27:31.194034 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.881172
I0429 14:27:31.194066 25258 solver.cpp:418]     Test net output #3: loss = 1.1781 (* 1 = 1.1781 loss)
I0429 14:27:33.902739 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:27:35.382983 25258 solver.cpp:239] Iteration 6760 (0.405221 iter/s, 49.3557s/20 iters), loss = 1.10057
I0429 14:27:35.387962 25258 solver.cpp:258]     Train net output #0: loss = 1.10057 (* 1 = 1.10057 loss)
I0429 14:27:35.387993 25258 sgd_solver.cpp:112] Iteration 6760, lr = 0.01
I0429 14:27:42.748941 25258 solver.cpp:239] Iteration 6780 (2.71711 iter/s, 7.36076s/20 iters), loss = 1.21562
I0429 14:27:42.754717 25258 solver.cpp:258]     Train net output #0: loss = 1.21562 (* 1 = 1.21562 loss)
I0429 14:27:42.754777 25258 sgd_solver.cpp:112] Iteration 6780, lr = 0.01
I0429 14:27:48.770184 25258 solver.cpp:239] Iteration 6800 (3.32484 iter/s, 6.01532s/20 iters), loss = 1.0707
I0429 14:27:48.775174 25258 solver.cpp:258]     Train net output #0: loss = 1.0707 (* 1 = 1.0707 loss)
I0429 14:27:48.775205 25258 sgd_solver.cpp:112] Iteration 6800, lr = 0.01
I0429 14:27:55.971117 25258 solver.cpp:239] Iteration 6820 (2.77942 iter/s, 7.19574s/20 iters), loss = 1.26629
I0429 14:27:55.976596 25258 solver.cpp:258]     Train net output #0: loss = 1.26629 (* 1 = 1.26629 loss)
I0429 14:27:55.976639 25258 sgd_solver.cpp:112] Iteration 6820, lr = 0.01
I0429 14:28:02.879456 25258 solver.cpp:239] Iteration 6840 (2.89743 iter/s, 6.90267s/20 iters), loss = 1.26984
I0429 14:28:02.884418 25258 solver.cpp:258]     Train net output #0: loss = 1.26984 (* 1 = 1.26984 loss)
I0429 14:28:02.884446 25258 sgd_solver.cpp:112] Iteration 6840, lr = 0.01
I0429 14:28:09.571461 25258 solver.cpp:239] Iteration 6860 (2.99095 iter/s, 6.68684s/20 iters), loss = 1.07143
I0429 14:28:09.577288 25258 solver.cpp:258]     Train net output #0: loss = 1.07143 (* 1 = 1.07143 loss)
I0429 14:28:09.577384 25258 sgd_solver.cpp:112] Iteration 6860, lr = 0.01
I0429 14:28:15.916020 25258 solver.cpp:239] Iteration 6880 (3.15528 iter/s, 6.33858s/20 iters), loss = 1.09702
I0429 14:28:15.916110 25258 solver.cpp:258]     Train net output #0: loss = 1.09702 (* 1 = 1.09702 loss)
I0429 14:28:15.916127 25258 sgd_solver.cpp:112] Iteration 6880, lr = 0.01
I0429 14:28:18.514063 25258 solver.cpp:239] Iteration 6900 (7.69865 iter/s, 2.59786s/20 iters), loss = 1.12122
I0429 14:28:18.514142 25258 solver.cpp:258]     Train net output #0: loss = 1.12122 (* 1 = 1.12122 loss)
I0429 14:28:18.514158 25258 sgd_solver.cpp:112] Iteration 6900, lr = 0.01
I0429 14:28:23.191916 25258 blocking_queue.cpp:49] Waiting for data
I0429 14:28:26.490275 25258 solver.cpp:239] Iteration 6920 (2.50756 iter/s, 7.97588s/20 iters), loss = 1.13822
I0429 14:28:26.498461 25258 solver.cpp:258]     Train net output #0: loss = 1.13822 (* 1 = 1.13822 loss)
I0429 14:28:26.498512 25258 sgd_solver.cpp:112] Iteration 6920, lr = 0.01
I0429 14:28:32.727916 25258 solver.cpp:239] Iteration 6940 (3.21064 iter/s, 6.22929s/20 iters), loss = 1.22145
I0429 14:28:32.735299 25258 solver.cpp:258]     Train net output #0: loss = 1.22145 (* 1 = 1.22145 loss)
I0429 14:28:32.735373 25258 sgd_solver.cpp:112] Iteration 6940, lr = 0.01
I0429 14:28:39.941293 25258 solver.cpp:239] Iteration 6960 (2.77553 iter/s, 7.20583s/20 iters), loss = 1.05289
I0429 14:28:39.946524 25258 solver.cpp:258]     Train net output #0: loss = 1.05289 (* 1 = 1.05289 loss)
I0429 14:28:39.946557 25258 sgd_solver.cpp:112] Iteration 6960, lr = 0.01
I0429 14:28:45.988682 25258 solver.cpp:239] Iteration 6980 (3.31017 iter/s, 6.04199s/20 iters), loss = 1.08007
I0429 14:28:45.993584 25258 solver.cpp:258]     Train net output #0: loss = 1.08007 (* 1 = 1.08007 loss)
I0429 14:28:45.993635 25258 sgd_solver.cpp:112] Iteration 6980, lr = 0.01
I0429 14:28:52.143646 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_7000.caffemodel
I0429 14:29:30.867938 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_7000.solverstate
I0429 14:29:31.271241 25258 solver.cpp:351] Iteration 7000, Testing net (#0)
I0429 14:29:35.814949 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:29:41.363065 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.485781
I0429 14:29:41.363140 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.720391
I0429 14:29:41.363155 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.864531
I0429 14:29:41.363173 25258 solver.cpp:418]     Test net output #3: loss = 1.20276 (* 1 = 1.20276 loss)
I0429 14:29:41.483145 25258 solver.cpp:239] Iteration 7000 (0.360438 iter/s, 55.488s/20 iters), loss = 1.08688
I0429 14:29:41.489434 25258 solver.cpp:258]     Train net output #0: loss = 1.08688 (* 1 = 1.08688 loss)
I0429 14:29:41.489480 25258 sgd_solver.cpp:112] Iteration 7000, lr = 0.01
I0429 14:29:49.339548 25258 solver.cpp:239] Iteration 7020 (2.5478 iter/s, 7.84991s/20 iters), loss = 1.14322
I0429 14:29:49.345811 25258 solver.cpp:258]     Train net output #0: loss = 1.14322 (* 1 = 1.14322 loss)
I0429 14:29:49.345868 25258 sgd_solver.cpp:112] Iteration 7020, lr = 0.01
I0429 14:29:56.800220 25258 solver.cpp:239] Iteration 7040 (2.683 iter/s, 7.45434s/20 iters), loss = 1.03888
I0429 14:29:56.800304 25258 solver.cpp:258]     Train net output #0: loss = 1.03888 (* 1 = 1.03888 loss)
I0429 14:29:56.800320 25258 sgd_solver.cpp:112] Iteration 7040, lr = 0.01
I0429 14:30:02.584414 25258 solver.cpp:239] Iteration 7060 (3.45787 iter/s, 5.78391s/20 iters), loss = 1.05329
I0429 14:30:02.596006 25258 solver.cpp:258]     Train net output #0: loss = 1.05329 (* 1 = 1.05329 loss)
I0429 14:30:02.596057 25258 sgd_solver.cpp:112] Iteration 7060, lr = 0.01
I0429 14:30:09.123618 25258 solver.cpp:239] Iteration 7080 (3.06399 iter/s, 6.52744s/20 iters), loss = 1.17944
I0429 14:30:09.128718 25258 solver.cpp:258]     Train net output #0: loss = 1.17944 (* 1 = 1.17944 loss)
I0429 14:30:09.128770 25258 sgd_solver.cpp:112] Iteration 7080, lr = 0.01
I0429 14:30:15.730235 25258 solver.cpp:239] Iteration 7100 (3.02969 iter/s, 6.60134s/20 iters), loss = 1.12004
I0429 14:30:15.735277 25258 solver.cpp:258]     Train net output #0: loss = 1.12004 (* 1 = 1.12004 loss)
I0429 14:30:15.735323 25258 sgd_solver.cpp:112] Iteration 7100, lr = 0.01
I0429 14:30:19.937491 25258 solver.cpp:239] Iteration 7120 (4.75951 iter/s, 4.20211s/20 iters), loss = 1.26408
I0429 14:30:19.946849 25258 solver.cpp:258]     Train net output #0: loss = 1.26408 (* 1 = 1.26408 loss)
I0429 14:30:19.946907 25258 sgd_solver.cpp:112] Iteration 7120, lr = 0.01
I0429 14:30:27.044355 25258 solver.cpp:239] Iteration 7140 (2.81796 iter/s, 7.09732s/20 iters), loss = 1.07465
I0429 14:30:27.049813 25258 solver.cpp:258]     Train net output #0: loss = 1.07465 (* 1 = 1.07465 loss)
I0429 14:30:27.049854 25258 sgd_solver.cpp:112] Iteration 7140, lr = 0.01
I0429 14:30:34.033856 25258 solver.cpp:239] Iteration 7160 (2.86375 iter/s, 6.98386s/20 iters), loss = 1.14609
I0429 14:30:34.038895 25258 solver.cpp:258]     Train net output #0: loss = 1.14609 (* 1 = 1.14609 loss)
I0429 14:30:34.038947 25258 sgd_solver.cpp:112] Iteration 7160, lr = 0.01
I0429 14:30:39.928248 25258 solver.cpp:239] Iteration 7180 (3.39605 iter/s, 5.88919s/20 iters), loss = 1.08578
I0429 14:30:39.933351 25258 solver.cpp:258]     Train net output #0: loss = 1.08578 (* 1 = 1.08578 loss)
I0429 14:30:39.933399 25258 sgd_solver.cpp:112] Iteration 7180, lr = 0.01
I0429 14:30:46.362865 25258 solver.cpp:239] Iteration 7200 (3.11074 iter/s, 6.42934s/20 iters), loss = 1.31267
I0429 14:30:46.372615 25258 solver.cpp:258]     Train net output #0: loss = 1.31267 (* 1 = 1.31267 loss)
I0429 14:30:46.372720 25258 sgd_solver.cpp:112] Iteration 7200, lr = 0.01
I0429 14:30:51.768921 25258 solver.cpp:239] Iteration 7220 (3.7063 iter/s, 5.39622s/20 iters), loss = 1.15104
I0429 14:30:51.769515 25258 solver.cpp:258]     Train net output #0: loss = 1.15104 (* 1 = 1.15104 loss)
I0429 14:30:51.769536 25258 sgd_solver.cpp:112] Iteration 7220, lr = 0.01
I0429 14:30:58.186888 25258 solver.cpp:239] Iteration 7240 (3.11665 iter/s, 6.41715s/20 iters), loss = 0.983798
I0429 14:30:58.192277 25258 solver.cpp:258]     Train net output #0: loss = 0.983798 (* 1 = 0.983798 loss)
I0429 14:30:58.192356 25258 sgd_solver.cpp:112] Iteration 7240, lr = 0.01
I0429 14:31:00.074002 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_7250.caffemodel
I0429 14:31:37.951751 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_7250.solverstate
I0429 14:31:38.366400 25258 solver.cpp:351] Iteration 7250, Testing net (#0)
I0429 14:31:42.056747 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:31:49.444054 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.499922
I0429 14:31:49.444111 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.7425
I0429 14:31:49.444123 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.878359
I0429 14:31:49.444134 25258 solver.cpp:418]     Test net output #3: loss = 1.16788 (* 1 = 1.16788 loss)
I0429 14:31:53.771654 25258 solver.cpp:239] Iteration 7260 (0.359856 iter/s, 55.5778s/20 iters), loss = 1.24223
I0429 14:31:53.778331 25258 solver.cpp:258]     Train net output #0: loss = 1.24223 (* 1 = 1.24223 loss)
I0429 14:31:53.778424 25258 sgd_solver.cpp:112] Iteration 7260, lr = 0.01
I0429 14:31:57.765661 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:31:59.259093 25258 solver.cpp:239] Iteration 7280 (3.64919 iter/s, 5.48067s/20 iters), loss = 1.13612
I0429 14:31:59.264044 25258 solver.cpp:258]     Train net output #0: loss = 1.13612 (* 1 = 1.13612 loss)
I0429 14:31:59.264078 25258 sgd_solver.cpp:112] Iteration 7280, lr = 0.01
I0429 14:32:05.868898 25258 solver.cpp:239] Iteration 7300 (3.02817 iter/s, 6.60466s/20 iters), loss = 1.25302
I0429 14:32:05.875033 25258 solver.cpp:258]     Train net output #0: loss = 1.25302 (* 1 = 1.25302 loss)
I0429 14:32:05.875079 25258 sgd_solver.cpp:112] Iteration 7300, lr = 0.01
I0429 14:32:13.072087 25258 solver.cpp:239] Iteration 7320 (2.78047 iter/s, 7.19303s/20 iters), loss = 1.024
I0429 14:32:13.073498 25258 solver.cpp:258]     Train net output #0: loss = 1.024 (* 1 = 1.024 loss)
I0429 14:32:13.073523 25258 sgd_solver.cpp:112] Iteration 7320, lr = 0.01
I0429 14:32:19.299492 25258 solver.cpp:239] Iteration 7340 (3.21243 iter/s, 6.22582s/20 iters), loss = 1.09786
I0429 14:32:19.305052 25258 solver.cpp:258]     Train net output #0: loss = 1.09786 (* 1 = 1.09786 loss)
I0429 14:32:19.305109 25258 sgd_solver.cpp:112] Iteration 7340, lr = 0.01
I0429 14:32:25.993091 25258 solver.cpp:239] Iteration 7360 (2.99049 iter/s, 6.68788s/20 iters), loss = 1.25022
I0429 14:32:25.998270 25258 solver.cpp:258]     Train net output #0: loss = 1.25022 (* 1 = 1.25022 loss)
I0429 14:32:25.998296 25258 sgd_solver.cpp:112] Iteration 7360, lr = 0.01
I0429 14:32:32.071640 25258 solver.cpp:239] Iteration 7380 (3.29316 iter/s, 6.0732s/20 iters), loss = 1.04208
I0429 14:32:32.076907 25258 solver.cpp:258]     Train net output #0: loss = 1.04208 (* 1 = 1.04208 loss)
I0429 14:32:32.076943 25258 sgd_solver.cpp:112] Iteration 7380, lr = 0.01
I0429 14:32:38.734853 25258 solver.cpp:239] Iteration 7400 (3.00401 iter/s, 6.65777s/20 iters), loss = 1.06849
I0429 14:32:38.734906 25258 solver.cpp:258]     Train net output #0: loss = 1.06849 (* 1 = 1.06849 loss)
I0429 14:32:38.734920 25258 sgd_solver.cpp:112] Iteration 7400, lr = 0.01
I0429 14:32:44.532944 25258 solver.cpp:239] Iteration 7420 (3.44955 iter/s, 5.79785s/20 iters), loss = 1.1006
I0429 14:32:44.537940 25258 solver.cpp:258]     Train net output #0: loss = 1.1006 (* 1 = 1.1006 loss)
I0429 14:32:44.537971 25258 sgd_solver.cpp:112] Iteration 7420, lr = 0.01
I0429 14:32:51.290068 25258 solver.cpp:239] Iteration 7440 (2.96411 iter/s, 6.7474s/20 iters), loss = 0.95811
I0429 14:32:51.290591 25258 solver.cpp:258]     Train net output #0: loss = 0.95811 (* 1 = 0.95811 loss)
I0429 14:32:51.290619 25258 sgd_solver.cpp:112] Iteration 7440, lr = 0.01
I0429 14:32:58.337764 25258 solver.cpp:239] Iteration 7460 (2.83811 iter/s, 7.04693s/20 iters), loss = 1.04843
I0429 14:32:58.343561 25258 solver.cpp:258]     Train net output #0: loss = 1.04843 (* 1 = 1.04843 loss)
I0429 14:32:58.343647 25258 sgd_solver.cpp:112] Iteration 7460, lr = 0.01
I0429 14:33:03.928647 25258 solver.cpp:239] Iteration 7480 (3.58106 iter/s, 5.58493s/20 iters), loss = 1.04226
I0429 14:33:03.939985 25258 solver.cpp:258]     Train net output #0: loss = 1.04226 (* 1 = 1.04226 loss)
I0429 14:33:03.940043 25258 sgd_solver.cpp:112] Iteration 7480, lr = 0.01
I0429 14:33:09.331236 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_7500.caffemodel
I0429 14:33:45.621618 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_7500.solverstate
I0429 14:33:46.004616 25258 solver.cpp:351] Iteration 7500, Testing net (#0)
I0429 14:33:50.379971 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:33:58.118839 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.536953
I0429 14:33:58.118892 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.760391
I0429 14:33:58.118899 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.888828
I0429 14:33:58.118911 25258 solver.cpp:418]     Test net output #3: loss = 1.11363 (* 1 = 1.11363 loss)
I0429 14:33:58.262284 25258 solver.cpp:239] Iteration 7500 (0.368183 iter/s, 54.3208s/20 iters), loss = 1.13771
I0429 14:33:58.262337 25258 solver.cpp:258]     Train net output #0: loss = 1.13771 (* 1 = 1.13771 loss)
I0429 14:33:58.262347 25258 sgd_solver.cpp:112] Iteration 7500, lr = 0.01
I0429 14:34:04.773923 25258 solver.cpp:239] Iteration 7520 (3.07155 iter/s, 6.51138s/20 iters), loss = 0.951872
I0429 14:34:04.779372 25258 solver.cpp:258]     Train net output #0: loss = 0.951872 (* 1 = 0.951872 loss)
I0429 14:34:04.779412 25258 sgd_solver.cpp:112] Iteration 7520, lr = 0.01
I0429 14:34:07.888164 25258 solver.cpp:239] Iteration 7540 (6.43353 iter/s, 3.10871s/20 iters), loss = 1.14446
I0429 14:34:07.897776 25258 solver.cpp:258]     Train net output #0: loss = 1.14446 (* 1 = 1.14446 loss)
I0429 14:34:07.897814 25258 sgd_solver.cpp:112] Iteration 7540, lr = 0.01
I0429 14:34:15.376539 25258 solver.cpp:239] Iteration 7560 (2.67431 iter/s, 7.47855s/20 iters), loss = 1.12095
I0429 14:34:15.385803 25258 solver.cpp:258]     Train net output #0: loss = 1.12095 (* 1 = 1.12095 loss)
I0429 14:34:15.385843 25258 sgd_solver.cpp:112] Iteration 7560, lr = 0.01
I0429 14:34:22.916666 25258 solver.cpp:239] Iteration 7580 (2.65581 iter/s, 7.53067s/20 iters), loss = 0.980863
I0429 14:34:22.921787 25258 solver.cpp:258]     Train net output #0: loss = 0.980863 (* 1 = 0.980863 loss)
I0429 14:34:22.921815 25258 sgd_solver.cpp:112] Iteration 7580, lr = 0.01
I0429 14:34:28.041569 25258 solver.cpp:239] Iteration 7600 (3.90653 iter/s, 5.11964s/20 iters), loss = 1.07677
I0429 14:34:28.041652 25258 solver.cpp:258]     Train net output #0: loss = 1.07677 (* 1 = 1.07677 loss)
I0429 14:34:28.041668 25258 sgd_solver.cpp:112] Iteration 7600, lr = 0.01
I0429 14:34:33.818218 25258 solver.cpp:239] Iteration 7620 (3.46237 iter/s, 5.77638s/20 iters), loss = 1.17519
I0429 14:34:33.823257 25258 solver.cpp:258]     Train net output #0: loss = 1.17519 (* 1 = 1.17519 loss)
I0429 14:34:33.823292 25258 sgd_solver.cpp:112] Iteration 7620, lr = 0.01
I0429 14:34:38.139708 25258 solver.cpp:239] Iteration 7640 (4.63357 iter/s, 4.31633s/20 iters), loss = 1.1185
I0429 14:34:38.149062 25258 solver.cpp:258]     Train net output #0: loss = 1.1185 (* 1 = 1.1185 loss)
I0429 14:34:38.149106 25258 sgd_solver.cpp:112] Iteration 7640, lr = 0.01
I0429 14:34:45.667779 25258 solver.cpp:239] Iteration 7660 (2.6601 iter/s, 7.51851s/20 iters), loss = 1.12399
I0429 14:34:45.672940 25258 solver.cpp:258]     Train net output #0: loss = 1.12399 (* 1 = 1.12399 loss)
I0429 14:34:45.672971 25258 sgd_solver.cpp:112] Iteration 7660, lr = 0.01
I0429 14:34:52.227689 25258 solver.cpp:239] Iteration 7680 (3.05132 iter/s, 6.55454s/20 iters), loss = 0.911138
I0429 14:34:52.233189 25258 solver.cpp:258]     Train net output #0: loss = 0.911138 (* 1 = 0.911138 loss)
I0429 14:34:52.233228 25258 sgd_solver.cpp:112] Iteration 7680, lr = 0.01
I0429 14:34:58.784822 25258 solver.cpp:239] Iteration 7700 (3.05276 iter/s, 6.55145s/20 iters), loss = 0.945536
I0429 14:34:58.791790 25258 solver.cpp:258]     Train net output #0: loss = 0.945536 (* 1 = 0.945536 loss)
I0429 14:34:58.791810 25258 sgd_solver.cpp:112] Iteration 7700, lr = 0.01
I0429 14:35:04.421468 25258 solver.cpp:239] Iteration 7720 (3.5527 iter/s, 5.62952s/20 iters), loss = 1.14551
I0429 14:35:04.426926 25258 solver.cpp:258]     Train net output #0: loss = 1.14551 (* 1 = 1.14551 loss)
I0429 14:35:04.426970 25258 sgd_solver.cpp:112] Iteration 7720, lr = 0.01
I0429 14:35:11.499348 25258 solver.cpp:239] Iteration 7740 (2.82796 iter/s, 7.07224s/20 iters), loss = 1.11054
I0429 14:35:11.504686 25258 solver.cpp:258]     Train net output #0: loss = 1.11054 (* 1 = 1.11054 loss)
I0429 14:35:11.504745 25258 sgd_solver.cpp:112] Iteration 7740, lr = 0.01
I0429 14:35:13.722352 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_7750.caffemodel
I0429 14:35:56.914104 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_7750.solverstate
I0429 14:35:57.313091 25258 solver.cpp:351] Iteration 7750, Testing net (#0)
I0429 14:36:02.256289 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:36:08.758319 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.525078
I0429 14:36:08.758376 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.752891
I0429 14:36:08.758391 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.881484
I0429 14:36:08.758404 25258 solver.cpp:418]     Test net output #3: loss = 1.1332 (* 1 = 1.1332 loss)
I0429 14:36:11.892113 25258 solver.cpp:239] Iteration 7760 (0.331204 iter/s, 60.3857s/20 iters), loss = 1.03674
I0429 14:36:11.897781 25258 solver.cpp:258]     Train net output #0: loss = 1.03674 (* 1 = 1.03674 loss)
I0429 14:36:11.897814 25258 sgd_solver.cpp:112] Iteration 7760, lr = 0.01
I0429 14:36:17.989941 25258 solver.cpp:239] Iteration 7780 (3.28303 iter/s, 6.09194s/20 iters), loss = 1.07713
I0429 14:36:17.995419 25258 solver.cpp:258]     Train net output #0: loss = 1.07713 (* 1 = 1.07713 loss)
I0429 14:36:17.995463 25258 sgd_solver.cpp:112] Iteration 7780, lr = 0.01
I0429 14:36:23.490156 25258 blocking_queue.cpp:49] Waiting for data
I0429 14:36:24.258514 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:36:25.462419 25258 solver.cpp:239] Iteration 7800 (2.67853 iter/s, 7.46679s/20 iters), loss = 1.20605
I0429 14:36:25.467228 25258 solver.cpp:258]     Train net output #0: loss = 1.20605 (* 1 = 1.20605 loss)
I0429 14:36:25.467262 25258 sgd_solver.cpp:112] Iteration 7800, lr = 0.01
I0429 14:36:31.080272 25258 solver.cpp:239] Iteration 7820 (3.56323 iter/s, 5.61288s/20 iters), loss = 1.33272
I0429 14:36:31.081346 25258 solver.cpp:258]     Train net output #0: loss = 1.33272 (* 1 = 1.33272 loss)
I0429 14:36:31.081358 25258 sgd_solver.cpp:112] Iteration 7820, lr = 0.01
I0429 14:36:39.012099 25258 solver.cpp:239] Iteration 7840 (2.52192 iter/s, 7.93048s/20 iters), loss = 0.936261
I0429 14:36:39.021683 25258 solver.cpp:258]     Train net output #0: loss = 0.936261 (* 1 = 0.936261 loss)
I0429 14:36:39.021942 25258 sgd_solver.cpp:112] Iteration 7840, lr = 0.01
I0429 14:36:45.347831 25258 solver.cpp:239] Iteration 7860 (3.16153 iter/s, 6.32605s/20 iters), loss = 1.02529
I0429 14:36:45.347908 25258 solver.cpp:258]     Train net output #0: loss = 1.02529 (* 1 = 1.02529 loss)
I0429 14:36:45.347928 25258 sgd_solver.cpp:112] Iteration 7860, lr = 0.01
I0429 14:36:51.417951 25258 solver.cpp:239] Iteration 7880 (3.29497 iter/s, 6.06986s/20 iters), loss = 1.09157
I0429 14:36:51.422940 25258 solver.cpp:258]     Train net output #0: loss = 1.09157 (* 1 = 1.09157 loss)
I0429 14:36:51.422969 25258 sgd_solver.cpp:112] Iteration 7880, lr = 0.01
I0429 14:36:57.944866 25258 solver.cpp:239] Iteration 7900 (3.06667 iter/s, 6.52173s/20 iters), loss = 1.13338
I0429 14:36:57.951823 25258 solver.cpp:258]     Train net output #0: loss = 1.13338 (* 1 = 1.13338 loss)
I0429 14:36:57.951860 25258 sgd_solver.cpp:112] Iteration 7900, lr = 0.01
I0429 14:37:03.685792 25258 solver.cpp:239] Iteration 7920 (3.48812 iter/s, 5.73375s/20 iters), loss = 1.10356
I0429 14:37:03.691905 25258 solver.cpp:258]     Train net output #0: loss = 1.10356 (* 1 = 1.10356 loss)
I0429 14:37:03.691947 25258 sgd_solver.cpp:112] Iteration 7920, lr = 0.01
I0429 14:37:10.795763 25258 solver.cpp:239] Iteration 7940 (2.81544 iter/s, 7.10368s/20 iters), loss = 1.14583
I0429 14:37:10.805101 25258 solver.cpp:258]     Train net output #0: loss = 1.14583 (* 1 = 1.14583 loss)
I0429 14:37:10.805145 25258 sgd_solver.cpp:112] Iteration 7940, lr = 0.01
I0429 14:37:17.232537 25258 solver.cpp:239] Iteration 7960 (3.11175 iter/s, 6.42725s/20 iters), loss = 0.954052
I0429 14:37:17.237421 25258 solver.cpp:258]     Train net output #0: loss = 0.954052 (* 1 = 0.954052 loss)
I0429 14:37:17.237457 25258 sgd_solver.cpp:112] Iteration 7960, lr = 0.01
I0429 14:37:23.615146 25258 solver.cpp:239] Iteration 7980 (3.136 iter/s, 6.37754s/20 iters), loss = 0.957182
I0429 14:37:23.615219 25258 solver.cpp:258]     Train net output #0: loss = 0.957182 (* 1 = 0.957182 loss)
I0429 14:37:23.615238 25258 sgd_solver.cpp:112] Iteration 7980, lr = 0.01
I0429 14:37:29.343336 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_8000.caffemodel
I0429 14:38:17.999259 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_8000.solverstate
I0429 14:38:18.376338 25258 solver.cpp:351] Iteration 8000, Testing net (#0)
I0429 14:38:22.327639 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:38:28.002851 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.520234
I0429 14:38:28.002915 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.752656
I0429 14:38:28.002923 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.886094
I0429 14:38:28.002934 25258 solver.cpp:418]     Test net output #3: loss = 1.13118 (* 1 = 1.13118 loss)
I0429 14:38:28.124312 25258 solver.cpp:239] Iteration 8000 (0.310043 iter/s, 64.5073s/20 iters), loss = 1.08052
I0429 14:38:28.124420 25258 solver.cpp:258]     Train net output #0: loss = 1.08052 (* 1 = 1.08052 loss)
I0429 14:38:28.124439 25258 sgd_solver.cpp:112] Iteration 8000, lr = 0.01
I0429 14:38:34.235312 25258 solver.cpp:239] Iteration 8020 (3.27296 iter/s, 6.11068s/20 iters), loss = 1.05664
I0429 14:38:34.242836 25258 solver.cpp:258]     Train net output #0: loss = 1.05664 (* 1 = 1.05664 loss)
I0429 14:38:34.242898 25258 sgd_solver.cpp:112] Iteration 8020, lr = 0.01
I0429 14:38:38.631458 25258 solver.cpp:239] Iteration 8040 (4.55732 iter/s, 4.38855s/20 iters), loss = 0.95448
I0429 14:38:38.631546 25258 solver.cpp:258]     Train net output #0: loss = 0.95448 (* 1 = 0.95448 loss)
I0429 14:38:38.631567 25258 sgd_solver.cpp:112] Iteration 8040, lr = 0.01
I0429 14:38:45.385783 25258 solver.cpp:239] Iteration 8060 (2.9612 iter/s, 6.75403s/20 iters), loss = 1.0772
I0429 14:38:45.391002 25258 solver.cpp:258]     Train net output #0: loss = 1.0772 (* 1 = 1.0772 loss)
I0429 14:38:45.391047 25258 sgd_solver.cpp:112] Iteration 8060, lr = 0.01
I0429 14:38:52.138007 25258 solver.cpp:239] Iteration 8080 (2.96437 iter/s, 6.74681s/20 iters), loss = 1.12091
I0429 14:38:52.138512 25258 solver.cpp:258]     Train net output #0: loss = 1.12091 (* 1 = 1.12091 loss)
I0429 14:38:52.138530 25258 sgd_solver.cpp:112] Iteration 8080, lr = 0.01
I0429 14:38:55.332702 25258 solver.cpp:239] Iteration 8100 (6.26157 iter/s, 3.19409s/20 iters), loss = 1.01027
I0429 14:38:55.337682 25258 solver.cpp:258]     Train net output #0: loss = 1.01027 (* 1 = 1.01027 loss)
I0429 14:38:55.337805 25258 sgd_solver.cpp:112] Iteration 8100, lr = 0.01
I0429 14:39:03.571051 25258 solver.cpp:239] Iteration 8120 (2.42921 iter/s, 8.23313s/20 iters), loss = 1.04795
I0429 14:39:03.575908 25258 solver.cpp:258]     Train net output #0: loss = 1.04795 (* 1 = 1.04795 loss)
I0429 14:39:03.575950 25258 sgd_solver.cpp:112] Iteration 8120, lr = 0.01
I0429 14:39:10.477437 25258 solver.cpp:239] Iteration 8140 (2.89799 iter/s, 6.90133s/20 iters), loss = 0.985042
I0429 14:39:10.482656 25258 solver.cpp:258]     Train net output #0: loss = 0.985042 (* 1 = 0.985042 loss)
I0429 14:39:10.482692 25258 sgd_solver.cpp:112] Iteration 8140, lr = 0.01
I0429 14:39:16.592823 25258 solver.cpp:239] Iteration 8160 (3.27332 iter/s, 6.11s/20 iters), loss = 1.15133
I0429 14:39:16.597903 25258 solver.cpp:258]     Train net output #0: loss = 1.15133 (* 1 = 1.15133 loss)
I0429 14:39:16.597934 25258 sgd_solver.cpp:112] Iteration 8160, lr = 0.01
I0429 14:39:22.068300 25258 solver.cpp:239] Iteration 8180 (3.65615 iter/s, 5.47024s/20 iters), loss = 1.19199
I0429 14:39:22.074991 25258 solver.cpp:258]     Train net output #0: loss = 1.19199 (* 1 = 1.19199 loss)
I0429 14:39:22.075038 25258 sgd_solver.cpp:112] Iteration 8180, lr = 0.01
I0429 14:39:30.003533 25258 solver.cpp:239] Iteration 8200 (2.52259 iter/s, 7.92835s/20 iters), loss = 1.03962
I0429 14:39:30.008796 25258 solver.cpp:258]     Train net output #0: loss = 1.03962 (* 1 = 1.03962 loss)
I0429 14:39:30.008829 25258 sgd_solver.cpp:112] Iteration 8200, lr = 0.01
I0429 14:39:34.890725 25258 solver.cpp:239] Iteration 8220 (4.09686 iter/s, 4.88178s/20 iters), loss = 1.12585
I0429 14:39:34.895725 25258 solver.cpp:258]     Train net output #0: loss = 1.12585 (* 1 = 1.12585 loss)
I0429 14:39:34.895752 25258 sgd_solver.cpp:112] Iteration 8220, lr = 0.01
I0429 14:39:41.784761 25258 solver.cpp:239] Iteration 8240 (2.90325 iter/s, 6.88883s/20 iters), loss = 1.13126
I0429 14:39:41.789855 25258 solver.cpp:258]     Train net output #0: loss = 1.13126 (* 1 = 1.13126 loss)
I0429 14:39:41.789903 25258 sgd_solver.cpp:112] Iteration 8240, lr = 0.01
I0429 14:39:44.461199 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_8250.caffemodel
I0429 14:40:42.152918 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_8250.solverstate
I0429 14:40:42.513965 25258 solver.cpp:351] Iteration 8250, Testing net (#0)
I0429 14:40:45.717190 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:40:48.902851 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.547031
I0429 14:40:48.902930 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.774531
I0429 14:40:48.902943 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.896094
I0429 14:40:48.902956 25258 solver.cpp:418]     Test net output #3: loss = 1.08162 (* 1 = 1.08162 loss)
I0429 14:40:51.081149 25258 solver.cpp:239] Iteration 8260 (0.288645 iter/s, 69.2893s/20 iters), loss = 0.978578
I0429 14:40:51.087990 25258 solver.cpp:258]     Train net output #0: loss = 0.978578 (* 1 = 0.978578 loss)
I0429 14:40:51.088091 25258 sgd_solver.cpp:112] Iteration 8260, lr = 0.01
I0429 14:40:55.501097 25258 solver.cpp:239] Iteration 8280 (4.53204 iter/s, 4.41303s/20 iters), loss = 1.01789
I0429 14:40:55.509028 25258 solver.cpp:258]     Train net output #0: loss = 1.01789 (* 1 = 1.01789 loss)
I0429 14:40:55.509130 25258 sgd_solver.cpp:112] Iteration 8280, lr = 0.01
I0429 14:41:01.183279 25258 solver.cpp:239] Iteration 8300 (3.52477 iter/s, 5.67413s/20 iters), loss = 1.13158
I0429 14:41:01.183352 25258 solver.cpp:258]     Train net output #0: loss = 1.13158 (* 1 = 1.13158 loss)
I0429 14:41:01.183367 25258 sgd_solver.cpp:112] Iteration 8300, lr = 0.01
I0429 14:41:05.717398 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:41:06.944227 25258 solver.cpp:239] Iteration 8320 (3.47181 iter/s, 5.76069s/20 iters), loss = 1.07826
I0429 14:41:06.949479 25258 solver.cpp:258]     Train net output #0: loss = 1.07826 (* 1 = 1.07826 loss)
I0429 14:41:06.949527 25258 sgd_solver.cpp:112] Iteration 8320, lr = 0.01
I0429 14:41:12.629745 25258 solver.cpp:239] Iteration 8340 (3.52108 iter/s, 5.68007s/20 iters), loss = 1.01141
I0429 14:41:12.645911 25258 solver.cpp:258]     Train net output #0: loss = 1.01141 (* 1 = 1.01141 loss)
I0429 14:41:12.645936 25258 sgd_solver.cpp:112] Iteration 8340, lr = 0.01
I0429 14:41:19.223726 25258 solver.cpp:239] Iteration 8360 (3.04061 iter/s, 6.57763s/20 iters), loss = 0.97006
I0429 14:41:19.228972 25258 solver.cpp:258]     Train net output #0: loss = 0.97006 (* 1 = 0.97006 loss)
I0429 14:41:19.229027 25258 sgd_solver.cpp:112] Iteration 8360, lr = 0.01
I0429 14:41:25.042568 25258 solver.cpp:239] Iteration 8380 (3.44031 iter/s, 5.81342s/20 iters), loss = 0.98664
I0429 14:41:25.047948 25258 solver.cpp:258]     Train net output #0: loss = 0.98664 (* 1 = 0.98664 loss)
I0429 14:41:25.048008 25258 sgd_solver.cpp:112] Iteration 8380, lr = 0.01
I0429 14:41:31.772506 25258 solver.cpp:239] Iteration 8400 (2.97445 iter/s, 6.72394s/20 iters), loss = 1.12391
I0429 14:41:31.772593 25258 solver.cpp:258]     Train net output #0: loss = 1.12391 (* 1 = 1.12391 loss)
I0429 14:41:31.773005 25258 sgd_solver.cpp:112] Iteration 8400, lr = 0.01
I0429 14:41:38.517870 25258 solver.cpp:239] Iteration 8420 (2.96513 iter/s, 6.74506s/20 iters), loss = 1.09444
I0429 14:41:38.517964 25258 solver.cpp:258]     Train net output #0: loss = 1.09444 (* 1 = 1.09444 loss)
I0429 14:41:38.517979 25258 sgd_solver.cpp:112] Iteration 8420, lr = 0.01
I0429 14:41:45.407198 25258 solver.cpp:239] Iteration 8440 (2.90319 iter/s, 6.88899s/20 iters), loss = 0.884191
I0429 14:41:45.414548 25258 solver.cpp:258]     Train net output #0: loss = 0.884191 (* 1 = 0.884191 loss)
I0429 14:41:45.414602 25258 sgd_solver.cpp:112] Iteration 8440, lr = 0.01
I0429 14:41:52.188026 25258 solver.cpp:239] Iteration 8460 (2.95277 iter/s, 6.77331s/20 iters), loss = 0.950163
I0429 14:41:52.193835 25258 solver.cpp:258]     Train net output #0: loss = 0.950163 (* 1 = 0.950163 loss)
I0429 14:41:52.193863 25258 sgd_solver.cpp:112] Iteration 8460, lr = 0.01
I0429 14:41:59.238427 25258 solver.cpp:239] Iteration 8480 (2.83914 iter/s, 7.04437s/20 iters), loss = 1.00239
I0429 14:41:59.243845 25258 solver.cpp:258]     Train net output #0: loss = 1.00239 (* 1 = 1.00239 loss)
I0429 14:41:59.243901 25258 sgd_solver.cpp:112] Iteration 8480, lr = 0.01
I0429 14:42:04.586951 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_8500.caffemodel
I0429 14:42:49.174227 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_8500.solverstate
I0429 14:42:49.600113 25258 solver.cpp:351] Iteration 8500, Testing net (#0)
I0429 14:42:52.969938 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:42:57.651780 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.548281
I0429 14:42:57.651844 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.774844
I0429 14:42:57.651850 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.894375
I0429 14:42:57.651862 25258 solver.cpp:418]     Test net output #3: loss = 1.07329 (* 1 = 1.07329 loss)
I0429 14:42:57.745570 25258 solver.cpp:239] Iteration 8500 (0.34188 iter/s, 58.5001s/20 iters), loss = 1.13875
I0429 14:42:57.745656 25258 solver.cpp:258]     Train net output #0: loss = 1.13875 (* 1 = 1.13875 loss)
I0429 14:42:57.745679 25258 sgd_solver.cpp:112] Iteration 8500, lr = 0.01
I0429 14:43:02.213071 25258 solver.cpp:239] Iteration 8520 (4.47701 iter/s, 4.46727s/20 iters), loss = 1.01908
I0429 14:43:02.213153 25258 solver.cpp:258]     Train net output #0: loss = 1.01908 (* 1 = 1.01908 loss)
I0429 14:43:02.213171 25258 sgd_solver.cpp:112] Iteration 8520, lr = 0.01
I0429 14:43:08.458170 25258 solver.cpp:239] Iteration 8540 (3.20267 iter/s, 6.2448s/20 iters), loss = 1.07075
I0429 14:43:08.466590 25258 solver.cpp:258]     Train net output #0: loss = 1.07075 (* 1 = 1.07075 loss)
I0429 14:43:08.466645 25258 sgd_solver.cpp:112] Iteration 8540, lr = 0.01
I0429 14:43:15.311564 25258 solver.cpp:239] Iteration 8560 (2.92193 iter/s, 6.84478s/20 iters), loss = 0.78667
I0429 14:43:15.318014 25258 solver.cpp:258]     Train net output #0: loss = 0.78667 (* 1 = 0.78667 loss)
I0429 14:43:15.318114 25258 sgd_solver.cpp:112] Iteration 8560, lr = 0.01
I0429 14:43:21.676578 25258 solver.cpp:239] Iteration 8580 (3.14542 iter/s, 6.35846s/20 iters), loss = 1.04326
I0429 14:43:21.682401 25258 solver.cpp:258]     Train net output #0: loss = 1.04326 (* 1 = 1.04326 loss)
I0429 14:43:21.682423 25258 sgd_solver.cpp:112] Iteration 8580, lr = 0.01
I0429 14:43:27.961158 25258 solver.cpp:239] Iteration 8600 (3.18546 iter/s, 6.27853s/20 iters), loss = 1.06606
I0429 14:43:27.970432 25258 solver.cpp:258]     Train net output #0: loss = 1.06606 (* 1 = 1.06606 loss)
I0429 14:43:27.970486 25258 sgd_solver.cpp:112] Iteration 8600, lr = 0.01
I0429 14:43:33.866262 25258 solver.cpp:239] Iteration 8620 (3.39232 iter/s, 5.89568s/20 iters), loss = 0.951712
I0429 14:43:33.866361 25258 solver.cpp:258]     Train net output #0: loss = 0.951712 (* 1 = 0.951712 loss)
I0429 14:43:33.866379 25258 sgd_solver.cpp:112] Iteration 8620, lr = 0.01
I0429 14:43:39.994602 25258 solver.cpp:239] Iteration 8640 (3.26368 iter/s, 6.12804s/20 iters), loss = 0.972734
I0429 14:43:39.999727 25258 solver.cpp:258]     Train net output #0: loss = 0.972734 (* 1 = 0.972734 loss)
I0429 14:43:39.999765 25258 sgd_solver.cpp:112] Iteration 8640, lr = 0.01
I0429 14:43:47.076512 25258 blocking_queue.cpp:49] Waiting for data
I0429 14:43:47.647562 25258 solver.cpp:239] Iteration 8660 (2.61519 iter/s, 7.64762s/20 iters), loss = 1.09648
I0429 14:43:47.653219 25258 solver.cpp:258]     Train net output #0: loss = 1.09648 (* 1 = 1.09648 loss)
I0429 14:43:47.653256 25258 sgd_solver.cpp:112] Iteration 8660, lr = 0.01
I0429 14:43:54.071676 25258 solver.cpp:239] Iteration 8680 (3.1161 iter/s, 6.41827s/20 iters), loss = 0.981075
I0429 14:43:54.076781 25258 solver.cpp:258]     Train net output #0: loss = 0.981075 (* 1 = 0.981075 loss)
I0429 14:43:54.076812 25258 sgd_solver.cpp:112] Iteration 8680, lr = 0.01
I0429 14:44:00.568254 25258 solver.cpp:239] Iteration 8700 (3.08105 iter/s, 6.49129s/20 iters), loss = 1.04156
I0429 14:44:00.573340 25258 solver.cpp:258]     Train net output #0: loss = 1.04156 (* 1 = 1.04156 loss)
I0429 14:44:00.573385 25258 sgd_solver.cpp:112] Iteration 8700, lr = 0.01
I0429 14:44:08.458926 25258 solver.cpp:239] Iteration 8720 (2.53634 iter/s, 7.88536s/20 iters), loss = 0.918801
I0429 14:44:08.464287 25258 solver.cpp:258]     Train net output #0: loss = 0.918801 (* 1 = 0.918801 loss)
I0429 14:44:08.464323 25258 sgd_solver.cpp:112] Iteration 8720, lr = 0.01
I0429 14:44:15.646507 25258 solver.cpp:239] Iteration 8740 (2.78473 iter/s, 7.18202s/20 iters), loss = 0.922721
I0429 14:44:15.651857 25258 solver.cpp:258]     Train net output #0: loss = 0.922721 (* 1 = 0.922721 loss)
I0429 14:44:15.651911 25258 sgd_solver.cpp:112] Iteration 8740, lr = 0.01
I0429 14:44:17.755635 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_8750.caffemodel
I0429 14:44:55.516599 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_8750.solverstate
I0429 14:44:56.062614 25258 solver.cpp:351] Iteration 8750, Testing net (#0)
I0429 14:45:01.839921 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:45:07.051687 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.545469
I0429 14:45:07.051740 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.770625
I0429 14:45:07.051748 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.893984
I0429 14:45:07.051755 25258 solver.cpp:418]     Test net output #3: loss = 1.0853 (* 1 = 1.0853 loss)
I0429 14:45:11.400683 25258 solver.cpp:239] Iteration 8760 (0.358762 iter/s, 55.7473s/20 iters), loss = 1.1244
I0429 14:45:11.406714 25258 solver.cpp:258]     Train net output #0: loss = 1.1244 (* 1 = 1.1244 loss)
I0429 14:45:11.406777 25258 sgd_solver.cpp:112] Iteration 8760, lr = 0.01
I0429 14:45:16.466480 25258 solver.cpp:239] Iteration 8780 (3.95284 iter/s, 5.05965s/20 iters), loss = 0.965793
I0429 14:45:16.471752 25258 solver.cpp:258]     Train net output #0: loss = 0.965793 (* 1 = 0.965793 loss)
I0429 14:45:16.471792 25258 sgd_solver.cpp:112] Iteration 8780, lr = 0.01
I0429 14:45:23.835110 25258 solver.cpp:239] Iteration 8800 (2.71623 iter/s, 7.36315s/20 iters), loss = 0.956939
I0429 14:45:23.835208 25258 solver.cpp:258]     Train net output #0: loss = 0.956939 (* 1 = 0.956939 loss)
I0429 14:45:23.835228 25258 sgd_solver.cpp:112] Iteration 8800, lr = 0.01
I0429 14:45:29.817739 25258 solver.cpp:239] Iteration 8820 (3.3432 iter/s, 5.9823s/20 iters), loss = 1.05025
I0429 14:45:29.843387 25258 solver.cpp:258]     Train net output #0: loss = 1.05025 (* 1 = 1.05025 loss)
I0429 14:45:29.843410 25258 sgd_solver.cpp:112] Iteration 8820, lr = 0.01
I0429 14:45:35.491027 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:45:36.161638 25258 solver.cpp:239] Iteration 8840 (3.16552 iter/s, 6.31808s/20 iters), loss = 0.999579
I0429 14:45:36.166849 25258 solver.cpp:258]     Train net output #0: loss = 0.999579 (* 1 = 0.999579 loss)
I0429 14:45:36.166895 25258 sgd_solver.cpp:112] Iteration 8840, lr = 0.01
I0429 14:45:41.709540 25258 solver.cpp:239] Iteration 8860 (3.60845 iter/s, 5.54254s/20 iters), loss = 0.964218
I0429 14:45:41.714992 25258 solver.cpp:258]     Train net output #0: loss = 0.964218 (* 1 = 0.964218 loss)
I0429 14:45:41.715046 25258 sgd_solver.cpp:112] Iteration 8860, lr = 0.01
I0429 14:45:48.450350 25258 solver.cpp:239] Iteration 8880 (2.96948 iter/s, 6.73518s/20 iters), loss = 0.848219
I0429 14:45:48.458382 25258 solver.cpp:258]     Train net output #0: loss = 0.848219 (* 1 = 0.848219 loss)
I0429 14:45:48.458422 25258 sgd_solver.cpp:112] Iteration 8880, lr = 0.01
I0429 14:45:55.595654 25258 solver.cpp:239] Iteration 8900 (2.80227 iter/s, 7.13707s/20 iters), loss = 1.03756
I0429 14:45:55.602946 25258 solver.cpp:258]     Train net output #0: loss = 1.03756 (* 1 = 1.03756 loss)
I0429 14:45:55.602993 25258 sgd_solver.cpp:112] Iteration 8900, lr = 0.01
I0429 14:46:02.215759 25258 solver.cpp:239] Iteration 8920 (3.02451 iter/s, 6.61263s/20 iters), loss = 1.06638
I0429 14:46:02.225147 25258 solver.cpp:258]     Train net output #0: loss = 1.06638 (* 1 = 1.06638 loss)
I0429 14:46:02.225199 25258 sgd_solver.cpp:112] Iteration 8920, lr = 0.01
I0429 14:46:08.303830 25258 solver.cpp:239] Iteration 8940 (3.29027 iter/s, 6.07853s/20 iters), loss = 0.997545
I0429 14:46:08.303912 25258 solver.cpp:258]     Train net output #0: loss = 0.997545 (* 1 = 0.997545 loss)
I0429 14:46:08.303933 25258 sgd_solver.cpp:112] Iteration 8940, lr = 0.01
I0429 14:46:14.163697 25258 solver.cpp:239] Iteration 8960 (3.41321 iter/s, 5.85959s/20 iters), loss = 0.862903
I0429 14:46:14.170919 25258 solver.cpp:258]     Train net output #0: loss = 0.862903 (* 1 = 0.862903 loss)
I0429 14:46:14.170964 25258 sgd_solver.cpp:112] Iteration 8960, lr = 0.01
I0429 14:46:21.643260 25258 solver.cpp:239] Iteration 8980 (2.67662 iter/s, 7.47212s/20 iters), loss = 1.15319
I0429 14:46:21.653796 25258 solver.cpp:258]     Train net output #0: loss = 1.15319 (* 1 = 1.15319 loss)
I0429 14:46:21.653842 25258 sgd_solver.cpp:112] Iteration 8980, lr = 0.01
I0429 14:46:27.511806 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_9000.caffemodel
I0429 14:47:09.174958 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_9000.solverstate
I0429 14:47:09.522837 25258 solver.cpp:351] Iteration 9000, Testing net (#0)
I0429 14:47:14.003011 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:47:19.855362 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.586172
I0429 14:47:19.855437 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.806406
I0429 14:47:19.855458 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.913516
I0429 14:47:19.855494 25258 solver.cpp:418]     Test net output #3: loss = 1.02058 (* 1 = 1.02058 loss)
I0429 14:47:20.134544 25258 solver.cpp:239] Iteration 9000 (0.342003 iter/s, 58.4791s/20 iters), loss = 1.00995
I0429 14:47:20.134656 25258 solver.cpp:258]     Train net output #0: loss = 1.00995 (* 1 = 1.00995 loss)
I0429 14:47:20.134675 25258 sgd_solver.cpp:112] Iteration 9000, lr = 0.01
I0429 14:47:27.031100 25258 solver.cpp:239] Iteration 9020 (2.90013 iter/s, 6.89623s/20 iters), loss = 0.988196
I0429 14:47:27.035909 25258 solver.cpp:258]     Train net output #0: loss = 0.988196 (* 1 = 0.988196 loss)
I0429 14:47:27.035945 25258 sgd_solver.cpp:112] Iteration 9020, lr = 0.01
I0429 14:47:33.719853 25258 solver.cpp:239] Iteration 9040 (2.99233 iter/s, 6.68376s/20 iters), loss = 0.958916
I0429 14:47:33.725217 25258 solver.cpp:258]     Train net output #0: loss = 0.958916 (* 1 = 0.958916 loss)
I0429 14:47:33.725257 25258 sgd_solver.cpp:112] Iteration 9040, lr = 0.01
I0429 14:47:40.252425 25258 solver.cpp:239] Iteration 9060 (3.06418 iter/s, 6.52703s/20 iters), loss = 1.21493
I0429 14:47:40.264451 25258 solver.cpp:258]     Train net output #0: loss = 1.21493 (* 1 = 1.21493 loss)
I0429 14:47:40.264472 25258 sgd_solver.cpp:112] Iteration 9060, lr = 0.01
I0429 14:47:47.715332 25258 solver.cpp:239] Iteration 9080 (2.68432 iter/s, 7.45067s/20 iters), loss = 0.772755
I0429 14:47:47.720715 25258 solver.cpp:258]     Train net output #0: loss = 0.772755 (* 1 = 0.772755 loss)
I0429 14:47:47.720755 25258 sgd_solver.cpp:112] Iteration 9080, lr = 0.01
I0429 14:47:51.720311 25258 solver.cpp:239] Iteration 9100 (5.00063 iter/s, 3.99949s/20 iters), loss = 0.933128
I0429 14:47:51.725843 25258 solver.cpp:258]     Train net output #0: loss = 0.933128 (* 1 = 0.933128 loss)
I0429 14:47:51.725900 25258 sgd_solver.cpp:112] Iteration 9100, lr = 0.01
I0429 14:47:59.243185 25258 solver.cpp:239] Iteration 9120 (2.66214 iter/s, 7.51275s/20 iters), loss = 0.921994
I0429 14:47:59.251565 25258 solver.cpp:258]     Train net output #0: loss = 0.921994 (* 1 = 0.921994 loss)
I0429 14:47:59.251612 25258 sgd_solver.cpp:112] Iteration 9120, lr = 0.01
I0429 14:48:06.339234 25258 solver.cpp:239] Iteration 9140 (2.82188 iter/s, 7.08747s/20 iters), loss = 0.910137
I0429 14:48:06.339351 25258 solver.cpp:258]     Train net output #0: loss = 0.910137 (* 1 = 0.910137 loss)
I0429 14:48:06.339381 25258 sgd_solver.cpp:112] Iteration 9140, lr = 0.01
I0429 14:48:13.597860 25258 solver.cpp:239] Iteration 9160 (2.75576 iter/s, 7.25751s/20 iters), loss = 0.975981
I0429 14:48:13.602885 25258 solver.cpp:258]     Train net output #0: loss = 0.975981 (* 1 = 0.975981 loss)
I0429 14:48:13.602919 25258 sgd_solver.cpp:112] Iteration 9160, lr = 0.01
I0429 14:48:20.897770 25258 solver.cpp:239] Iteration 9180 (2.74172 iter/s, 7.2947s/20 iters), loss = 0.996114
I0429 14:48:20.911191 25258 solver.cpp:258]     Train net output #0: loss = 0.996114 (* 1 = 0.996114 loss)
I0429 14:48:20.911231 25258 sgd_solver.cpp:112] Iteration 9180, lr = 0.01
I0429 14:48:27.940501 25258 solver.cpp:239] Iteration 9200 (2.84531 iter/s, 7.0291s/20 iters), loss = 1.10805
I0429 14:48:27.945770 25258 solver.cpp:258]     Train net output #0: loss = 1.10805 (* 1 = 1.10805 loss)
I0429 14:48:27.945801 25258 sgd_solver.cpp:112] Iteration 9200, lr = 0.01
I0429 14:48:35.628367 25258 solver.cpp:239] Iteration 9220 (2.60336 iter/s, 7.68238s/20 iters), loss = 0.965037
I0429 14:48:35.633848 25258 solver.cpp:258]     Train net output #0: loss = 0.965037 (* 1 = 0.965037 loss)
I0429 14:48:35.633898 25258 sgd_solver.cpp:112] Iteration 9220, lr = 0.01
I0429 14:48:42.955814 25258 solver.cpp:239] Iteration 9240 (2.73153 iter/s, 7.32189s/20 iters), loss = 0.983999
I0429 14:48:42.955886 25258 solver.cpp:258]     Train net output #0: loss = 0.983999 (* 1 = 0.983999 loss)
I0429 14:48:42.955900 25258 sgd_solver.cpp:112] Iteration 9240, lr = 0.01
I0429 14:48:43.915593 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_9250.caffemodel
I0429 14:49:17.269569 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_9250.solverstate
I0429 14:49:17.836050 25258 solver.cpp:351] Iteration 9250, Testing net (#0)
I0429 14:49:27.026028 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:49:33.338212 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.595
I0429 14:49:33.338276 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.805938
I0429 14:49:33.338287 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.915547
I0429 14:49:33.338301 25258 solver.cpp:418]     Test net output #3: loss = 0.971542 (* 1 = 0.971542 loss)
I0429 14:49:37.384055 25258 solver.cpp:239] Iteration 9260 (0.367467 iter/s, 54.4266s/20 iters), loss = 0.839001
I0429 14:49:37.389417 25258 solver.cpp:258]     Train net output #0: loss = 0.839001 (* 1 = 0.839001 loss)
I0429 14:49:37.389494 25258 sgd_solver.cpp:112] Iteration 9260, lr = 0.01
I0429 14:49:44.954485 25258 solver.cpp:239] Iteration 9280 (2.64381 iter/s, 7.56484s/20 iters), loss = 0.97823
I0429 14:49:44.965829 25258 solver.cpp:258]     Train net output #0: loss = 0.97823 (* 1 = 0.97823 loss)
I0429 14:49:44.965872 25258 sgd_solver.cpp:112] Iteration 9280, lr = 0.01
I0429 14:49:52.722944 25258 solver.cpp:239] Iteration 9300 (2.57835 iter/s, 7.7569s/20 iters), loss = 1.09217
I0429 14:49:52.728407 25258 solver.cpp:258]     Train net output #0: loss = 1.09217 (* 1 = 1.09217 loss)
I0429 14:49:52.728442 25258 sgd_solver.cpp:112] Iteration 9300, lr = 0.01
I0429 14:49:59.556598 25258 solver.cpp:239] Iteration 9320 (2.92911 iter/s, 6.828s/20 iters), loss = 0.871832
I0429 14:49:59.556980 25258 solver.cpp:258]     Train net output #0: loss = 0.871832 (* 1 = 0.871832 loss)
I0429 14:49:59.556999 25258 sgd_solver.cpp:112] Iteration 9320, lr = 0.01
I0429 14:50:08.435581 25258 solver.cpp:239] Iteration 9340 (2.25268 iter/s, 8.87833s/20 iters), loss = 0.967392
I0429 14:50:08.441778 25258 solver.cpp:258]     Train net output #0: loss = 0.967392 (* 1 = 0.967392 loss)
I0429 14:50:08.441813 25258 sgd_solver.cpp:112] Iteration 9340, lr = 0.01
I0429 14:50:13.884253 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:50:15.371682 25258 solver.cpp:239] Iteration 9360 (2.88613 iter/s, 6.9297s/20 iters), loss = 0.970717
I0429 14:50:15.371757 25258 solver.cpp:258]     Train net output #0: loss = 0.970717 (* 1 = 0.970717 loss)
I0429 14:50:15.371770 25258 sgd_solver.cpp:112] Iteration 9360, lr = 0.01
I0429 14:50:23.042670 25258 solver.cpp:239] Iteration 9380 (2.60734 iter/s, 7.67065s/20 iters), loss = 1.12733
I0429 14:50:23.051663 25258 solver.cpp:258]     Train net output #0: loss = 1.12733 (* 1 = 1.12733 loss)
I0429 14:50:23.051729 25258 sgd_solver.cpp:112] Iteration 9380, lr = 0.01
I0429 14:50:30.932042 25258 solver.cpp:239] Iteration 9400 (2.538 iter/s, 7.88021s/20 iters), loss = 1.01136
I0429 14:50:30.932166 25258 solver.cpp:258]     Train net output #0: loss = 1.01136 (* 1 = 1.01136 loss)
I0429 14:50:30.932195 25258 sgd_solver.cpp:112] Iteration 9400, lr = 0.01
I0429 14:50:38.693114 25258 solver.cpp:239] Iteration 9420 (2.5773 iter/s, 7.76007s/20 iters), loss = 0.988721
I0429 14:50:38.699579 25258 solver.cpp:258]     Train net output #0: loss = 0.988721 (* 1 = 0.988721 loss)
I0429 14:50:38.699640 25258 sgd_solver.cpp:112] Iteration 9420, lr = 0.01
I0429 14:50:47.727591 25258 solver.cpp:239] Iteration 9440 (2.21539 iter/s, 9.02777s/20 iters), loss = 1.09407
I0429 14:50:47.733337 25258 solver.cpp:258]     Train net output #0: loss = 1.09407 (* 1 = 1.09407 loss)
I0429 14:50:47.733398 25258 sgd_solver.cpp:112] Iteration 9440, lr = 0.01
I0429 14:50:53.952806 25258 solver.cpp:239] Iteration 9460 (3.21579 iter/s, 6.2193s/20 iters), loss = 0.9186
I0429 14:50:53.958835 25258 solver.cpp:258]     Train net output #0: loss = 0.9186 (* 1 = 0.9186 loss)
I0429 14:50:53.958855 25258 sgd_solver.cpp:112] Iteration 9460, lr = 0.01
I0429 14:51:02.945515 25258 solver.cpp:239] Iteration 9480 (2.22559 iter/s, 8.98638s/20 iters), loss = 0.845678
I0429 14:51:02.952508 25258 solver.cpp:258]     Train net output #0: loss = 0.845678 (* 1 = 0.845678 loss)
I0429 14:51:02.952577 25258 sgd_solver.cpp:112] Iteration 9480, lr = 0.01
I0429 14:51:07.062310 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_9500.caffemodel
I0429 14:51:43.730351 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_9500.solverstate
I0429 14:51:44.188709 25258 solver.cpp:351] Iteration 9500, Testing net (#0)
I0429 14:51:52.406002 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:51:54.200640 25258 blocking_queue.cpp:49] Waiting for data
I0429 14:51:57.217666 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.577344
I0429 14:51:57.217815 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.794219
I0429 14:51:57.217833 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.910391
I0429 14:51:57.217887 25258 solver.cpp:418]     Test net output #3: loss = 1.01758 (* 1 = 1.01758 loss)
I0429 14:51:57.364342 25258 solver.cpp:239] Iteration 9500 (0.367577 iter/s, 54.4103s/20 iters), loss = 0.973384
I0429 14:51:57.364418 25258 solver.cpp:258]     Train net output #0: loss = 0.973384 (* 1 = 0.973384 loss)
I0429 14:51:57.364431 25258 sgd_solver.cpp:112] Iteration 9500, lr = 0.01
I0429 14:52:03.322674 25258 solver.cpp:239] Iteration 9520 (3.3568 iter/s, 5.95806s/20 iters), loss = 0.868719
I0429 14:52:03.322796 25258 solver.cpp:258]     Train net output #0: loss = 0.868719 (* 1 = 0.868719 loss)
I0429 14:52:03.323215 25258 sgd_solver.cpp:112] Iteration 9520, lr = 0.01
I0429 14:52:09.064823 25258 solver.cpp:239] Iteration 9540 (3.48318 iter/s, 5.74188s/20 iters), loss = 0.93256
I0429 14:52:09.070389 25258 solver.cpp:258]     Train net output #0: loss = 0.93256 (* 1 = 0.93256 loss)
I0429 14:52:09.070442 25258 sgd_solver.cpp:112] Iteration 9540, lr = 0.01
I0429 14:52:17.155810 25258 solver.cpp:239] Iteration 9560 (2.47366 iter/s, 8.0852s/20 iters), loss = 0.882035
I0429 14:52:17.161394 25258 solver.cpp:258]     Train net output #0: loss = 0.882035 (* 1 = 0.882035 loss)
I0429 14:52:17.161422 25258 sgd_solver.cpp:112] Iteration 9560, lr = 0.01
I0429 14:52:22.626595 25258 solver.cpp:239] Iteration 9580 (3.65962 iter/s, 5.46504s/20 iters), loss = 0.964099
I0429 14:52:22.626678 25258 solver.cpp:258]     Train net output #0: loss = 0.964099 (* 1 = 0.964099 loss)
I0429 14:52:22.626693 25258 sgd_solver.cpp:112] Iteration 9580, lr = 0.01
I0429 14:52:30.413516 25258 solver.cpp:239] Iteration 9600 (2.56852 iter/s, 7.78659s/20 iters), loss = 0.891708
I0429 14:52:30.422191 25258 solver.cpp:258]     Train net output #0: loss = 0.891708 (* 1 = 0.891708 loss)
I0429 14:52:30.422230 25258 sgd_solver.cpp:112] Iteration 9600, lr = 0.01
I0429 14:52:38.377568 25258 solver.cpp:239] Iteration 9620 (2.5141 iter/s, 7.95515s/20 iters), loss = 0.842536
I0429 14:52:38.385468 25258 solver.cpp:258]     Train net output #0: loss = 0.842536 (* 1 = 0.842536 loss)
I0429 14:52:38.385505 25258 sgd_solver.cpp:112] Iteration 9620, lr = 0.01
I0429 14:52:44.775343 25258 solver.cpp:239] Iteration 9640 (3.13005 iter/s, 6.38967s/20 iters), loss = 0.91828
I0429 14:52:44.785085 25258 solver.cpp:258]     Train net output #0: loss = 0.91828 (* 1 = 0.91828 loss)
I0429 14:52:44.785135 25258 sgd_solver.cpp:112] Iteration 9640, lr = 0.01
I0429 14:52:53.633545 25258 solver.cpp:239] Iteration 9660 (2.26034 iter/s, 8.84821s/20 iters), loss = 0.844345
I0429 14:52:53.641644 25258 solver.cpp:258]     Train net output #0: loss = 0.844345 (* 1 = 0.844345 loss)
I0429 14:52:53.641680 25258 sgd_solver.cpp:112] Iteration 9660, lr = 0.01
I0429 14:53:01.412482 25258 solver.cpp:239] Iteration 9680 (2.57379 iter/s, 7.77063s/20 iters), loss = 0.984626
I0429 14:53:01.418865 25258 solver.cpp:258]     Train net output #0: loss = 0.984626 (* 1 = 0.984626 loss)
I0429 14:53:01.418916 25258 sgd_solver.cpp:112] Iteration 9680, lr = 0.01
I0429 14:53:07.747253 25258 solver.cpp:239] Iteration 9700 (3.16045 iter/s, 6.32821s/20 iters), loss = 0.947509
I0429 14:53:07.752230 25258 solver.cpp:258]     Train net output #0: loss = 0.947509 (* 1 = 0.947509 loss)
I0429 14:53:07.752267 25258 sgd_solver.cpp:112] Iteration 9700, lr = 0.01
I0429 14:53:14.811182 25258 solver.cpp:239] Iteration 9720 (2.83336 iter/s, 7.05875s/20 iters), loss = 0.98293
I0429 14:53:14.811245 25258 solver.cpp:258]     Train net output #0: loss = 0.98293 (* 1 = 0.98293 loss)
I0429 14:53:14.811256 25258 sgd_solver.cpp:112] Iteration 9720, lr = 0.01
I0429 14:53:19.356742 25258 solver.cpp:239] Iteration 9740 (4.40012 iter/s, 4.54534s/20 iters), loss = 0.925018
I0429 14:53:19.362064 25258 solver.cpp:258]     Train net output #0: loss = 0.925018 (* 1 = 0.925018 loss)
I0429 14:53:19.362112 25258 sgd_solver.cpp:112] Iteration 9740, lr = 0.01
I0429 14:53:22.662407 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_9750.caffemodel
I0429 14:53:53.781998 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_9750.solverstate
I0429 14:53:54.172935 25258 solver.cpp:351] Iteration 9750, Testing net (#0)
I0429 14:53:59.362177 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:54:05.199823 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.616562
I0429 14:54:05.199904 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.825312
I0429 14:54:05.199918 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.927266
I0429 14:54:05.199932 25258 solver.cpp:418]     Test net output #3: loss = 0.92938 (* 1 = 0.92938 loss)
I0429 14:54:12.160001 25258 solver.cpp:239] Iteration 9760 (0.378814 iter/s, 52.7964s/20 iters), loss = 0.861907
I0429 14:54:12.166290 25258 solver.cpp:258]     Train net output #0: loss = 0.861907 (* 1 = 0.861907 loss)
I0429 14:54:12.166357 25258 sgd_solver.cpp:112] Iteration 9760, lr = 0.01
I0429 14:54:26.903262 25258 solver.cpp:239] Iteration 9780 (1.35717 iter/s, 14.7366s/20 iters), loss = 0.824031
I0429 14:54:26.908510 25258 solver.cpp:258]     Train net output #0: loss = 0.824031 (* 1 = 0.824031 loss)
I0429 14:54:26.908545 25258 sgd_solver.cpp:112] Iteration 9780, lr = 0.01
I0429 14:54:36.847775 25258 solver.cpp:239] Iteration 9800 (2.01228 iter/s, 9.93899s/20 iters), loss = 1.05402
I0429 14:54:36.847872 25258 solver.cpp:258]     Train net output #0: loss = 1.05402 (* 1 = 1.05402 loss)
I0429 14:54:36.847887 25258 sgd_solver.cpp:112] Iteration 9800, lr = 0.01
I0429 14:54:43.921270 25258 solver.cpp:239] Iteration 9820 (2.82759 iter/s, 7.07316s/20 iters), loss = 0.791261
I0429 14:54:43.926861 25258 solver.cpp:258]     Train net output #0: loss = 0.791261 (* 1 = 0.791261 loss)
I0429 14:54:43.926904 25258 sgd_solver.cpp:112] Iteration 9820, lr = 0.01
I0429 14:54:51.144316 25258 solver.cpp:239] Iteration 9840 (2.77113 iter/s, 7.21728s/20 iters), loss = 0.823763
I0429 14:54:51.144381 25258 solver.cpp:258]     Train net output #0: loss = 0.823763 (* 1 = 0.823763 loss)
I0429 14:54:51.144398 25258 sgd_solver.cpp:112] Iteration 9840, lr = 0.01
I0429 14:54:57.855887 25258 solver.cpp:239] Iteration 9860 (2.98005 iter/s, 6.7113s/20 iters), loss = 1.01329
I0429 14:54:57.861599 25258 solver.cpp:258]     Train net output #0: loss = 1.01329 (* 1 = 1.01329 loss)
I0429 14:54:57.861644 25258 sgd_solver.cpp:112] Iteration 9860, lr = 0.01
I0429 14:55:04.627804 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:55:04.829668 25258 solver.cpp:239] Iteration 9880 (2.87031 iter/s, 6.96788s/20 iters), loss = 0.952837
I0429 14:55:04.829790 25258 solver.cpp:258]     Train net output #0: loss = 0.952837 (* 1 = 0.952837 loss)
I0429 14:55:04.829807 25258 sgd_solver.cpp:112] Iteration 9880, lr = 0.01
I0429 14:55:12.100203 25258 solver.cpp:239] Iteration 9900 (2.75096 iter/s, 7.27019s/20 iters), loss = 0.948942
I0429 14:55:12.100265 25258 solver.cpp:258]     Train net output #0: loss = 0.948942 (* 1 = 0.948942 loss)
I0429 14:55:12.100276 25258 sgd_solver.cpp:112] Iteration 9900, lr = 0.01
I0429 14:55:18.711122 25258 solver.cpp:239] Iteration 9920 (3.02544 iter/s, 6.6106s/20 iters), loss = 0.919349
I0429 14:55:18.711297 25258 solver.cpp:258]     Train net output #0: loss = 0.919349 (* 1 = 0.919349 loss)
I0429 14:55:18.711328 25258 sgd_solver.cpp:112] Iteration 9920, lr = 0.01
I0429 14:55:25.975358 25258 solver.cpp:239] Iteration 9940 (2.75336 iter/s, 7.26385s/20 iters), loss = 0.916755
I0429 14:55:25.975435 25258 solver.cpp:258]     Train net output #0: loss = 0.916755 (* 1 = 0.916755 loss)
I0429 14:55:25.975450 25258 sgd_solver.cpp:112] Iteration 9940, lr = 0.01
I0429 14:55:32.269850 25258 solver.cpp:239] Iteration 9960 (3.1803 iter/s, 6.28872s/20 iters), loss = 0.76782
I0429 14:55:32.270745 25258 solver.cpp:258]     Train net output #0: loss = 0.76782 (* 1 = 0.76782 loss)
I0429 14:55:32.270766 25258 sgd_solver.cpp:112] Iteration 9960, lr = 0.01
I0429 14:55:39.925004 25258 solver.cpp:239] Iteration 9980 (2.613 iter/s, 7.65403s/20 iters), loss = 0.902976
I0429 14:55:39.930007 25258 solver.cpp:258]     Train net output #0: loss = 0.902976 (* 1 = 0.902976 loss)
I0429 14:55:39.930070 25258 sgd_solver.cpp:112] Iteration 9980, lr = 0.01
I0429 14:55:45.049299 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_10000.caffemodel
I0429 14:56:22.128814 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_10000.solverstate
I0429 14:56:22.483845 25258 solver.cpp:351] Iteration 10000, Testing net (#0)
I0429 14:56:28.499053 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:56:32.261253 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.621484
I0429 14:56:32.261309 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.817422
I0429 14:56:32.261327 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.921641
I0429 14:56:32.261343 25258 solver.cpp:418]     Test net output #3: loss = 0.935626 (* 1 = 0.935626 loss)
I0429 14:56:32.401270 25258 solver.cpp:239] Iteration 10000 (0.381172 iter/s, 52.4698s/20 iters), loss = 0.791226
I0429 14:56:32.413810 25258 solver.cpp:258]     Train net output #0: loss = 0.791226 (* 1 = 0.791226 loss)
I0429 14:56:32.413853 25258 sgd_solver.cpp:112] Iteration 10000, lr = 0.001
I0429 14:56:37.924034 25258 solver.cpp:239] Iteration 10020 (3.6297 iter/s, 5.5101s/20 iters), loss = 1.20451
I0429 14:56:37.929847 25258 solver.cpp:258]     Train net output #0: loss = 1.20451 (* 1 = 1.20451 loss)
I0429 14:56:37.929888 25258 sgd_solver.cpp:112] Iteration 10020, lr = 0.001
I0429 14:56:43.003477 25258 solver.cpp:239] Iteration 10040 (3.94206 iter/s, 5.07348s/20 iters), loss = 0.880302
I0429 14:56:43.011215 25258 solver.cpp:258]     Train net output #0: loss = 0.880302 (* 1 = 0.880302 loss)
I0429 14:56:43.011248 25258 sgd_solver.cpp:112] Iteration 10040, lr = 0.001
I0429 14:56:55.362902 25258 solver.cpp:239] Iteration 10060 (1.61926 iter/s, 12.3513s/20 iters), loss = 0.911436
I0429 14:56:55.369374 25258 solver.cpp:258]     Train net output #0: loss = 0.911436 (* 1 = 0.911436 loss)
I0429 14:56:55.369403 25258 sgd_solver.cpp:112] Iteration 10060, lr = 0.001
I0429 14:57:09.817946 25258 solver.cpp:239] Iteration 10080 (1.38426 iter/s, 14.4482s/20 iters), loss = 0.706267
I0429 14:57:09.823062 25258 solver.cpp:258]     Train net output #0: loss = 0.706267 (* 1 = 0.706267 loss)
I0429 14:57:09.823102 25258 sgd_solver.cpp:112] Iteration 10080, lr = 0.001
I0429 14:57:20.242465 25258 solver.cpp:239] Iteration 10100 (1.91955 iter/s, 10.4191s/20 iters), loss = 0.795243
I0429 14:57:20.248096 25258 solver.cpp:258]     Train net output #0: loss = 0.795243 (* 1 = 0.795243 loss)
I0429 14:57:20.248147 25258 sgd_solver.cpp:112] Iteration 10100, lr = 0.001
I0429 14:57:27.208071 25258 solver.cpp:239] Iteration 10120 (2.87365 iter/s, 6.95979s/20 iters), loss = 0.684445
I0429 14:57:27.214092 25258 solver.cpp:258]     Train net output #0: loss = 0.684445 (* 1 = 0.684445 loss)
I0429 14:57:27.214154 25258 sgd_solver.cpp:112] Iteration 10120, lr = 0.001
I0429 14:57:32.914631 25258 solver.cpp:239] Iteration 10140 (3.50852 iter/s, 5.7004s/20 iters), loss = 0.67961
I0429 14:57:32.925817 25258 solver.cpp:258]     Train net output #0: loss = 0.67961 (* 1 = 0.67961 loss)
I0429 14:57:32.925858 25258 sgd_solver.cpp:112] Iteration 10140, lr = 0.001
I0429 14:57:39.449398 25258 solver.cpp:239] Iteration 10160 (3.06587 iter/s, 6.52343s/20 iters), loss = 0.78493
I0429 14:57:39.455560 25258 solver.cpp:258]     Train net output #0: loss = 0.78493 (* 1 = 0.78493 loss)
I0429 14:57:39.455611 25258 sgd_solver.cpp:112] Iteration 10160, lr = 0.001
I0429 14:57:47.218935 25258 solver.cpp:239] Iteration 10180 (2.57628 iter/s, 7.76314s/20 iters), loss = 0.68204
I0429 14:57:47.225800 25258 solver.cpp:258]     Train net output #0: loss = 0.68204 (* 1 = 0.68204 loss)
I0429 14:57:47.225863 25258 sgd_solver.cpp:112] Iteration 10180, lr = 0.001
I0429 14:57:53.967504 25258 solver.cpp:239] Iteration 10200 (2.96668 iter/s, 6.74153s/20 iters), loss = 0.68765
I0429 14:57:53.974581 25258 solver.cpp:258]     Train net output #0: loss = 0.68765 (* 1 = 0.68765 loss)
I0429 14:57:53.974617 25258 sgd_solver.cpp:112] Iteration 10200, lr = 0.001
I0429 14:58:01.314846 25258 solver.cpp:239] Iteration 10220 (2.72477 iter/s, 7.34006s/20 iters), loss = 0.691396
I0429 14:58:01.321111 25258 solver.cpp:258]     Train net output #0: loss = 0.691396 (* 1 = 0.691396 loss)
I0429 14:58:01.321178 25258 sgd_solver.cpp:112] Iteration 10220, lr = 0.001
I0429 14:58:06.841873 25258 solver.cpp:239] Iteration 10240 (3.62277 iter/s, 5.52063s/20 iters), loss = 0.650248
I0429 14:58:06.846971 25258 solver.cpp:258]     Train net output #0: loss = 0.650248 (* 1 = 0.650248 loss)
I0429 14:58:06.847023 25258 sgd_solver.cpp:112] Iteration 10240, lr = 0.001
I0429 14:58:10.222506 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_10250.caffemodel
I0429 14:58:49.412729 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_10250.solverstate
I0429 14:58:49.796921 25258 solver.cpp:351] Iteration 10250, Testing net (#0)
I0429 14:58:55.635593 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 14:58:58.502946 25258 blocking_queue.cpp:49] Waiting for data
I0429 14:58:59.134654 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.730391
I0429 14:58:59.134699 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.886172
I0429 14:58:59.134708 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.952187
I0429 14:58:59.134723 25258 solver.cpp:418]     Test net output #3: loss = 0.691007 (* 1 = 0.691007 loss)
I0429 14:59:00.246362 25258 solver.cpp:239] Iteration 10260 (0.374547 iter/s, 53.3979s/20 iters), loss = 0.750865
I0429 14:59:00.246435 25258 solver.cpp:258]     Train net output #0: loss = 0.750865 (* 1 = 0.750865 loss)
I0429 14:59:00.246453 25258 sgd_solver.cpp:112] Iteration 10260, lr = 0.001
I0429 14:59:05.957784 25258 solver.cpp:239] Iteration 10280 (3.50192 iter/s, 5.71116s/20 iters), loss = 0.675036
I0429 14:59:05.962779 25258 solver.cpp:258]     Train net output #0: loss = 0.675036 (* 1 = 0.675036 loss)
I0429 14:59:05.962826 25258 sgd_solver.cpp:112] Iteration 10280, lr = 0.001
I0429 14:59:11.816519 25258 solver.cpp:239] Iteration 10300 (3.41673 iter/s, 5.85356s/20 iters), loss = 0.694107
I0429 14:59:11.823006 25258 solver.cpp:258]     Train net output #0: loss = 0.694107 (* 1 = 0.694107 loss)
I0429 14:59:11.823070 25258 sgd_solver.cpp:112] Iteration 10300, lr = 0.001
I0429 14:59:18.342061 25258 solver.cpp:239] Iteration 10320 (3.06841 iter/s, 6.51803s/20 iters), loss = 0.637587
I0429 14:59:18.346014 25258 solver.cpp:258]     Train net output #0: loss = 0.637587 (* 1 = 0.637587 loss)
I0429 14:59:18.346050 25258 sgd_solver.cpp:112] Iteration 10320, lr = 0.001
I0429 14:59:28.609342 25258 solver.cpp:239] Iteration 10340 (1.94874 iter/s, 10.263s/20 iters), loss = 0.577195
I0429 14:59:28.614543 25258 solver.cpp:258]     Train net output #0: loss = 0.577195 (* 1 = 0.577195 loss)
I0429 14:59:28.614579 25258 sgd_solver.cpp:112] Iteration 10340, lr = 0.001
I0429 14:59:43.214383 25258 solver.cpp:239] Iteration 10360 (1.36992 iter/s, 14.5994s/20 iters), loss = 0.50331
I0429 14:59:43.219447 25258 solver.cpp:258]     Train net output #0: loss = 0.50331 (* 1 = 0.50331 loss)
I0429 14:59:43.219480 25258 sgd_solver.cpp:112] Iteration 10360, lr = 0.001
I0429 14:59:58.771015 25258 solver.cpp:239] Iteration 10380 (1.28608 iter/s, 15.5511s/20 iters), loss = 0.684767
I0429 14:59:58.776437 25258 solver.cpp:258]     Train net output #0: loss = 0.684767 (* 1 = 0.684767 loss)
I0429 14:59:58.776469 25258 sgd_solver.cpp:112] Iteration 10380, lr = 0.001
I0429 15:00:06.071267 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:00:06.857879 25258 solver.cpp:239] Iteration 10400 (2.47488 iter/s, 8.0812s/20 iters), loss = 0.6132
I0429 15:00:06.863396 25258 solver.cpp:258]     Train net output #0: loss = 0.6132 (* 1 = 0.6132 loss)
I0429 15:00:06.863446 25258 sgd_solver.cpp:112] Iteration 10400, lr = 0.001
I0429 15:00:12.729878 25258 solver.cpp:239] Iteration 10420 (3.40929 iter/s, 5.86633s/20 iters), loss = 0.59729
I0429 15:00:12.729986 25258 solver.cpp:258]     Train net output #0: loss = 0.59729 (* 1 = 0.59729 loss)
I0429 15:00:12.730020 25258 sgd_solver.cpp:112] Iteration 10420, lr = 0.001
I0429 15:00:18.540051 25258 solver.cpp:239] Iteration 10440 (3.44241 iter/s, 5.80988s/20 iters), loss = 0.574317
I0429 15:00:18.545533 25258 solver.cpp:258]     Train net output #0: loss = 0.574317 (* 1 = 0.574317 loss)
I0429 15:00:18.545574 25258 sgd_solver.cpp:112] Iteration 10440, lr = 0.001
I0429 15:00:26.271363 25258 solver.cpp:239] Iteration 10460 (2.58879 iter/s, 7.72562s/20 iters), loss = 0.538868
I0429 15:00:26.271440 25258 solver.cpp:258]     Train net output #0: loss = 0.538868 (* 1 = 0.538868 loss)
I0429 15:00:26.271456 25258 sgd_solver.cpp:112] Iteration 10460, lr = 0.001
I0429 15:00:33.361678 25258 solver.cpp:239] Iteration 10480 (2.82087 iter/s, 7.09002s/20 iters), loss = 0.576042
I0429 15:00:33.368012 25258 solver.cpp:258]     Train net output #0: loss = 0.576042 (* 1 = 0.576042 loss)
I0429 15:00:33.368034 25258 sgd_solver.cpp:112] Iteration 10480, lr = 0.001
I0429 15:00:40.510444 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_10500.caffemodel
I0429 15:01:06.340148 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_10500.solverstate
I0429 15:01:06.750075 25258 solver.cpp:351] Iteration 10500, Testing net (#0)
I0429 15:01:13.784340 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:01:17.339118 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.750078
I0429 15:01:17.339177 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.896875
I0429 15:01:17.339190 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.956875
I0429 15:01:17.339203 25258 solver.cpp:418]     Test net output #3: loss = 0.62993 (* 1 = 0.62993 loss)
I0429 15:01:17.436209 25258 solver.cpp:239] Iteration 10500 (0.453855 iter/s, 44.0669s/20 iters), loss = 0.680613
I0429 15:01:17.436312 25258 solver.cpp:258]     Train net output #0: loss = 0.680613 (* 1 = 0.680613 loss)
I0429 15:01:17.436334 25258 sgd_solver.cpp:112] Iteration 10500, lr = 0.001
I0429 15:01:23.082072 25258 solver.cpp:239] Iteration 10520 (3.54259 iter/s, 5.64558s/20 iters), loss = 0.418823
I0429 15:01:23.087906 25258 solver.cpp:258]     Train net output #0: loss = 0.418823 (* 1 = 0.418823 loss)
I0429 15:01:23.087980 25258 sgd_solver.cpp:112] Iteration 10520, lr = 0.001
I0429 15:01:29.037287 25258 solver.cpp:239] Iteration 10540 (3.36176 iter/s, 5.94926s/20 iters), loss = 0.648349
I0429 15:01:29.037361 25258 solver.cpp:258]     Train net output #0: loss = 0.648349 (* 1 = 0.648349 loss)
I0429 15:01:29.037375 25258 sgd_solver.cpp:112] Iteration 10540, lr = 0.001
I0429 15:01:36.521121 25258 solver.cpp:239] Iteration 10560 (2.67254 iter/s, 7.48352s/20 iters), loss = 0.574978
I0429 15:01:36.526198 25258 solver.cpp:258]     Train net output #0: loss = 0.574978 (* 1 = 0.574978 loss)
I0429 15:01:36.526234 25258 sgd_solver.cpp:112] Iteration 10560, lr = 0.001
I0429 15:01:43.062609 25258 solver.cpp:239] Iteration 10580 (3.05987 iter/s, 6.53623s/20 iters), loss = 0.521757
I0429 15:01:43.067767 25258 solver.cpp:258]     Train net output #0: loss = 0.521757 (* 1 = 0.521757 loss)
I0429 15:01:43.067806 25258 sgd_solver.cpp:112] Iteration 10580, lr = 0.001
I0429 15:01:50.323659 25258 solver.cpp:239] Iteration 10600 (2.75646 iter/s, 7.25569s/20 iters), loss = 0.533951
I0429 15:01:50.328761 25258 solver.cpp:258]     Train net output #0: loss = 0.533951 (* 1 = 0.533951 loss)
I0429 15:01:50.328802 25258 sgd_solver.cpp:112] Iteration 10600, lr = 0.001
I0429 15:01:57.369629 25258 solver.cpp:239] Iteration 10620 (2.84064 iter/s, 7.04066s/20 iters), loss = 0.678273
I0429 15:01:57.375010 25258 solver.cpp:258]     Train net output #0: loss = 0.678273 (* 1 = 0.678273 loss)
I0429 15:01:57.375059 25258 sgd_solver.cpp:112] Iteration 10620, lr = 0.001
I0429 15:02:03.887333 25258 solver.cpp:239] Iteration 10640 (3.07118 iter/s, 6.51216s/20 iters), loss = 0.402697
I0429 15:02:03.892196 25258 solver.cpp:258]     Train net output #0: loss = 0.402697 (* 1 = 0.402697 loss)
I0429 15:02:03.892269 25258 sgd_solver.cpp:112] Iteration 10640, lr = 0.001
I0429 15:02:16.265900 25258 solver.cpp:239] Iteration 10660 (1.61669 iter/s, 12.3709s/20 iters), loss = 0.599132
I0429 15:02:16.270567 25258 solver.cpp:258]     Train net output #0: loss = 0.599132 (* 1 = 0.599132 loss)
I0429 15:02:16.270640 25258 sgd_solver.cpp:112] Iteration 10660, lr = 0.001
I0429 15:02:31.391546 25258 solver.cpp:239] Iteration 10680 (1.3227 iter/s, 15.1206s/20 iters), loss = 0.576616
I0429 15:02:31.398787 25258 solver.cpp:258]     Train net output #0: loss = 0.576616 (* 1 = 0.576616 loss)
I0429 15:02:31.398859 25258 sgd_solver.cpp:112] Iteration 10680, lr = 0.001
I0429 15:02:44.883970 25258 solver.cpp:239] Iteration 10700 (1.48315 iter/s, 13.4848s/20 iters), loss = 0.471647
I0429 15:02:44.891191 25258 solver.cpp:258]     Train net output #0: loss = 0.471647 (* 1 = 0.471647 loss)
I0429 15:02:44.891229 25258 sgd_solver.cpp:112] Iteration 10700, lr = 0.001
I0429 15:02:51.736963 25258 solver.cpp:239] Iteration 10720 (2.9216 iter/s, 6.84557s/20 iters), loss = 0.589046
I0429 15:02:51.742782 25258 solver.cpp:258]     Train net output #0: loss = 0.589046 (* 1 = 0.589046 loss)
I0429 15:02:51.742805 25258 sgd_solver.cpp:112] Iteration 10720, lr = 0.001
I0429 15:02:59.302534 25258 solver.cpp:239] Iteration 10740 (2.64567 iter/s, 7.55953s/20 iters), loss = 0.580135
I0429 15:02:59.308291 25258 solver.cpp:258]     Train net output #0: loss = 0.580135 (* 1 = 0.580135 loss)
I0429 15:02:59.308377 25258 sgd_solver.cpp:112] Iteration 10740, lr = 0.001
I0429 15:03:03.306366 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_10750.caffemodel
I0429 15:03:44.916687 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_10750.solverstate
I0429 15:03:45.276134 25258 solver.cpp:351] Iteration 10750, Testing net (#0)
I0429 15:03:51.390308 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:03:55.285246 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.770859
I0429 15:03:55.285324 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.906016
I0429 15:03:55.285341 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.961328
I0429 15:03:55.285356 25258 solver.cpp:418]     Test net output #3: loss = 0.586598 (* 1 = 0.586598 loss)
I0429 15:03:58.238705 25258 solver.cpp:239] Iteration 10760 (0.339393 iter/s, 58.9288s/20 iters), loss = 0.633206
I0429 15:03:58.238822 25258 solver.cpp:258]     Train net output #0: loss = 0.633206 (* 1 = 0.633206 loss)
I0429 15:03:58.238843 25258 sgd_solver.cpp:112] Iteration 10760, lr = 0.001
I0429 15:04:04.295648 25258 solver.cpp:239] Iteration 10780 (3.30217 iter/s, 6.05663s/20 iters), loss = 0.603639
I0429 15:04:04.303570 25258 solver.cpp:258]     Train net output #0: loss = 0.603639 (* 1 = 0.603639 loss)
I0429 15:04:04.303613 25258 sgd_solver.cpp:112] Iteration 10780, lr = 0.001
I0429 15:04:09.984356 25258 solver.cpp:239] Iteration 10800 (3.52073 iter/s, 5.68063s/20 iters), loss = 0.457956
I0429 15:04:09.989907 25258 solver.cpp:258]     Train net output #0: loss = 0.457956 (* 1 = 0.457956 loss)
I0429 15:04:09.989949 25258 sgd_solver.cpp:112] Iteration 10800, lr = 0.001
I0429 15:04:14.923352 25258 solver.cpp:239] Iteration 10820 (4.05408 iter/s, 4.9333s/20 iters), loss = 0.535815
I0429 15:04:14.933007 25258 solver.cpp:258]     Train net output #0: loss = 0.535815 (* 1 = 0.535815 loss)
I0429 15:04:14.933033 25258 sgd_solver.cpp:112] Iteration 10820, lr = 0.001
I0429 15:04:17.531561 25258 solver.cpp:239] Iteration 10840 (7.69679 iter/s, 2.59849s/20 iters), loss = 0.545956
I0429 15:04:17.531641 25258 solver.cpp:258]     Train net output #0: loss = 0.545956 (* 1 = 0.545956 loss)
I0429 15:04:17.531654 25258 sgd_solver.cpp:112] Iteration 10840, lr = 0.001
I0429 15:04:24.393774 25258 solver.cpp:239] Iteration 10860 (2.91464 iter/s, 6.86192s/20 iters), loss = 0.507722
I0429 15:04:24.401836 25258 solver.cpp:258]     Train net output #0: loss = 0.507722 (* 1 = 0.507722 loss)
I0429 15:04:24.401880 25258 sgd_solver.cpp:112] Iteration 10860, lr = 0.001
I0429 15:04:32.331799 25258 solver.cpp:239] Iteration 10880 (2.52215 iter/s, 7.92974s/20 iters), loss = 0.428967
I0429 15:04:32.339427 25258 solver.cpp:258]     Train net output #0: loss = 0.428967 (* 1 = 0.428967 loss)
I0429 15:04:32.339463 25258 sgd_solver.cpp:112] Iteration 10880, lr = 0.001
I0429 15:04:39.418546 25258 solver.cpp:239] Iteration 10900 (2.82529 iter/s, 7.07892s/20 iters), loss = 0.525858
I0429 15:04:39.418644 25258 solver.cpp:258]     Train net output #0: loss = 0.525858 (* 1 = 0.525858 loss)
I0429 15:04:39.418661 25258 sgd_solver.cpp:112] Iteration 10900, lr = 0.001
I0429 15:04:44.960660 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:04:45.731122 25258 solver.cpp:239] Iteration 10920 (3.16843 iter/s, 6.31228s/20 iters), loss = 0.480207
I0429 15:04:45.736218 25258 solver.cpp:258]     Train net output #0: loss = 0.480207 (* 1 = 0.480207 loss)
I0429 15:04:45.736250 25258 sgd_solver.cpp:112] Iteration 10920, lr = 0.001
I0429 15:04:59.067206 25258 solver.cpp:239] Iteration 10940 (1.50031 iter/s, 13.3306s/20 iters), loss = 0.553273
I0429 15:04:59.072374 25258 solver.cpp:258]     Train net output #0: loss = 0.553273 (* 1 = 0.553273 loss)
I0429 15:04:59.072409 25258 sgd_solver.cpp:112] Iteration 10940, lr = 0.001
I0429 15:05:14.126842 25258 solver.cpp:239] Iteration 10960 (1.32855 iter/s, 15.054s/20 iters), loss = 0.489826
I0429 15:05:14.132144 25258 solver.cpp:258]     Train net output #0: loss = 0.489826 (* 1 = 0.489826 loss)
I0429 15:05:14.132175 25258 sgd_solver.cpp:112] Iteration 10960, lr = 0.001
I0429 15:05:26.477735 25258 solver.cpp:239] Iteration 10980 (1.62006 iter/s, 12.3452s/20 iters), loss = 0.492424
I0429 15:05:26.483341 25258 solver.cpp:258]     Train net output #0: loss = 0.492424 (* 1 = 0.492424 loss)
I0429 15:05:26.483384 25258 sgd_solver.cpp:112] Iteration 10980, lr = 0.001
I0429 15:05:32.835784 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_11000.caffemodel
I0429 15:06:15.290776 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_11000.solverstate
I0429 15:06:15.664064 25258 solver.cpp:351] Iteration 11000, Testing net (#0)
I0429 15:06:23.802840 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:06:27.031406 25258 blocking_queue.cpp:49] Waiting for data
I0429 15:06:28.475103 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.783281
I0429 15:06:28.475178 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.912266
I0429 15:06:28.475193 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.964609
I0429 15:06:28.475211 25258 solver.cpp:418]     Test net output #3: loss = 0.551042 (* 1 = 0.551042 loss)
I0429 15:06:28.692070 25258 solver.cpp:239] Iteration 11000 (0.321507 iter/s, 62.2069s/20 iters), loss = 0.462878
I0429 15:06:28.696451 25258 solver.cpp:258]     Train net output #0: loss = 0.462878 (* 1 = 0.462878 loss)
I0429 15:06:28.696502 25258 sgd_solver.cpp:112] Iteration 11000, lr = 0.001
I0429 15:06:35.542719 25258 solver.cpp:239] Iteration 11020 (2.92138 iter/s, 6.84608s/20 iters), loss = 0.601146
I0429 15:06:35.542814 25258 solver.cpp:258]     Train net output #0: loss = 0.601146 (* 1 = 0.601146 loss)
I0429 15:06:35.542834 25258 sgd_solver.cpp:112] Iteration 11020, lr = 0.001
I0429 15:06:40.879467 25258 solver.cpp:239] Iteration 11040 (3.7478 iter/s, 5.33647s/20 iters), loss = 0.411881
I0429 15:06:40.890184 25258 solver.cpp:258]     Train net output #0: loss = 0.411881 (* 1 = 0.411881 loss)
I0429 15:06:40.890230 25258 sgd_solver.cpp:112] Iteration 11040, lr = 0.001
I0429 15:06:46.987658 25258 solver.cpp:239] Iteration 11060 (3.28014 iter/s, 6.0973s/20 iters), loss = 0.577782
I0429 15:06:46.998158 25258 solver.cpp:258]     Train net output #0: loss = 0.577782 (* 1 = 0.577782 loss)
I0429 15:06:46.998191 25258 sgd_solver.cpp:112] Iteration 11060, lr = 0.001
I0429 15:06:54.365097 25258 solver.cpp:239] Iteration 11080 (2.7149 iter/s, 7.36675s/20 iters), loss = 0.574328
I0429 15:06:54.365929 25258 solver.cpp:258]     Train net output #0: loss = 0.574328 (* 1 = 0.574328 loss)
I0429 15:06:54.365967 25258 sgd_solver.cpp:112] Iteration 11080, lr = 0.001
I0429 15:07:00.336103 25258 solver.cpp:239] Iteration 11100 (3.35008 iter/s, 5.97s/20 iters), loss = 0.45677
I0429 15:07:00.336185 25258 solver.cpp:258]     Train net output #0: loss = 0.45677 (* 1 = 0.45677 loss)
I0429 15:07:00.336199 25258 sgd_solver.cpp:112] Iteration 11100, lr = 0.001
I0429 15:07:07.772155 25258 solver.cpp:239] Iteration 11120 (2.68971 iter/s, 7.43574s/20 iters), loss = 0.41863
I0429 15:07:07.772240 25258 solver.cpp:258]     Train net output #0: loss = 0.41863 (* 1 = 0.41863 loss)
I0429 15:07:07.772258 25258 sgd_solver.cpp:112] Iteration 11120, lr = 0.001
I0429 15:07:13.911732 25258 solver.cpp:239] Iteration 11140 (3.25771 iter/s, 6.13929s/20 iters), loss = 0.535165
I0429 15:07:13.921886 25258 solver.cpp:258]     Train net output #0: loss = 0.535165 (* 1 = 0.535165 loss)
I0429 15:07:13.921921 25258 sgd_solver.cpp:112] Iteration 11140, lr = 0.001
I0429 15:07:20.813801 25258 solver.cpp:239] Iteration 11160 (2.90203 iter/s, 6.89172s/20 iters), loss = 0.444503
I0429 15:07:20.825999 25258 solver.cpp:258]     Train net output #0: loss = 0.444503 (* 1 = 0.444503 loss)
I0429 15:07:20.826023 25258 sgd_solver.cpp:112] Iteration 11160, lr = 0.001
I0429 15:07:31.910722 25258 solver.cpp:239] Iteration 11180 (1.80434 iter/s, 11.0844s/20 iters), loss = 0.445429
I0429 15:07:31.916141 25258 solver.cpp:258]     Train net output #0: loss = 0.445429 (* 1 = 0.445429 loss)
I0429 15:07:31.916174 25258 sgd_solver.cpp:112] Iteration 11180, lr = 0.001
I0429 15:07:46.561899 25258 solver.cpp:239] Iteration 11200 (1.36562 iter/s, 14.6453s/20 iters), loss = 0.490389
I0429 15:07:46.569923 25258 solver.cpp:258]     Train net output #0: loss = 0.490389 (* 1 = 0.490389 loss)
I0429 15:07:46.569977 25258 sgd_solver.cpp:112] Iteration 11200, lr = 0.001
I0429 15:08:02.063763 25258 solver.cpp:239] Iteration 11220 (1.29087 iter/s, 15.4934s/20 iters), loss = 0.399949
I0429 15:08:02.064123 25258 solver.cpp:258]     Train net output #0: loss = 0.399949 (* 1 = 0.399949 loss)
I0429 15:08:02.064141 25258 sgd_solver.cpp:112] Iteration 11220, lr = 0.001
I0429 15:08:09.954316 25258 solver.cpp:239] Iteration 11240 (2.53486 iter/s, 7.88997s/20 iters), loss = 0.618186
I0429 15:08:09.954380 25258 solver.cpp:258]     Train net output #0: loss = 0.618186 (* 1 = 0.618186 loss)
I0429 15:08:09.954391 25258 sgd_solver.cpp:112] Iteration 11240, lr = 0.001
I0429 15:08:13.376677 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_11250.caffemodel
I0429 15:08:39.773793 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_11250.solverstate
I0429 15:08:40.223909 25258 solver.cpp:351] Iteration 11250, Testing net (#0)
I0429 15:08:49.588003 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:08:53.724753 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.792188
I0429 15:08:53.724808 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.914766
I0429 15:08:53.724822 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.966172
I0429 15:08:53.724834 25258 solver.cpp:418]     Test net output #3: loss = 0.526434 (* 1 = 0.526434 loss)
I0429 15:08:56.110743 25258 solver.cpp:239] Iteration 11260 (0.433322 iter/s, 46.155s/20 iters), loss = 0.574287
I0429 15:08:56.116271 25258 solver.cpp:258]     Train net output #0: loss = 0.574287 (* 1 = 0.574287 loss)
I0429 15:08:56.116322 25258 sgd_solver.cpp:112] Iteration 11260, lr = 0.001
I0429 15:09:03.037125 25258 solver.cpp:239] Iteration 11280 (2.88989 iter/s, 6.92067s/20 iters), loss = 0.536925
I0429 15:09:03.037205 25258 solver.cpp:258]     Train net output #0: loss = 0.536925 (* 1 = 0.536925 loss)
I0429 15:09:03.037227 25258 sgd_solver.cpp:112] Iteration 11280, lr = 0.001
I0429 15:09:08.804247 25258 solver.cpp:239] Iteration 11300 (3.46809 iter/s, 5.76686s/20 iters), loss = 0.513808
I0429 15:09:08.804323 25258 solver.cpp:258]     Train net output #0: loss = 0.513808 (* 1 = 0.513808 loss)
I0429 15:09:08.804347 25258 sgd_solver.cpp:112] Iteration 11300, lr = 0.001
I0429 15:09:15.017966 25258 solver.cpp:239] Iteration 11320 (3.21882 iter/s, 6.21345s/20 iters), loss = 0.451315
I0429 15:09:15.023576 25258 solver.cpp:258]     Train net output #0: loss = 0.451315 (* 1 = 0.451315 loss)
I0429 15:09:15.023632 25258 sgd_solver.cpp:112] Iteration 11320, lr = 0.001
I0429 15:09:21.402715 25258 solver.cpp:239] Iteration 11340 (3.1353 iter/s, 6.37897s/20 iters), loss = 0.530167
I0429 15:09:21.412355 25258 solver.cpp:258]     Train net output #0: loss = 0.530167 (* 1 = 0.530167 loss)
I0429 15:09:21.412400 25258 sgd_solver.cpp:112] Iteration 11340, lr = 0.001
I0429 15:09:28.031540 25258 solver.cpp:239] Iteration 11360 (3.0216 iter/s, 6.619s/20 iters), loss = 0.483092
I0429 15:09:28.036356 25258 solver.cpp:258]     Train net output #0: loss = 0.483092 (* 1 = 0.483092 loss)
I0429 15:09:28.036379 25258 sgd_solver.cpp:112] Iteration 11360, lr = 0.001
I0429 15:09:34.529561 25258 solver.cpp:239] Iteration 11380 (3.08023 iter/s, 6.49302s/20 iters), loss = 0.435466
I0429 15:09:34.529629 25258 solver.cpp:258]     Train net output #0: loss = 0.435466 (* 1 = 0.435466 loss)
I0429 15:09:34.529644 25258 sgd_solver.cpp:112] Iteration 11380, lr = 0.001
I0429 15:09:40.398217 25258 solver.cpp:239] Iteration 11400 (3.41248 iter/s, 5.86083s/20 iters), loss = 0.352142
I0429 15:09:40.398303 25258 solver.cpp:258]     Train net output #0: loss = 0.352142 (* 1 = 0.352142 loss)
I0429 15:09:40.398320 25258 sgd_solver.cpp:112] Iteration 11400, lr = 0.001
I0429 15:09:46.440789 25258 solver.cpp:239] Iteration 11420 (3.31136 iter/s, 6.03982s/20 iters), loss = 0.557653
I0429 15:09:46.446414 25258 solver.cpp:258]     Train net output #0: loss = 0.557653 (* 1 = 0.557653 loss)
I0429 15:09:46.446429 25258 sgd_solver.cpp:112] Iteration 11420, lr = 0.001
I0429 15:09:51.226529 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:09:51.596446 25258 solver.cpp:239] Iteration 11440 (3.88359 iter/s, 5.14988s/20 iters), loss = 0.476263
I0429 15:09:51.601900 25258 solver.cpp:258]     Train net output #0: loss = 0.476263 (* 1 = 0.476263 loss)
I0429 15:09:51.601956 25258 sgd_solver.cpp:112] Iteration 11440, lr = 0.001
I0429 15:09:56.920549 25258 solver.cpp:239] Iteration 11460 (3.76045 iter/s, 5.31851s/20 iters), loss = 0.367734
I0429 15:09:56.925771 25258 solver.cpp:258]     Train net output #0: loss = 0.367734 (* 1 = 0.367734 loss)
I0429 15:09:56.925810 25258 sgd_solver.cpp:112] Iteration 11460, lr = 0.001
I0429 15:10:07.738272 25258 solver.cpp:239] Iteration 11480 (1.84975 iter/s, 10.8123s/20 iters), loss = 0.433938
I0429 15:10:07.743304 25258 solver.cpp:258]     Train net output #0: loss = 0.433938 (* 1 = 0.433938 loss)
I0429 15:10:07.743331 25258 sgd_solver.cpp:112] Iteration 11480, lr = 0.001
I0429 15:10:19.882927 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_11500.caffemodel
I0429 15:11:03.607370 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_11500.solverstate
I0429 15:11:03.986407 25258 solver.cpp:351] Iteration 11500, Testing net (#0)
I0429 15:11:11.773783 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:11:14.360679 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.804766
I0429 15:11:14.360723 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.921328
I0429 15:11:14.360730 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.968047
I0429 15:11:14.360741 25258 solver.cpp:418]     Test net output #3: loss = 0.49776 (* 1 = 0.49776 loss)
I0429 15:11:14.707445 25258 solver.cpp:239] Iteration 11500 (0.298676 iter/s, 66.9623s/20 iters), loss = 0.520648
I0429 15:11:14.707520 25258 solver.cpp:258]     Train net output #0: loss = 0.520648 (* 1 = 0.520648 loss)
I0429 15:11:14.707535 25258 sgd_solver.cpp:112] Iteration 11500, lr = 0.001
I0429 15:11:19.504797 25258 solver.cpp:239] Iteration 11520 (4.1721 iter/s, 4.79375s/20 iters), loss = 0.4935
I0429 15:11:19.508383 25258 solver.cpp:258]     Train net output #0: loss = 0.4935 (* 1 = 0.4935 loss)
I0429 15:11:19.508450 25258 sgd_solver.cpp:112] Iteration 11520, lr = 0.001
I0429 15:11:25.328577 25258 solver.cpp:239] Iteration 11540 (3.4364 iter/s, 5.82004s/20 iters), loss = 0.574548
I0429 15:11:25.328655 25258 solver.cpp:258]     Train net output #0: loss = 0.574548 (* 1 = 0.574548 loss)
I0429 15:11:25.328671 25258 sgd_solver.cpp:112] Iteration 11540, lr = 0.001
I0429 15:11:32.400264 25258 solver.cpp:239] Iteration 11560 (2.8283 iter/s, 7.07138s/20 iters), loss = 0.383483
I0429 15:11:32.405233 25258 solver.cpp:258]     Train net output #0: loss = 0.383483 (* 1 = 0.383483 loss)
I0429 15:11:32.405274 25258 sgd_solver.cpp:112] Iteration 11560, lr = 0.001
I0429 15:11:36.808251 25258 solver.cpp:239] Iteration 11580 (4.54247 iter/s, 4.40289s/20 iters), loss = 0.492315
I0429 15:11:36.813606 25258 solver.cpp:258]     Train net output #0: loss = 0.492315 (* 1 = 0.492315 loss)
I0429 15:11:36.813627 25258 sgd_solver.cpp:112] Iteration 11580, lr = 0.001
I0429 15:11:43.310271 25258 solver.cpp:239] Iteration 11600 (3.07859 iter/s, 6.49647s/20 iters), loss = 0.470357
I0429 15:11:43.315775 25258 solver.cpp:258]     Train net output #0: loss = 0.470357 (* 1 = 0.470357 loss)
I0429 15:11:43.315848 25258 sgd_solver.cpp:112] Iteration 11600, lr = 0.001
I0429 15:11:49.404541 25258 solver.cpp:239] Iteration 11620 (3.28482 iter/s, 6.0886s/20 iters), loss = 0.438081
I0429 15:11:49.409893 25258 solver.cpp:258]     Train net output #0: loss = 0.438081 (* 1 = 0.438081 loss)
I0429 15:11:49.409940 25258 sgd_solver.cpp:112] Iteration 11620, lr = 0.001
I0429 15:11:54.818099 25258 solver.cpp:239] Iteration 11640 (3.69818 iter/s, 5.40806s/20 iters), loss = 0.350694
I0429 15:11:54.823699 25258 solver.cpp:258]     Train net output #0: loss = 0.350694 (* 1 = 0.350694 loss)
I0429 15:11:54.823755 25258 sgd_solver.cpp:112] Iteration 11640, lr = 0.001
I0429 15:12:00.527642 25258 solver.cpp:239] Iteration 11660 (3.50643 iter/s, 5.70381s/20 iters), loss = 0.611426
I0429 15:12:00.532913 25258 solver.cpp:258]     Train net output #0: loss = 0.611426 (* 1 = 0.611426 loss)
I0429 15:12:00.532972 25258 sgd_solver.cpp:112] Iteration 11660, lr = 0.001
I0429 15:12:06.825834 25258 solver.cpp:239] Iteration 11680 (3.17826 iter/s, 6.29275s/20 iters), loss = 0.366292
I0429 15:12:06.831557 25258 solver.cpp:258]     Train net output #0: loss = 0.366292 (* 1 = 0.366292 loss)
I0429 15:12:06.831586 25258 sgd_solver.cpp:112] Iteration 11680, lr = 0.001
I0429 15:12:13.826205 25258 solver.cpp:239] Iteration 11700 (2.85942 iter/s, 6.99442s/20 iters), loss = 0.408383
I0429 15:12:13.832561 25258 solver.cpp:258]     Train net output #0: loss = 0.408383 (* 1 = 0.408383 loss)
I0429 15:12:13.832610 25258 sgd_solver.cpp:112] Iteration 11700, lr = 0.001
I0429 15:12:20.760162 25258 solver.cpp:239] Iteration 11720 (2.88707 iter/s, 6.92743s/20 iters), loss = 0.419713
I0429 15:12:20.766485 25258 solver.cpp:258]     Train net output #0: loss = 0.419713 (* 1 = 0.419713 loss)
I0429 15:12:20.766554 25258 sgd_solver.cpp:112] Iteration 11720, lr = 0.001
I0429 15:12:26.542937 25258 solver.cpp:239] Iteration 11740 (3.46245 iter/s, 5.77625s/20 iters), loss = 0.392561
I0429 15:12:26.543048 25258 solver.cpp:258]     Train net output #0: loss = 0.392561 (* 1 = 0.392561 loss)
I0429 15:12:26.543059 25258 sgd_solver.cpp:112] Iteration 11740, lr = 0.001
I0429 15:12:28.885593 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_11750.caffemodel
I0429 15:12:52.761637 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_11750.solverstate
I0429 15:12:53.150036 25258 solver.cpp:351] Iteration 11750, Testing net (#0)
I0429 15:12:57.613682 25258 blocking_queue.cpp:49] Waiting for data
I0429 15:13:04.812438 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:13:08.979267 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.812422
I0429 15:13:08.979331 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.923281
I0429 15:13:08.979348 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.9675
I0429 15:13:08.979368 25258 solver.cpp:418]     Test net output #3: loss = 0.479005 (* 1 = 0.479005 loss)
I0429 15:13:12.707448 25258 solver.cpp:239] Iteration 11760 (0.433247 iter/s, 46.1631s/20 iters), loss = 0.487881
I0429 15:13:12.712620 25258 solver.cpp:258]     Train net output #0: loss = 0.487881 (* 1 = 0.487881 loss)
I0429 15:13:12.712653 25258 sgd_solver.cpp:112] Iteration 11760, lr = 0.001
I0429 15:13:19.511600 25258 solver.cpp:239] Iteration 11780 (2.9417 iter/s, 6.79878s/20 iters), loss = 0.455776
I0429 15:13:19.520952 25258 solver.cpp:258]     Train net output #0: loss = 0.455776 (* 1 = 0.455776 loss)
I0429 15:13:19.521000 25258 sgd_solver.cpp:112] Iteration 11780, lr = 0.001
I0429 15:13:25.806265 25258 solver.cpp:239] Iteration 11800 (3.18211 iter/s, 6.28514s/20 iters), loss = 0.413945
I0429 15:13:25.812925 25258 solver.cpp:258]     Train net output #0: loss = 0.413945 (* 1 = 0.413945 loss)
I0429 15:13:25.812945 25258 sgd_solver.cpp:112] Iteration 11800, lr = 0.001
I0429 15:13:32.258908 25258 solver.cpp:239] Iteration 11820 (3.1028 iter/s, 6.44579s/20 iters), loss = 0.408009
I0429 15:13:32.264248 25258 solver.cpp:258]     Train net output #0: loss = 0.408009 (* 1 = 0.408009 loss)
I0429 15:13:32.264295 25258 sgd_solver.cpp:112] Iteration 11820, lr = 0.001
I0429 15:13:39.534277 25258 solver.cpp:239] Iteration 11840 (2.75208 iter/s, 7.26723s/20 iters), loss = 0.340263
I0429 15:13:39.537389 25258 solver.cpp:258]     Train net output #0: loss = 0.340263 (* 1 = 0.340263 loss)
I0429 15:13:39.537418 25258 sgd_solver.cpp:112] Iteration 11840, lr = 0.001
I0429 15:13:47.155300 25258 solver.cpp:239] Iteration 11860 (2.62547 iter/s, 7.61769s/20 iters), loss = 0.436063
I0429 15:13:47.160610 25258 solver.cpp:258]     Train net output #0: loss = 0.436063 (* 1 = 0.436063 loss)
I0429 15:13:47.162580 25258 sgd_solver.cpp:112] Iteration 11860, lr = 0.001
I0429 15:13:52.939538 25258 solver.cpp:239] Iteration 11880 (3.46094 iter/s, 5.77877s/20 iters), loss = 0.417417
I0429 15:13:52.945117 25258 solver.cpp:258]     Train net output #0: loss = 0.417417 (* 1 = 0.417417 loss)
I0429 15:13:52.945232 25258 sgd_solver.cpp:112] Iteration 11880, lr = 0.001
I0429 15:14:00.076452 25258 solver.cpp:239] Iteration 11900 (2.80457 iter/s, 7.13121s/20 iters), loss = 0.408918
I0429 15:14:00.085947 25258 solver.cpp:258]     Train net output #0: loss = 0.408918 (* 1 = 0.408918 loss)
I0429 15:14:00.086007 25258 sgd_solver.cpp:112] Iteration 11900, lr = 0.001
I0429 15:14:06.809798 25258 solver.cpp:239] Iteration 11920 (2.97593 iter/s, 6.72058s/20 iters), loss = 0.366572
I0429 15:14:06.812142 25258 solver.cpp:258]     Train net output #0: loss = 0.366572 (* 1 = 0.366572 loss)
I0429 15:14:06.812224 25258 sgd_solver.cpp:112] Iteration 11920, lr = 0.001
I0429 15:14:13.439363 25258 solver.cpp:239] Iteration 11940 (3.01792 iter/s, 6.62707s/20 iters), loss = 0.489375
I0429 15:14:13.439451 25258 solver.cpp:258]     Train net output #0: loss = 0.489375 (* 1 = 0.489375 loss)
I0429 15:14:13.439466 25258 sgd_solver.cpp:112] Iteration 11940, lr = 0.001
I0429 15:14:18.819428 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:14:19.089849 25258 solver.cpp:239] Iteration 11960 (3.541 iter/s, 5.64811s/20 iters), loss = 0.420948
I0429 15:14:19.089936 25258 solver.cpp:258]     Train net output #0: loss = 0.420948 (* 1 = 0.420948 loss)
I0429 15:14:19.089954 25258 sgd_solver.cpp:112] Iteration 11960, lr = 0.001
I0429 15:14:25.791369 25258 solver.cpp:239] Iteration 11980 (2.98453 iter/s, 6.70122s/20 iters), loss = 0.43035
I0429 15:14:25.796712 25258 solver.cpp:258]     Train net output #0: loss = 0.43035 (* 1 = 0.43035 loss)
I0429 15:14:25.796766 25258 sgd_solver.cpp:112] Iteration 11980, lr = 0.001
I0429 15:14:32.977845 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_12000.caffemodel
I0429 15:15:05.518117 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_12000.solverstate
I0429 15:15:05.923791 25258 solver.cpp:351] Iteration 12000, Testing net (#0)
I0429 15:15:19.094919 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:15:22.306133 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.817891
I0429 15:15:22.306223 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.927734
I0429 15:15:22.306236 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.96875
I0429 15:15:22.306251 25258 solver.cpp:418]     Test net output #3: loss = 0.462977 (* 1 = 0.462977 loss)
I0429 15:15:22.449512 25258 solver.cpp:239] Iteration 12000 (0.353037 iter/s, 56.6512s/20 iters), loss = 0.442684
I0429 15:15:22.453892 25258 solver.cpp:258]     Train net output #0: loss = 0.442684 (* 1 = 0.442684 loss)
I0429 15:15:22.453945 25258 sgd_solver.cpp:112] Iteration 12000, lr = 0.001
I0429 15:15:29.813535 25258 solver.cpp:239] Iteration 12020 (2.71759 iter/s, 7.35947s/20 iters), loss = 0.39022
I0429 15:15:29.818572 25258 solver.cpp:258]     Train net output #0: loss = 0.39022 (* 1 = 0.39022 loss)
I0429 15:15:29.818605 25258 sgd_solver.cpp:112] Iteration 12020, lr = 0.001
I0429 15:15:35.747900 25258 solver.cpp:239] Iteration 12040 (3.37316 iter/s, 5.92915s/20 iters), loss = 0.404294
I0429 15:15:35.782943 25258 solver.cpp:258]     Train net output #0: loss = 0.404294 (* 1 = 0.404294 loss)
I0429 15:15:35.782969 25258 sgd_solver.cpp:112] Iteration 12040, lr = 0.001
I0429 15:15:41.011929 25258 solver.cpp:239] Iteration 12060 (3.82495 iter/s, 5.22883s/20 iters), loss = 0.422897
I0429 15:15:41.017638 25258 solver.cpp:258]     Train net output #0: loss = 0.422897 (* 1 = 0.422897 loss)
I0429 15:15:41.017694 25258 sgd_solver.cpp:112] Iteration 12060, lr = 0.001
I0429 15:15:48.189551 25258 solver.cpp:239] Iteration 12080 (2.78872 iter/s, 7.17174s/20 iters), loss = 0.407361
I0429 15:15:48.194715 25258 solver.cpp:258]     Train net output #0: loss = 0.407361 (* 1 = 0.407361 loss)
I0429 15:15:48.194754 25258 sgd_solver.cpp:112] Iteration 12080, lr = 0.001
I0429 15:15:55.476294 25258 solver.cpp:239] Iteration 12100 (2.74674 iter/s, 7.28135s/20 iters), loss = 0.466168
I0429 15:15:55.483777 25258 solver.cpp:258]     Train net output #0: loss = 0.466168 (* 1 = 0.466168 loss)
I0429 15:15:55.483822 25258 sgd_solver.cpp:112] Iteration 12100, lr = 0.001
I0429 15:16:01.916302 25258 solver.cpp:239] Iteration 12120 (3.10929 iter/s, 6.43234s/20 iters), loss = 0.372589
I0429 15:16:01.922982 25258 solver.cpp:258]     Train net output #0: loss = 0.372589 (* 1 = 0.372589 loss)
I0429 15:16:01.923081 25258 sgd_solver.cpp:112] Iteration 12120, lr = 0.001
I0429 15:16:08.358928 25258 solver.cpp:239] Iteration 12140 (3.10765 iter/s, 6.43573s/20 iters), loss = 0.390631
I0429 15:16:08.372822 25258 solver.cpp:258]     Train net output #0: loss = 0.390631 (* 1 = 0.390631 loss)
I0429 15:16:08.372874 25258 sgd_solver.cpp:112] Iteration 12140, lr = 0.001
I0429 15:16:15.295429 25258 solver.cpp:239] Iteration 12160 (2.88915 iter/s, 6.92245s/20 iters), loss = 0.405931
I0429 15:16:15.300688 25258 solver.cpp:258]     Train net output #0: loss = 0.405931 (* 1 = 0.405931 loss)
I0429 15:16:15.300740 25258 sgd_solver.cpp:112] Iteration 12160, lr = 0.001
I0429 15:16:22.255985 25258 solver.cpp:239] Iteration 12180 (2.87558 iter/s, 6.95511s/20 iters), loss = 0.453692
I0429 15:16:22.256043 25258 solver.cpp:258]     Train net output #0: loss = 0.453692 (* 1 = 0.453692 loss)
I0429 15:16:22.256055 25258 sgd_solver.cpp:112] Iteration 12180, lr = 0.001
I0429 15:16:29.001315 25258 solver.cpp:239] Iteration 12200 (2.96513 iter/s, 6.74506s/20 iters), loss = 0.298726
I0429 15:16:29.006363 25258 solver.cpp:258]     Train net output #0: loss = 0.298726 (* 1 = 0.298726 loss)
I0429 15:16:29.006402 25258 sgd_solver.cpp:112] Iteration 12200, lr = 0.001
I0429 15:16:37.128384 25258 solver.cpp:239] Iteration 12220 (2.46251 iter/s, 8.12179s/20 iters), loss = 0.376648
I0429 15:16:37.133821 25258 solver.cpp:258]     Train net output #0: loss = 0.376648 (* 1 = 0.376648 loss)
I0429 15:16:37.133867 25258 sgd_solver.cpp:112] Iteration 12220, lr = 0.001
I0429 15:16:44.136564 25258 solver.cpp:239] Iteration 12240 (2.8561 iter/s, 7.00255s/20 iters), loss = 0.358965
I0429 15:16:44.141825 25258 solver.cpp:258]     Train net output #0: loss = 0.358965 (* 1 = 0.358965 loss)
I0429 15:16:44.141866 25258 sgd_solver.cpp:112] Iteration 12240, lr = 0.001
I0429 15:16:47.046231 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_12250.caffemodel
I0429 15:17:18.988639 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_12250.solverstate
I0429 15:17:19.356740 25258 solver.cpp:351] Iteration 12250, Testing net (#0)
I0429 15:17:36.406461 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:17:39.248091 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.829063
I0429 15:17:39.248157 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.931719
I0429 15:17:39.248167 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.969063
I0429 15:17:39.248180 25258 solver.cpp:418]     Test net output #3: loss = 0.440214 (* 1 = 0.440214 loss)
I0429 15:17:42.881384 25258 solver.cpp:239] Iteration 12260 (0.340496 iter/s, 58.7379s/20 iters), loss = 0.389838
I0429 15:17:42.881466 25258 solver.cpp:258]     Train net output #0: loss = 0.389838 (* 1 = 0.389838 loss)
I0429 15:17:42.881489 25258 sgd_solver.cpp:112] Iteration 12260, lr = 0.001
I0429 15:17:49.467869 25258 solver.cpp:239] Iteration 12280 (3.03665 iter/s, 6.5862s/20 iters), loss = 0.465517
I0429 15:17:49.477818 25258 solver.cpp:258]     Train net output #0: loss = 0.465517 (* 1 = 0.465517 loss)
I0429 15:17:49.477871 25258 sgd_solver.cpp:112] Iteration 12280, lr = 0.001
I0429 15:17:55.250644 25258 solver.cpp:239] Iteration 12300 (3.46455 iter/s, 5.77276s/20 iters), loss = 0.423667
I0429 15:17:55.250733 25258 solver.cpp:258]     Train net output #0: loss = 0.423667 (* 1 = 0.423667 loss)
I0429 15:17:55.250749 25258 sgd_solver.cpp:112] Iteration 12300, lr = 0.001
I0429 15:18:01.145678 25258 solver.cpp:239] Iteration 12320 (3.39273 iter/s, 5.89497s/20 iters), loss = 0.506134
I0429 15:18:01.150851 25258 solver.cpp:258]     Train net output #0: loss = 0.506134 (* 1 = 0.506134 loss)
I0429 15:18:01.150887 25258 sgd_solver.cpp:112] Iteration 12320, lr = 0.001
I0429 15:18:07.166318 25258 solver.cpp:239] Iteration 12340 (3.32475 iter/s, 6.01548s/20 iters), loss = 0.380996
I0429 15:18:07.172646 25258 solver.cpp:258]     Train net output #0: loss = 0.380996 (* 1 = 0.380996 loss)
I0429 15:18:07.172700 25258 sgd_solver.cpp:112] Iteration 12340, lr = 0.001
I0429 15:18:13.687340 25258 solver.cpp:239] Iteration 12360 (3.06996 iter/s, 6.51475s/20 iters), loss = 0.343776
I0429 15:18:13.701943 25258 solver.cpp:258]     Train net output #0: loss = 0.343776 (* 1 = 0.343776 loss)
I0429 15:18:13.702060 25258 sgd_solver.cpp:112] Iteration 12360, lr = 0.001
I0429 15:18:16.097873 25258 solver.cpp:239] Iteration 12380 (8.34715 iter/s, 2.39603s/20 iters), loss = 0.406258
I0429 15:18:16.097939 25258 solver.cpp:258]     Train net output #0: loss = 0.406258 (* 1 = 0.406258 loss)
I0429 15:18:16.097954 25258 sgd_solver.cpp:112] Iteration 12380, lr = 0.001
I0429 15:18:24.990952 25258 solver.cpp:239] Iteration 12400 (2.24896 iter/s, 8.89301s/20 iters), loss = 0.478463
I0429 15:18:24.996275 25258 solver.cpp:258]     Train net output #0: loss = 0.478463 (* 1 = 0.478463 loss)
I0429 15:18:24.996312 25258 sgd_solver.cpp:112] Iteration 12400, lr = 0.001
I0429 15:18:33.411093 25258 solver.cpp:239] Iteration 12420 (2.37675 iter/s, 8.41485s/20 iters), loss = 0.346872
I0429 15:18:33.416868 25258 solver.cpp:258]     Train net output #0: loss = 0.346872 (* 1 = 0.346872 loss)
I0429 15:18:33.416913 25258 sgd_solver.cpp:112] Iteration 12420, lr = 0.001
I0429 15:18:40.033810 25258 solver.cpp:239] Iteration 12440 (3.02253 iter/s, 6.61697s/20 iters), loss = 0.358499
I0429 15:18:40.039369 25258 solver.cpp:258]     Train net output #0: loss = 0.358499 (* 1 = 0.358499 loss)
I0429 15:18:40.039422 25258 sgd_solver.cpp:112] Iteration 12440, lr = 0.001
I0429 15:18:48.374830 25258 solver.cpp:239] Iteration 12460 (2.39938 iter/s, 8.33549s/20 iters), loss = 0.387826
I0429 15:18:48.382184 25258 solver.cpp:258]     Train net output #0: loss = 0.387826 (* 1 = 0.387826 loss)
I0429 15:18:48.382316 25258 sgd_solver.cpp:112] Iteration 12460, lr = 0.001
I0429 15:18:54.495834 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:18:55.789541 25258 solver.cpp:239] Iteration 12480 (2.69998 iter/s, 7.40747s/20 iters), loss = 0.425095
I0429 15:18:55.795089 25258 solver.cpp:258]     Train net output #0: loss = 0.425095 (* 1 = 0.425095 loss)
I0429 15:18:55.795126 25258 sgd_solver.cpp:112] Iteration 12480, lr = 0.001
I0429 15:19:02.441905 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_12500.caffemodel
I0429 15:19:36.527577 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_12500.solverstate
I0429 15:19:36.956972 25258 solver.cpp:351] Iteration 12500, Testing net (#0)
I0429 15:19:56.688695 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:19:59.744467 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.836172
I0429 15:19:59.744529 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.935313
I0429 15:19:59.744563 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.971484
I0429 15:19:59.744581 25258 solver.cpp:418]     Test net output #3: loss = 0.423993 (* 1 = 0.423993 loss)
I0429 15:19:59.888746 25258 solver.cpp:239] Iteration 12500 (0.312043 iter/s, 64.0938s/20 iters), loss = 0.302591
I0429 15:19:59.888823 25258 solver.cpp:258]     Train net output #0: loss = 0.302591 (* 1 = 0.302591 loss)
I0429 15:19:59.888840 25258 sgd_solver.cpp:112] Iteration 12500, lr = 0.001
I0429 15:20:06.445430 25258 solver.cpp:239] Iteration 12520 (3.05037 iter/s, 6.55659s/20 iters), loss = 0.329119
I0429 15:20:06.445492 25258 solver.cpp:258]     Train net output #0: loss = 0.329119 (* 1 = 0.329119 loss)
I0429 15:20:06.445502 25258 sgd_solver.cpp:112] Iteration 12520, lr = 0.001
I0429 15:20:13.606428 25258 solver.cpp:239] Iteration 12540 (2.79294 iter/s, 7.16091s/20 iters), loss = 0.34831
I0429 15:20:13.613775 25258 solver.cpp:258]     Train net output #0: loss = 0.34831 (* 1 = 0.34831 loss)
I0429 15:20:13.613806 25258 sgd_solver.cpp:112] Iteration 12540, lr = 0.001
I0429 15:20:20.102373 25258 solver.cpp:239] Iteration 12560 (3.08233 iter/s, 6.48859s/20 iters), loss = 0.330342
I0429 15:20:20.109154 25258 solver.cpp:258]     Train net output #0: loss = 0.330342 (* 1 = 0.330342 loss)
I0429 15:20:20.109192 25258 sgd_solver.cpp:112] Iteration 12560, lr = 0.001
I0429 15:20:25.959728 25258 solver.cpp:239] Iteration 12580 (3.41847 iter/s, 5.85057s/20 iters), loss = 0.445352
I0429 15:20:25.959795 25258 solver.cpp:258]     Train net output #0: loss = 0.445352 (* 1 = 0.445352 loss)
I0429 15:20:25.959807 25258 sgd_solver.cpp:112] Iteration 12580, lr = 0.001
I0429 15:20:28.195242 25258 solver.cpp:239] Iteration 12600 (8.94685 iter/s, 2.23542s/20 iters), loss = 0.30779
I0429 15:20:28.195338 25258 solver.cpp:258]     Train net output #0: loss = 0.30779 (* 1 = 0.30779 loss)
I0429 15:20:28.195356 25258 sgd_solver.cpp:112] Iteration 12600, lr = 0.001
I0429 15:20:36.401382 25258 solver.cpp:239] Iteration 12620 (2.43749 iter/s, 8.20515s/20 iters), loss = 0.368604
I0429 15:20:36.405622 25258 solver.cpp:258]     Train net output #0: loss = 0.368604 (* 1 = 0.368604 loss)
I0429 15:20:36.405654 25258 sgd_solver.cpp:112] Iteration 12620, lr = 0.001
I0429 15:20:44.315572 25258 solver.cpp:239] Iteration 12640 (2.52846 iter/s, 7.90994s/20 iters), loss = 0.350064
I0429 15:20:44.324940 25258 solver.cpp:258]     Train net output #0: loss = 0.350064 (* 1 = 0.350064 loss)
I0429 15:20:44.324980 25258 sgd_solver.cpp:112] Iteration 12640, lr = 0.001
I0429 15:20:51.630825 25258 solver.cpp:239] Iteration 12660 (2.73752 iter/s, 7.30588s/20 iters), loss = 0.355509
I0429 15:20:51.635928 25258 solver.cpp:258]     Train net output #0: loss = 0.355509 (* 1 = 0.355509 loss)
I0429 15:20:51.635962 25258 sgd_solver.cpp:112] Iteration 12660, lr = 0.001
I0429 15:20:58.166213 25258 solver.cpp:239] Iteration 12680 (3.06266 iter/s, 6.53026s/20 iters), loss = 0.347868
I0429 15:20:58.172878 25258 solver.cpp:258]     Train net output #0: loss = 0.347868 (* 1 = 0.347868 loss)
I0429 15:20:58.172931 25258 sgd_solver.cpp:112] Iteration 12680, lr = 0.001
I0429 15:21:06.168611 25258 solver.cpp:239] Iteration 12700 (2.50134 iter/s, 7.99572s/20 iters), loss = 0.467861
I0429 15:21:06.168687 25258 solver.cpp:258]     Train net output #0: loss = 0.467861 (* 1 = 0.467861 loss)
I0429 15:21:06.168704 25258 sgd_solver.cpp:112] Iteration 12700, lr = 0.001
I0429 15:21:12.720079 25258 solver.cpp:239] Iteration 12720 (3.05281 iter/s, 6.55135s/20 iters), loss = 0.2844
I0429 15:21:12.725196 25258 solver.cpp:258]     Train net output #0: loss = 0.2844 (* 1 = 0.2844 loss)
I0429 15:21:12.725237 25258 sgd_solver.cpp:112] Iteration 12720, lr = 0.001
I0429 15:21:17.982661 25258 blocking_queue.cpp:49] Waiting for data
I0429 15:21:20.486088 25258 solver.cpp:239] Iteration 12740 (2.57703 iter/s, 7.76087s/20 iters), loss = 0.443985
I0429 15:21:20.491091 25258 solver.cpp:258]     Train net output #0: loss = 0.443985 (* 1 = 0.443985 loss)
I0429 15:21:20.491127 25258 sgd_solver.cpp:112] Iteration 12740, lr = 0.001
I0429 15:21:24.129199 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_12750.caffemodel
I0429 15:21:56.392217 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_12750.solverstate
I0429 15:21:56.962091 25258 solver.cpp:351] Iteration 12750, Testing net (#0)
I0429 15:22:17.182317 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:22:19.983958 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.840156
I0429 15:22:19.984056 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.935469
I0429 15:22:19.984071 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.970781
I0429 15:22:19.984088 25258 solver.cpp:418]     Test net output #3: loss = 0.416499 (* 1 = 0.416499 loss)
I0429 15:22:23.158931 25258 solver.cpp:239] Iteration 12760 (0.319144 iter/s, 62.6676s/20 iters), loss = 0.387454
I0429 15:22:23.164116 25258 solver.cpp:258]     Train net output #0: loss = 0.387454 (* 1 = 0.387454 loss)
I0429 15:22:23.164170 25258 sgd_solver.cpp:112] Iteration 12760, lr = 0.001
I0429 15:22:29.232895 25258 solver.cpp:239] Iteration 12780 (3.29558 iter/s, 6.06874s/20 iters), loss = 0.387805
I0429 15:22:29.238350 25258 solver.cpp:258]     Train net output #0: loss = 0.387805 (* 1 = 0.387805 loss)
I0429 15:22:29.238394 25258 sgd_solver.cpp:112] Iteration 12780, lr = 0.001
I0429 15:22:36.443683 25258 solver.cpp:239] Iteration 12800 (2.77574 iter/s, 7.20529s/20 iters), loss = 0.416025
I0429 15:22:36.448595 25258 solver.cpp:258]     Train net output #0: loss = 0.416025 (* 1 = 0.416025 loss)
I0429 15:22:36.448622 25258 sgd_solver.cpp:112] Iteration 12800, lr = 0.001
I0429 15:22:43.013784 25258 solver.cpp:239] Iteration 12820 (3.04641 iter/s, 6.5651s/20 iters), loss = 0.376182
I0429 15:22:43.020213 25258 solver.cpp:258]     Train net output #0: loss = 0.376182 (* 1 = 0.376182 loss)
I0429 15:22:43.020296 25258 sgd_solver.cpp:112] Iteration 12820, lr = 0.001
I0429 15:22:50.958016 25258 solver.cpp:239] Iteration 12840 (2.51959 iter/s, 7.93779s/20 iters), loss = 0.448215
I0429 15:22:50.963367 25258 solver.cpp:258]     Train net output #0: loss = 0.448215 (* 1 = 0.448215 loss)
I0429 15:22:50.963414 25258 sgd_solver.cpp:112] Iteration 12840, lr = 0.001
I0429 15:22:57.306051 25258 solver.cpp:239] Iteration 12860 (3.15326 iter/s, 6.34265s/20 iters), loss = 0.447716
I0429 15:22:57.313302 25258 solver.cpp:258]     Train net output #0: loss = 0.447716 (* 1 = 0.447716 loss)
I0429 15:22:57.313372 25258 sgd_solver.cpp:112] Iteration 12860, lr = 0.001
I0429 15:23:03.684165 25258 solver.cpp:239] Iteration 12880 (3.1393 iter/s, 6.37084s/20 iters), loss = 0.329371
I0429 15:23:03.690690 25258 solver.cpp:258]     Train net output #0: loss = 0.329371 (* 1 = 0.329371 loss)
I0429 15:23:03.690758 25258 sgd_solver.cpp:112] Iteration 12880, lr = 0.001
I0429 15:23:10.491495 25258 solver.cpp:239] Iteration 12900 (2.94083 iter/s, 6.80079s/20 iters), loss = 0.382763
I0429 15:23:10.491575 25258 solver.cpp:258]     Train net output #0: loss = 0.382763 (* 1 = 0.382763 loss)
I0429 15:23:10.491608 25258 sgd_solver.cpp:112] Iteration 12900, lr = 0.001
I0429 15:23:17.721796 25258 solver.cpp:239] Iteration 12920 (2.76706 iter/s, 7.22788s/20 iters), loss = 0.306843
I0429 15:23:17.729818 25258 solver.cpp:258]     Train net output #0: loss = 0.306843 (* 1 = 0.306843 loss)
I0429 15:23:17.729861 25258 sgd_solver.cpp:112] Iteration 12920, lr = 0.001
I0429 15:23:24.795765 25258 solver.cpp:239] Iteration 12940 (2.83051 iter/s, 7.06587s/20 iters), loss = 0.295709
I0429 15:23:24.800755 25258 solver.cpp:258]     Train net output #0: loss = 0.295709 (* 1 = 0.295709 loss)
I0429 15:23:24.800791 25258 sgd_solver.cpp:112] Iteration 12940, lr = 0.001
I0429 15:23:33.382391 25258 solver.cpp:239] Iteration 12960 (2.33058 iter/s, 8.58157s/20 iters), loss = 0.348495
I0429 15:23:33.387581 25258 solver.cpp:258]     Train net output #0: loss = 0.348495 (* 1 = 0.348495 loss)
I0429 15:23:33.387630 25258 sgd_solver.cpp:112] Iteration 12960, lr = 0.001
I0429 15:23:40.829879 25258 solver.cpp:239] Iteration 12980 (2.68736 iter/s, 7.44224s/20 iters), loss = 0.449433
I0429 15:23:40.835269 25258 solver.cpp:258]     Train net output #0: loss = 0.449433 (* 1 = 0.449433 loss)
I0429 15:23:40.835309 25258 sgd_solver.cpp:112] Iteration 12980, lr = 0.001
I0429 15:23:48.231981 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:23:48.729861 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_13000.caffemodel
I0429 15:24:31.215319 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_13000.solverstate
I0429 15:24:31.578622 25258 solver.cpp:351] Iteration 13000, Testing net (#0)
I0429 15:24:43.571172 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:24:45.052404 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.849922
I0429 15:24:45.055424 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.938203
I0429 15:24:45.055451 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.972656
I0429 15:24:45.055466 25258 solver.cpp:418]     Test net output #3: loss = 0.394867 (* 1 = 0.394867 loss)
I0429 15:24:45.178814 25258 solver.cpp:239] Iteration 13000 (0.310834 iter/s, 64.343s/20 iters), loss = 0.341372
I0429 15:24:45.178915 25258 solver.cpp:258]     Train net output #0: loss = 0.341372 (* 1 = 0.341372 loss)
I0429 15:24:45.178936 25258 sgd_solver.cpp:112] Iteration 13000, lr = 0.001
I0429 15:24:52.248984 25258 solver.cpp:239] Iteration 13020 (2.82887 iter/s, 7.06996s/20 iters), loss = 0.343958
I0429 15:24:52.254642 25258 solver.cpp:258]     Train net output #0: loss = 0.343958 (* 1 = 0.343958 loss)
I0429 15:24:52.254684 25258 sgd_solver.cpp:112] Iteration 13020, lr = 0.001
I0429 15:24:59.499480 25258 solver.cpp:239] Iteration 13040 (2.76062 iter/s, 7.24476s/20 iters), loss = 0.4759
I0429 15:24:59.505023 25258 solver.cpp:258]     Train net output #0: loss = 0.4759 (* 1 = 0.4759 loss)
I0429 15:24:59.505060 25258 sgd_solver.cpp:112] Iteration 13040, lr = 0.001
I0429 15:25:05.031046 25258 solver.cpp:239] Iteration 13060 (3.61929 iter/s, 5.52595s/20 iters), loss = 0.306244
I0429 15:25:05.040444 25258 solver.cpp:258]     Train net output #0: loss = 0.306244 (* 1 = 0.306244 loss)
I0429 15:25:05.040506 25258 sgd_solver.cpp:112] Iteration 13060, lr = 0.001
I0429 15:25:11.824888 25258 solver.cpp:239] Iteration 13080 (2.94795 iter/s, 6.78437s/20 iters), loss = 0.345918
I0429 15:25:11.831218 25258 solver.cpp:258]     Train net output #0: loss = 0.345918 (* 1 = 0.345918 loss)
I0429 15:25:11.831284 25258 sgd_solver.cpp:112] Iteration 13080, lr = 0.001
I0429 15:25:19.707254 25258 solver.cpp:239] Iteration 13100 (2.53937 iter/s, 7.87598s/20 iters), loss = 0.487682
I0429 15:25:19.713852 25258 solver.cpp:258]     Train net output #0: loss = 0.487682 (* 1 = 0.487682 loss)
I0429 15:25:19.713893 25258 sgd_solver.cpp:112] Iteration 13100, lr = 0.001
I0429 15:25:27.068799 25258 solver.cpp:239] Iteration 13120 (2.71929 iter/s, 7.35486s/20 iters), loss = 0.385155
I0429 15:25:27.074612 25258 solver.cpp:258]     Train net output #0: loss = 0.385155 (* 1 = 0.385155 loss)
I0429 15:25:27.074702 25258 sgd_solver.cpp:112] Iteration 13120, lr = 0.001
I0429 15:25:34.226642 25258 solver.cpp:239] Iteration 13140 (2.79643 iter/s, 7.15196s/20 iters), loss = 0.44402
I0429 15:25:34.236052 25258 solver.cpp:258]     Train net output #0: loss = 0.44402 (* 1 = 0.44402 loss)
I0429 15:25:34.236129 25258 sgd_solver.cpp:112] Iteration 13140, lr = 0.001
I0429 15:25:42.219720 25258 solver.cpp:239] Iteration 13160 (2.50513 iter/s, 7.98361s/20 iters), loss = 0.360153
I0429 15:25:42.226341 25258 solver.cpp:258]     Train net output #0: loss = 0.360153 (* 1 = 0.360153 loss)
I0429 15:25:42.226377 25258 sgd_solver.cpp:112] Iteration 13160, lr = 0.001
I0429 15:25:49.988297 25258 solver.cpp:239] Iteration 13180 (2.5767 iter/s, 7.76186s/20 iters), loss = 0.33798
I0429 15:25:50.001787 25258 solver.cpp:258]     Train net output #0: loss = 0.33798 (* 1 = 0.33798 loss)
I0429 15:25:50.001827 25258 sgd_solver.cpp:112] Iteration 13180, lr = 0.001
I0429 15:25:57.888651 25258 solver.cpp:239] Iteration 13200 (2.53589 iter/s, 7.88678s/20 iters), loss = 0.296225
I0429 15:25:57.888720 25258 solver.cpp:258]     Train net output #0: loss = 0.296225 (* 1 = 0.296225 loss)
I0429 15:25:57.888734 25258 sgd_solver.cpp:112] Iteration 13200, lr = 0.001
I0429 15:26:04.611109 25258 solver.cpp:239] Iteration 13220 (2.97519 iter/s, 6.72225s/20 iters), loss = 0.458333
I0429 15:26:04.616645 25258 solver.cpp:258]     Train net output #0: loss = 0.458333 (* 1 = 0.458333 loss)
I0429 15:26:04.616701 25258 sgd_solver.cpp:112] Iteration 13220, lr = 0.001
I0429 15:26:12.656143 25258 solver.cpp:239] Iteration 13240 (2.48774 iter/s, 8.03944s/20 iters), loss = 0.24029
I0429 15:26:12.680105 25258 solver.cpp:258]     Train net output #0: loss = 0.24029 (* 1 = 0.24029 loss)
I0429 15:26:12.680127 25258 sgd_solver.cpp:112] Iteration 13240, lr = 0.001
I0429 15:26:16.184437 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_13250.caffemodel
I0429 15:26:54.941438 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_13250.solverstate
I0429 15:26:55.360687 25258 solver.cpp:351] Iteration 13250, Testing net (#0)
I0429 15:27:04.842842 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:27:07.321197 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.847344
I0429 15:27:07.321269 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.939375
I0429 15:27:07.321280 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.973359
I0429 15:27:07.321295 25258 solver.cpp:418]     Test net output #3: loss = 0.397938 (* 1 = 0.397938 loss)
I0429 15:27:10.125736 25258 solver.cpp:239] Iteration 13260 (0.348162 iter/s, 57.4445s/20 iters), loss = 0.302663
I0429 15:27:10.130753 25258 solver.cpp:258]     Train net output #0: loss = 0.302663 (* 1 = 0.302663 loss)
I0429 15:27:10.130810 25258 sgd_solver.cpp:112] Iteration 13260, lr = 0.001
I0429 15:27:17.463215 25258 solver.cpp:239] Iteration 13280 (2.72763 iter/s, 7.33237s/20 iters), loss = 0.265041
I0429 15:27:17.468152 25258 solver.cpp:258]     Train net output #0: loss = 0.265041 (* 1 = 0.265041 loss)
I0429 15:27:17.468189 25258 sgd_solver.cpp:112] Iteration 13280, lr = 0.001
I0429 15:27:23.861022 25258 solver.cpp:239] Iteration 13300 (3.12853 iter/s, 6.39278s/20 iters), loss = 0.276355
I0429 15:27:23.869803 25258 solver.cpp:258]     Train net output #0: loss = 0.276355 (* 1 = 0.276355 loss)
I0429 15:27:23.869850 25258 sgd_solver.cpp:112] Iteration 13300, lr = 0.001
I0429 15:27:29.989595 25258 solver.cpp:239] Iteration 13320 (3.26812 iter/s, 6.11972s/20 iters), loss = 0.405496
I0429 15:27:29.991309 25258 solver.cpp:258]     Train net output #0: loss = 0.405496 (* 1 = 0.405496 loss)
I0429 15:27:29.991329 25258 sgd_solver.cpp:112] Iteration 13320, lr = 0.001
I0429 15:27:36.867754 25258 solver.cpp:239] Iteration 13340 (2.90852 iter/s, 6.87634s/20 iters), loss = 0.264766
I0429 15:27:36.872895 25258 solver.cpp:258]     Train net output #0: loss = 0.264766 (* 1 = 0.264766 loss)
I0429 15:27:36.872941 25258 sgd_solver.cpp:112] Iteration 13340, lr = 0.001
I0429 15:27:44.593525 25258 solver.cpp:239] Iteration 13360 (2.5905 iter/s, 7.72052s/20 iters), loss = 0.402383
I0429 15:27:44.599817 25258 solver.cpp:258]     Train net output #0: loss = 0.402383 (* 1 = 0.402383 loss)
I0429 15:27:44.599880 25258 sgd_solver.cpp:112] Iteration 13360, lr = 0.001
I0429 15:27:52.357583 25258 solver.cpp:239] Iteration 13380 (2.57809 iter/s, 7.75769s/20 iters), loss = 0.395911
I0429 15:27:52.363909 25258 solver.cpp:258]     Train net output #0: loss = 0.395911 (* 1 = 0.395911 loss)
I0429 15:27:52.363965 25258 sgd_solver.cpp:112] Iteration 13380, lr = 0.001
I0429 15:27:59.641219 25258 solver.cpp:239] Iteration 13400 (2.7483 iter/s, 7.27722s/20 iters), loss = 0.298999
I0429 15:27:59.647058 25258 solver.cpp:258]     Train net output #0: loss = 0.298999 (* 1 = 0.298999 loss)
I0429 15:27:59.647117 25258 sgd_solver.cpp:112] Iteration 13400, lr = 0.001
I0429 15:28:06.759672 25258 solver.cpp:239] Iteration 13420 (2.81195 iter/s, 7.11251s/20 iters), loss = 0.358996
I0429 15:28:06.770110 25258 solver.cpp:258]     Train net output #0: loss = 0.358996 (* 1 = 0.358996 loss)
I0429 15:28:06.770164 25258 sgd_solver.cpp:112] Iteration 13420, lr = 0.001
I0429 15:28:14.613099 25258 solver.cpp:239] Iteration 13440 (2.55008 iter/s, 7.84289s/20 iters), loss = 0.348742
I0429 15:28:14.618120 25258 solver.cpp:258]     Train net output #0: loss = 0.348742 (* 1 = 0.348742 loss)
I0429 15:28:14.618155 25258 sgd_solver.cpp:112] Iteration 13440, lr = 0.001
I0429 15:28:21.736788 25258 solver.cpp:239] Iteration 13460 (2.80956 iter/s, 7.11855s/20 iters), loss = 0.262363
I0429 15:28:21.743003 25258 solver.cpp:258]     Train net output #0: loss = 0.262363 (* 1 = 0.262363 loss)
I0429 15:28:21.743073 25258 sgd_solver.cpp:112] Iteration 13460, lr = 0.001
I0429 15:28:28.973165 25258 solver.cpp:239] Iteration 13480 (2.76622 iter/s, 7.23008s/20 iters), loss = 0.291126
I0429 15:28:28.979256 25258 solver.cpp:258]     Train net output #0: loss = 0.291126 (* 1 = 0.291126 loss)
I0429 15:28:28.979300 25258 sgd_solver.cpp:112] Iteration 13480, lr = 0.001
I0429 15:28:36.015983 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_13500.caffemodel
I0429 15:29:21.226302 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_13500.solverstate
I0429 15:29:21.621809 25258 solver.cpp:351] Iteration 13500, Testing net (#0)
I0429 15:29:30.760265 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:29:32.749059 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.852813
I0429 15:29:32.749121 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.937344
I0429 15:29:32.749136 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.974297
I0429 15:29:32.749150 25258 solver.cpp:418]     Test net output #3: loss = 0.382616 (* 1 = 0.382616 loss)
I0429 15:29:33.088112 25258 solver.cpp:239] Iteration 13500 (0.311974 iter/s, 64.1079s/20 iters), loss = 0.371179
I0429 15:29:33.088520 25258 solver.cpp:258]     Train net output #0: loss = 0.371179 (* 1 = 0.371179 loss)
I0429 15:29:33.088537 25258 sgd_solver.cpp:112] Iteration 13500, lr = 0.001
I0429 15:29:36.482220 25258 blocking_queue.cpp:49] Waiting for data
I0429 15:29:38.138128 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:29:39.162149 25258 solver.cpp:239] Iteration 13520 (3.29299 iter/s, 6.07351s/20 iters), loss = 0.30613
I0429 15:29:39.162245 25258 solver.cpp:258]     Train net output #0: loss = 0.30613 (* 1 = 0.30613 loss)
I0429 15:29:39.162266 25258 sgd_solver.cpp:112] Iteration 13520, lr = 0.001
I0429 15:29:44.800168 25258 solver.cpp:239] Iteration 13540 (3.54748 iter/s, 5.6378s/20 iters), loss = 0.258546
I0429 15:29:44.809245 25258 solver.cpp:258]     Train net output #0: loss = 0.258546 (* 1 = 0.258546 loss)
I0429 15:29:44.809325 25258 sgd_solver.cpp:112] Iteration 13540, lr = 0.001
I0429 15:29:51.953362 25258 solver.cpp:239] Iteration 13560 (2.79954 iter/s, 7.14404s/20 iters), loss = 0.387776
I0429 15:29:51.958899 25258 solver.cpp:258]     Train net output #0: loss = 0.387776 (* 1 = 0.387776 loss)
I0429 15:29:51.958955 25258 sgd_solver.cpp:112] Iteration 13560, lr = 0.001
I0429 15:29:59.679339 25258 solver.cpp:239] Iteration 13580 (2.59057 iter/s, 7.7203s/20 iters), loss = 0.269677
I0429 15:29:59.686801 25258 solver.cpp:258]     Train net output #0: loss = 0.269677 (* 1 = 0.269677 loss)
I0429 15:29:59.686872 25258 sgd_solver.cpp:112] Iteration 13580, lr = 0.001
I0429 15:30:05.768714 25258 solver.cpp:239] Iteration 13600 (3.28846 iter/s, 6.08187s/20 iters), loss = 0.276166
I0429 15:30:05.773897 25258 solver.cpp:258]     Train net output #0: loss = 0.276166 (* 1 = 0.276166 loss)
I0429 15:30:05.773924 25258 sgd_solver.cpp:112] Iteration 13600, lr = 0.001
I0429 15:30:13.063554 25258 solver.cpp:239] Iteration 13620 (2.74366 iter/s, 7.28952s/20 iters), loss = 0.529973
I0429 15:30:13.069964 25258 solver.cpp:258]     Train net output #0: loss = 0.529973 (* 1 = 0.529973 loss)
I0429 15:30:13.070000 25258 sgd_solver.cpp:112] Iteration 13620, lr = 0.001
I0429 15:30:20.577949 25258 solver.cpp:239] Iteration 13640 (2.66388 iter/s, 7.50786s/20 iters), loss = 0.206241
I0429 15:30:20.583160 25258 solver.cpp:258]     Train net output #0: loss = 0.206241 (* 1 = 0.206241 loss)
I0429 15:30:20.583199 25258 sgd_solver.cpp:112] Iteration 13640, lr = 0.001
I0429 15:30:26.854595 25258 solver.cpp:239] Iteration 13660 (3.18911 iter/s, 6.27133s/20 iters), loss = 0.340665
I0429 15:30:26.859724 25258 solver.cpp:258]     Train net output #0: loss = 0.340665 (* 1 = 0.340665 loss)
I0429 15:30:26.859748 25258 sgd_solver.cpp:112] Iteration 13660, lr = 0.001
I0429 15:30:32.557229 25258 solver.cpp:239] Iteration 13680 (3.51037 iter/s, 5.6974s/20 iters), loss = 0.342057
I0429 15:30:32.565826 25258 solver.cpp:258]     Train net output #0: loss = 0.342057 (* 1 = 0.342057 loss)
I0429 15:30:32.565872 25258 sgd_solver.cpp:112] Iteration 13680, lr = 0.001
I0429 15:30:38.109293 25258 solver.cpp:239] Iteration 13700 (3.6079 iter/s, 5.54339s/20 iters), loss = 0.30997
I0429 15:30:38.116425 25258 solver.cpp:258]     Train net output #0: loss = 0.30997 (* 1 = 0.30997 loss)
I0429 15:30:38.116469 25258 sgd_solver.cpp:112] Iteration 13700, lr = 0.001
I0429 15:30:45.267099 25258 solver.cpp:239] Iteration 13720 (2.79698 iter/s, 7.15056s/20 iters), loss = 0.220921
I0429 15:30:45.267212 25258 solver.cpp:258]     Train net output #0: loss = 0.220921 (* 1 = 0.220921 loss)
I0429 15:30:45.267232 25258 sgd_solver.cpp:112] Iteration 13720, lr = 0.001
I0429 15:30:52.967185 25258 solver.cpp:239] Iteration 13740 (2.59746 iter/s, 7.69982s/20 iters), loss = 0.369235
I0429 15:30:52.972604 25258 solver.cpp:258]     Train net output #0: loss = 0.369235 (* 1 = 0.369235 loss)
I0429 15:30:52.972647 25258 sgd_solver.cpp:112] Iteration 13740, lr = 0.001
I0429 15:30:55.659564 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_13750.caffemodel
I0429 15:31:30.167548 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_13750.solverstate
I0429 15:31:30.517180 25258 solver.cpp:351] Iteration 13750, Testing net (#0)
I0429 15:31:40.740461 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:31:42.446841 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.860156
I0429 15:31:42.446910 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.942031
I0429 15:31:42.446920 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.973203
I0429 15:31:42.446933 25258 solver.cpp:418]     Test net output #3: loss = 0.368467 (* 1 = 0.368467 loss)
I0429 15:31:43.876852 25258 solver.cpp:239] Iteration 13760 (0.392901 iter/s, 50.9034s/20 iters), loss = 0.255209
I0429 15:31:43.876935 25258 solver.cpp:258]     Train net output #0: loss = 0.255209 (* 1 = 0.255209 loss)
I0429 15:31:43.879030 25258 sgd_solver.cpp:112] Iteration 13760, lr = 0.001
I0429 15:31:51.172561 25258 solver.cpp:239] Iteration 13780 (2.74143 iter/s, 7.29547s/20 iters), loss = 0.266002
I0429 15:31:51.177884 25258 solver.cpp:258]     Train net output #0: loss = 0.266002 (* 1 = 0.266002 loss)
I0429 15:31:51.177948 25258 sgd_solver.cpp:112] Iteration 13780, lr = 0.001
I0429 15:31:57.936416 25258 solver.cpp:239] Iteration 13800 (2.95927 iter/s, 6.75842s/20 iters), loss = 0.319625
I0429 15:31:57.941510 25258 solver.cpp:258]     Train net output #0: loss = 0.319625 (* 1 = 0.319625 loss)
I0429 15:31:57.941541 25258 sgd_solver.cpp:112] Iteration 13800, lr = 0.001
I0429 15:32:04.835204 25258 solver.cpp:239] Iteration 13820 (2.90126 iter/s, 6.89356s/20 iters), loss = 0.291625
I0429 15:32:04.842203 25258 solver.cpp:258]     Train net output #0: loss = 0.291625 (* 1 = 0.291625 loss)
I0429 15:32:04.842231 25258 sgd_solver.cpp:112] Iteration 13820, lr = 0.001
I0429 15:32:13.018973 25258 solver.cpp:239] Iteration 13840 (2.446 iter/s, 8.17661s/20 iters), loss = 0.344493
I0429 15:32:13.029803 25258 solver.cpp:258]     Train net output #0: loss = 0.344493 (* 1 = 0.344493 loss)
I0429 15:32:13.029839 25258 sgd_solver.cpp:112] Iteration 13840, lr = 0.001
I0429 15:32:19.739408 25258 solver.cpp:239] Iteration 13860 (2.98087 iter/s, 6.70945s/20 iters), loss = 0.266571
I0429 15:32:19.748695 25258 solver.cpp:258]     Train net output #0: loss = 0.266571 (* 1 = 0.266571 loss)
I0429 15:32:19.748836 25258 sgd_solver.cpp:112] Iteration 13860, lr = 0.001
I0429 15:32:26.621820 25258 solver.cpp:239] Iteration 13880 (2.90991 iter/s, 6.87306s/20 iters), loss = 0.352749
I0429 15:32:26.621948 25258 solver.cpp:258]     Train net output #0: loss = 0.352749 (* 1 = 0.352749 loss)
I0429 15:32:26.621968 25258 sgd_solver.cpp:112] Iteration 13880, lr = 0.001
I0429 15:32:32.329370 25258 solver.cpp:239] Iteration 13900 (3.50429 iter/s, 5.7073s/20 iters), loss = 0.330407
I0429 15:32:32.329453 25258 solver.cpp:258]     Train net output #0: loss = 0.330407 (* 1 = 0.330407 loss)
I0429 15:32:32.329469 25258 sgd_solver.cpp:112] Iteration 13900, lr = 0.001
I0429 15:32:39.966890 25258 solver.cpp:239] Iteration 13920 (2.61873 iter/s, 7.63728s/20 iters), loss = 0.310384
I0429 15:32:39.986721 25258 solver.cpp:258]     Train net output #0: loss = 0.310384 (* 1 = 0.310384 loss)
I0429 15:32:39.986744 25258 sgd_solver.cpp:112] Iteration 13920, lr = 0.001
I0429 15:32:46.275058 25258 solver.cpp:239] Iteration 13940 (3.18055 iter/s, 6.28821s/20 iters), loss = 0.346418
I0429 15:32:46.282433 25258 solver.cpp:258]     Train net output #0: loss = 0.346418 (* 1 = 0.346418 loss)
I0429 15:32:46.282481 25258 sgd_solver.cpp:112] Iteration 13940, lr = 0.001
I0429 15:32:51.928356 25258 solver.cpp:239] Iteration 13960 (3.54244 iter/s, 5.64583s/20 iters), loss = 0.327849
I0429 15:32:51.933606 25258 solver.cpp:258]     Train net output #0: loss = 0.327849 (* 1 = 0.327849 loss)
I0429 15:32:51.933648 25258 sgd_solver.cpp:112] Iteration 13960, lr = 0.001
I0429 15:32:59.772282 25258 solver.cpp:239] Iteration 13980 (2.55356 iter/s, 7.83221s/20 iters), loss = 0.244052
I0429 15:32:59.772384 25258 solver.cpp:258]     Train net output #0: loss = 0.244052 (* 1 = 0.244052 loss)
I0429 15:32:59.772403 25258 sgd_solver.cpp:112] Iteration 13980, lr = 0.001
I0429 15:33:06.622103 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_14000.caffemodel
I0429 15:33:27.924474 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_14000.solverstate
I0429 15:33:28.372311 25258 solver.cpp:351] Iteration 14000, Testing net (#0)
I0429 15:33:40.153327 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:33:41.574685 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.862891
I0429 15:33:41.574801 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.944922
I0429 15:33:41.574811 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.974375
I0429 15:33:41.574828 25258 solver.cpp:418]     Test net output #3: loss = 0.354566 (* 1 = 0.354566 loss)
I0429 15:33:41.718158 25258 solver.cpp:239] Iteration 14000 (0.476815 iter/s, 41.945s/20 iters), loss = 0.193119
I0429 15:33:41.718286 25258 solver.cpp:258]     Train net output #0: loss = 0.193119 (* 1 = 0.193119 loss)
I0429 15:33:41.718317 25258 sgd_solver.cpp:112] Iteration 14000, lr = 0.001
I0429 15:33:51.714864 25258 solver.cpp:239] Iteration 14020 (2.00073 iter/s, 9.99637s/20 iters), loss = 0.304502
I0429 15:33:51.720496 25258 solver.cpp:258]     Train net output #0: loss = 0.304502 (* 1 = 0.304502 loss)
I0429 15:33:51.720553 25258 sgd_solver.cpp:112] Iteration 14020, lr = 0.001
I0429 15:34:04.127110 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:34:06.218575 25258 solver.cpp:239] Iteration 14040 (1.37952 iter/s, 14.4978s/20 iters), loss = 0.314421
I0429 15:34:06.225291 25258 solver.cpp:258]     Train net output #0: loss = 0.31442 (* 1 = 0.31442 loss)
I0429 15:34:06.225369 25258 sgd_solver.cpp:112] Iteration 14040, lr = 0.001
I0429 15:34:15.463665 25258 solver.cpp:239] Iteration 14060 (2.16492 iter/s, 9.23823s/20 iters), loss = 0.235458
I0429 15:34:15.473033 25258 solver.cpp:258]     Train net output #0: loss = 0.235458 (* 1 = 0.235458 loss)
I0429 15:34:15.473076 25258 sgd_solver.cpp:112] Iteration 14060, lr = 0.001
I0429 15:34:23.088191 25258 solver.cpp:239] Iteration 14080 (2.62639 iter/s, 7.61503s/20 iters), loss = 0.277923
I0429 15:34:23.093818 25258 solver.cpp:258]     Train net output #0: loss = 0.277923 (* 1 = 0.277923 loss)
I0429 15:34:23.093868 25258 sgd_solver.cpp:112] Iteration 14080, lr = 0.001
I0429 15:34:30.061241 25258 solver.cpp:239] Iteration 14100 (2.87052 iter/s, 6.96737s/20 iters), loss = 0.346556
I0429 15:34:30.066329 25258 solver.cpp:258]     Train net output #0: loss = 0.346556 (* 1 = 0.346556 loss)
I0429 15:34:30.066368 25258 sgd_solver.cpp:112] Iteration 14100, lr = 0.001
I0429 15:34:38.195180 25258 solver.cpp:239] Iteration 14120 (2.46042 iter/s, 8.12869s/20 iters), loss = 0.289913
I0429 15:34:38.201489 25258 solver.cpp:258]     Train net output #0: loss = 0.289913 (* 1 = 0.289913 loss)
I0429 15:34:38.201584 25258 sgd_solver.cpp:112] Iteration 14120, lr = 0.001
I0429 15:34:45.354387 25258 solver.cpp:239] Iteration 14140 (2.79611 iter/s, 7.1528s/20 iters), loss = 0.395182
I0429 15:34:45.360611 25258 solver.cpp:258]     Train net output #0: loss = 0.395182 (* 1 = 0.395182 loss)
I0429 15:34:45.360647 25258 sgd_solver.cpp:112] Iteration 14140, lr = 0.001
I0429 15:34:52.753509 25258 solver.cpp:239] Iteration 14160 (2.70535 iter/s, 7.39275s/20 iters), loss = 0.219893
I0429 15:34:52.758723 25258 solver.cpp:258]     Train net output #0: loss = 0.219893 (* 1 = 0.219893 loss)
I0429 15:34:52.758769 25258 sgd_solver.cpp:112] Iteration 14160, lr = 0.001
I0429 15:34:59.939883 25258 solver.cpp:239] Iteration 14180 (2.78534 iter/s, 7.18045s/20 iters), loss = 0.397649
I0429 15:34:59.945598 25258 solver.cpp:258]     Train net output #0: loss = 0.397649 (* 1 = 0.397649 loss)
I0429 15:34:59.945668 25258 sgd_solver.cpp:112] Iteration 14180, lr = 0.001
I0429 15:35:06.388273 25258 solver.cpp:239] Iteration 14200 (3.10436 iter/s, 6.44255s/20 iters), loss = 0.344268
I0429 15:35:06.388435 25258 solver.cpp:258]     Train net output #0: loss = 0.344268 (* 1 = 0.344268 loss)
I0429 15:35:06.388456 25258 sgd_solver.cpp:112] Iteration 14200, lr = 0.001
I0429 15:35:13.023347 25258 solver.cpp:239] Iteration 14220 (3.01442 iter/s, 6.63477s/20 iters), loss = 0.314109
I0429 15:35:13.028681 25258 solver.cpp:258]     Train net output #0: loss = 0.314108 (* 1 = 0.314108 loss)
I0429 15:35:13.028723 25258 sgd_solver.cpp:112] Iteration 14220, lr = 0.001
I0429 15:35:18.941272 25258 solver.cpp:239] Iteration 14240 (3.38268 iter/s, 5.91247s/20 iters), loss = 0.300178
I0429 15:35:18.947660 25258 solver.cpp:258]     Train net output #0: loss = 0.300178 (* 1 = 0.300178 loss)
I0429 15:35:18.947726 25258 sgd_solver.cpp:112] Iteration 14240, lr = 0.001
I0429 15:35:22.347950 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_14250.caffemodel
I0429 15:35:51.133329 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_14250.solverstate
I0429 15:35:51.527496 25258 solver.cpp:351] Iteration 14250, Testing net (#0)
I0429 15:36:01.812410 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:36:03.036900 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.864297
I0429 15:36:03.036988 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.946406
I0429 15:36:03.037000 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.974844
I0429 15:36:03.037016 25258 solver.cpp:418]     Test net output #3: loss = 0.354011 (* 1 = 0.354011 loss)
I0429 15:36:04.411835 25258 blocking_queue.cpp:49] Waiting for data
I0429 15:36:05.561467 25258 solver.cpp:239] Iteration 14260 (0.429066 iter/s, 46.6129s/20 iters), loss = 0.549422
I0429 15:36:05.561548 25258 solver.cpp:258]     Train net output #0: loss = 0.549421 (* 1 = 0.549421 loss)
I0429 15:36:05.561565 25258 sgd_solver.cpp:112] Iteration 14260, lr = 0.001
I0429 15:36:11.696993 25258 solver.cpp:239] Iteration 14280 (3.25982 iter/s, 6.1353s/20 iters), loss = 0.266506
I0429 15:36:11.702193 25258 solver.cpp:258]     Train net output #0: loss = 0.266506 (* 1 = 0.266506 loss)
I0429 15:36:11.702251 25258 sgd_solver.cpp:112] Iteration 14280, lr = 0.001
I0429 15:36:19.990427 25258 solver.cpp:239] Iteration 14300 (2.41311 iter/s, 8.28807s/20 iters), loss = 0.283565
I0429 15:36:19.996639 25258 solver.cpp:258]     Train net output #0: loss = 0.283565 (* 1 = 0.283565 loss)
I0429 15:36:19.996687 25258 sgd_solver.cpp:112] Iteration 14300, lr = 0.001
I0429 15:36:36.426432 25258 solver.cpp:239] Iteration 14320 (1.21732 iter/s, 16.4295s/20 iters), loss = 0.304222
I0429 15:36:36.431574 25258 solver.cpp:258]     Train net output #0: loss = 0.304222 (* 1 = 0.304222 loss)
I0429 15:36:36.431604 25258 sgd_solver.cpp:112] Iteration 14320, lr = 0.001
I0429 15:36:52.586385 25258 solver.cpp:239] Iteration 14340 (1.23805 iter/s, 16.1545s/20 iters), loss = 0.31138
I0429 15:36:52.591670 25258 solver.cpp:258]     Train net output #0: loss = 0.31138 (* 1 = 0.31138 loss)
I0429 15:36:52.591711 25258 sgd_solver.cpp:112] Iteration 14340, lr = 0.001
I0429 15:37:00.385036 25258 solver.cpp:239] Iteration 14360 (2.56634 iter/s, 7.79319s/20 iters), loss = 0.351429
I0429 15:37:00.393179 25258 solver.cpp:258]     Train net output #0: loss = 0.351429 (* 1 = 0.351429 loss)
I0429 15:37:00.393219 25258 sgd_solver.cpp:112] Iteration 14360, lr = 0.001
I0429 15:37:07.737740 25258 solver.cpp:239] Iteration 14380 (2.72317 iter/s, 7.34438s/20 iters), loss = 0.319539
I0429 15:37:07.747436 25258 solver.cpp:258]     Train net output #0: loss = 0.319539 (* 1 = 0.319539 loss)
I0429 15:37:07.747499 25258 sgd_solver.cpp:112] Iteration 14380, lr = 0.001
I0429 15:37:14.544275 25258 solver.cpp:239] Iteration 14400 (2.9426 iter/s, 6.7967s/20 iters), loss = 0.320803
I0429 15:37:14.544358 25258 solver.cpp:258]     Train net output #0: loss = 0.320803 (* 1 = 0.320803 loss)
I0429 15:37:14.544371 25258 sgd_solver.cpp:112] Iteration 14400, lr = 0.001
I0429 15:37:22.043368 25258 solver.cpp:239] Iteration 14420 (2.66708 iter/s, 7.49884s/20 iters), loss = 0.301982
I0429 15:37:22.049827 25258 solver.cpp:258]     Train net output #0: loss = 0.301982 (* 1 = 0.301982 loss)
I0429 15:37:22.049870 25258 sgd_solver.cpp:112] Iteration 14420, lr = 0.001
I0429 15:37:28.286351 25258 solver.cpp:239] Iteration 14440 (3.20698 iter/s, 6.23639s/20 iters), loss = 0.256391
I0429 15:37:28.292212 25258 solver.cpp:258]     Train net output #0: loss = 0.256391 (* 1 = 0.256391 loss)
I0429 15:37:28.292258 25258 sgd_solver.cpp:112] Iteration 14440, lr = 0.001
I0429 15:37:35.197623 25258 solver.cpp:239] Iteration 14460 (2.89638 iter/s, 6.90518s/20 iters), loss = 0.293111
I0429 15:37:35.205848 25258 solver.cpp:258]     Train net output #0: loss = 0.293111 (* 1 = 0.293111 loss)
I0429 15:37:35.205931 25258 sgd_solver.cpp:112] Iteration 14460, lr = 0.001
I0429 15:37:42.123832 25258 solver.cpp:239] Iteration 14480 (2.89107 iter/s, 6.91786s/20 iters), loss = 0.236791
I0429 15:37:42.130455 25258 solver.cpp:258]     Train net output #0: loss = 0.236791 (* 1 = 0.236791 loss)
I0429 15:37:42.130517 25258 sgd_solver.cpp:112] Iteration 14480, lr = 0.001
I0429 15:37:47.501099 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_14500.caffemodel
I0429 15:38:25.008656 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_14500.solverstate
I0429 15:38:25.400770 25258 solver.cpp:351] Iteration 14500, Testing net (#0)
I0429 15:38:34.515630 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:38:35.607637 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.869687
I0429 15:38:35.607715 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.947266
I0429 15:38:35.607743 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.974609
I0429 15:38:35.607760 25258 solver.cpp:418]     Test net output #3: loss = 0.34159 (* 1 = 0.34159 loss)
I0429 15:38:35.702235 25258 solver.cpp:239] Iteration 14500 (0.373338 iter/s, 53.5707s/20 iters), loss = 0.282109
I0429 15:38:35.706638 25258 solver.cpp:258]     Train net output #0: loss = 0.282108 (* 1 = 0.282108 loss)
I0429 15:38:35.706712 25258 sgd_solver.cpp:112] Iteration 14500, lr = 0.001
I0429 15:38:40.138770 25258 solver.cpp:239] Iteration 14520 (4.51258 iter/s, 4.43205s/20 iters), loss = 0.236509
I0429 15:38:40.144780 25258 solver.cpp:258]     Train net output #0: loss = 0.236509 (* 1 = 0.236509 loss)
I0429 15:38:40.144814 25258 sgd_solver.cpp:112] Iteration 14520, lr = 0.001
I0429 15:38:45.677613 25258 solver.cpp:239] Iteration 14540 (3.61487 iter/s, 5.5327s/20 iters), loss = 0.368205
I0429 15:38:45.684877 25258 solver.cpp:258]     Train net output #0: loss = 0.368205 (* 1 = 0.368205 loss)
I0429 15:38:45.684972 25258 sgd_solver.cpp:112] Iteration 14540, lr = 0.001
I0429 15:38:50.648813 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:38:51.381229 25258 solver.cpp:239] Iteration 14560 (3.51615 iter/s, 5.68804s/20 iters), loss = 0.239721
I0429 15:38:51.382342 25258 solver.cpp:258]     Train net output #0: loss = 0.239721 (* 1 = 0.239721 loss)
I0429 15:38:51.382380 25258 sgd_solver.cpp:112] Iteration 14560, lr = 0.001
I0429 15:38:56.946285 25258 solver.cpp:239] Iteration 14580 (3.59465 iter/s, 5.56383s/20 iters), loss = 0.28135
I0429 15:38:56.951490 25258 solver.cpp:258]     Train net output #0: loss = 0.28135 (* 1 = 0.28135 loss)
I0429 15:38:56.951534 25258 sgd_solver.cpp:112] Iteration 14580, lr = 0.001
I0429 15:39:08.928058 25258 solver.cpp:239] Iteration 14600 (1.66996 iter/s, 11.9763s/20 iters), loss = 0.279626
I0429 15:39:08.933506 25258 solver.cpp:258]     Train net output #0: loss = 0.279626 (* 1 = 0.279626 loss)
I0429 15:39:08.933548 25258 sgd_solver.cpp:112] Iteration 14600, lr = 0.001
I0429 15:39:23.733283 25258 solver.cpp:239] Iteration 14620 (1.3514 iter/s, 14.7995s/20 iters), loss = 0.324932
I0429 15:39:23.738555 25258 solver.cpp:258]     Train net output #0: loss = 0.324932 (* 1 = 0.324932 loss)
I0429 15:39:23.738585 25258 sgd_solver.cpp:112] Iteration 14620, lr = 0.001
I0429 15:39:36.826139 25258 solver.cpp:239] Iteration 14640 (1.5282 iter/s, 13.0873s/20 iters), loss = 0.290094
I0429 15:39:36.831624 25258 solver.cpp:258]     Train net output #0: loss = 0.290094 (* 1 = 0.290094 loss)
I0429 15:39:36.831663 25258 sgd_solver.cpp:112] Iteration 14640, lr = 0.001
I0429 15:39:43.302027 25258 solver.cpp:239] Iteration 14660 (3.09106 iter/s, 6.47027s/20 iters), loss = 0.350491
I0429 15:39:43.302110 25258 solver.cpp:258]     Train net output #0: loss = 0.350491 (* 1 = 0.350491 loss)
I0429 15:39:43.302121 25258 sgd_solver.cpp:112] Iteration 14660, lr = 0.001
I0429 15:39:48.638562 25258 solver.cpp:239] Iteration 14680 (3.74791 iter/s, 5.33631s/20 iters), loss = 0.189918
I0429 15:39:48.645829 25258 solver.cpp:258]     Train net output #0: loss = 0.189918 (* 1 = 0.189918 loss)
I0429 15:39:48.645877 25258 sgd_solver.cpp:112] Iteration 14680, lr = 0.001
I0429 15:39:55.477316 25258 solver.cpp:239] Iteration 14700 (2.92768 iter/s, 6.83134s/20 iters), loss = 0.350709
I0429 15:39:55.484429 25258 solver.cpp:258]     Train net output #0: loss = 0.350709 (* 1 = 0.350709 loss)
I0429 15:39:55.484541 25258 sgd_solver.cpp:112] Iteration 14700, lr = 0.001
I0429 15:40:02.619822 25258 solver.cpp:239] Iteration 14720 (2.80295 iter/s, 7.13533s/20 iters), loss = 0.245403
I0429 15:40:02.625291 25258 solver.cpp:258]     Train net output #0: loss = 0.245403 (* 1 = 0.245403 loss)
I0429 15:40:02.625345 25258 sgd_solver.cpp:112] Iteration 14720, lr = 0.001
I0429 15:40:10.127154 25258 solver.cpp:239] Iteration 14740 (2.66605 iter/s, 7.50172s/20 iters), loss = 0.274341
I0429 15:40:10.127764 25258 solver.cpp:258]     Train net output #0: loss = 0.274341 (* 1 = 0.274341 loss)
I0429 15:40:10.127781 25258 sgd_solver.cpp:112] Iteration 14740, lr = 0.001
I0429 15:40:12.910567 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_14750.caffemodel
I0429 15:40:38.328830 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_14750.solverstate
I0429 15:40:38.779032 25258 solver.cpp:351] Iteration 14750, Testing net (#0)
I0429 15:40:48.921015 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:40:50.745630 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.871172
I0429 15:40:50.745690 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.948672
I0429 15:40:50.745699 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.976484
I0429 15:40:50.745741 25258 solver.cpp:418]     Test net output #3: loss = 0.340205 (* 1 = 0.340205 loss)
I0429 15:40:53.623675 25258 solver.cpp:239] Iteration 14760 (0.459823 iter/s, 43.495s/20 iters), loss = 0.155817
I0429 15:40:53.628806 25258 solver.cpp:258]     Train net output #0: loss = 0.155817 (* 1 = 0.155817 loss)
I0429 15:40:53.628845 25258 sgd_solver.cpp:112] Iteration 14760, lr = 0.001
I0429 15:40:58.484349 25258 solver.cpp:239] Iteration 14780 (4.1191 iter/s, 4.85543s/20 iters), loss = 0.356505
I0429 15:40:58.493887 25258 solver.cpp:258]     Train net output #0: loss = 0.356505 (* 1 = 0.356505 loss)
I0429 15:40:58.493924 25258 sgd_solver.cpp:112] Iteration 14780, lr = 0.001
I0429 15:41:05.816417 25258 solver.cpp:239] Iteration 14800 (2.73135 iter/s, 7.32238s/20 iters), loss = 0.134207
I0429 15:41:05.821697 25258 solver.cpp:258]     Train net output #0: loss = 0.134207 (* 1 = 0.134207 loss)
I0429 15:41:05.821776 25258 sgd_solver.cpp:112] Iteration 14800, lr = 0.001
I0429 15:41:11.664954 25258 solver.cpp:239] Iteration 14820 (3.42283 iter/s, 5.84312s/20 iters), loss = 0.198821
I0429 15:41:11.670013 25258 solver.cpp:258]     Train net output #0: loss = 0.198821 (* 1 = 0.198821 loss)
I0429 15:41:11.670043 25258 sgd_solver.cpp:112] Iteration 14820, lr = 0.001
I0429 15:41:20.005414 25258 solver.cpp:239] Iteration 14840 (2.39946 iter/s, 8.3352s/20 iters), loss = 0.33992
I0429 15:41:20.010977 25258 solver.cpp:258]     Train net output #0: loss = 0.33992 (* 1 = 0.33992 loss)
I0429 15:41:20.011014 25258 sgd_solver.cpp:112] Iteration 14840, lr = 0.001
I0429 15:41:27.238204 25258 solver.cpp:239] Iteration 14860 (2.76737 iter/s, 7.22707s/20 iters), loss = 0.320191
I0429 15:41:27.243690 25258 solver.cpp:258]     Train net output #0: loss = 0.320191 (* 1 = 0.320191 loss)
I0429 15:41:27.243729 25258 sgd_solver.cpp:112] Iteration 14860, lr = 0.001
I0429 15:41:33.082010 25258 solver.cpp:239] Iteration 14880 (3.42572 iter/s, 5.83819s/20 iters), loss = 0.321615
I0429 15:41:33.091045 25258 solver.cpp:258]     Train net output #0: loss = 0.321615 (* 1 = 0.321615 loss)
I0429 15:41:33.091140 25258 sgd_solver.cpp:112] Iteration 14880, lr = 0.001
I0429 15:41:38.377867 25258 solver.cpp:239] Iteration 14900 (3.78298 iter/s, 5.28683s/20 iters), loss = 0.288267
I0429 15:41:38.385778 25258 solver.cpp:258]     Train net output #0: loss = 0.288267 (* 1 = 0.288267 loss)
I0429 15:41:38.385816 25258 sgd_solver.cpp:112] Iteration 14900, lr = 0.001
I0429 15:41:52.135380 25258 solver.cpp:239] Iteration 14920 (1.45462 iter/s, 13.7493s/20 iters), loss = 0.320019
I0429 15:41:52.135653 25258 solver.cpp:258]     Train net output #0: loss = 0.320019 (* 1 = 0.320019 loss)
I0429 15:41:52.135664 25258 sgd_solver.cpp:112] Iteration 14920, lr = 0.001
I0429 15:42:05.405637 25258 solver.cpp:239] Iteration 14940 (1.5072 iter/s, 13.2696s/20 iters), loss = 0.354924
I0429 15:42:05.413350 25258 solver.cpp:258]     Train net output #0: loss = 0.354924 (* 1 = 0.354924 loss)
I0429 15:42:05.413434 25258 sgd_solver.cpp:112] Iteration 14940, lr = 0.001
I0429 15:42:14.613878 25258 solver.cpp:239] Iteration 14960 (2.17383 iter/s, 9.20036s/20 iters), loss = 0.287337
I0429 15:42:14.618677 25258 solver.cpp:258]     Train net output #0: loss = 0.287337 (* 1 = 0.287337 loss)
I0429 15:42:14.618710 25258 sgd_solver.cpp:112] Iteration 14960, lr = 0.001
I0429 15:42:22.318718 25258 solver.cpp:239] Iteration 14980 (2.59745 iter/s, 7.69986s/20 iters), loss = 0.285458
I0429 15:42:22.324159 25258 solver.cpp:258]     Train net output #0: loss = 0.285458 (* 1 = 0.285458 loss)
I0429 15:42:22.324240 25258 sgd_solver.cpp:112] Iteration 14980, lr = 0.001
I0429 15:42:28.488912 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_15000.caffemodel
I0429 15:43:07.232645 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_15000.solverstate
I0429 15:43:07.637285 25258 solver.cpp:351] Iteration 15000, Testing net (#0)
I0429 15:43:17.501546 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:43:17.870993 25258 blocking_queue.cpp:49] Waiting for data
I0429 15:43:18.400936 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.877734
I0429 15:43:18.400977 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.95
I0429 15:43:18.400984 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.977188
I0429 15:43:18.400993 25258 solver.cpp:418]     Test net output #3: loss = 0.316127 (* 1 = 0.316127 loss)
I0429 15:43:18.517469 25258 solver.cpp:239] Iteration 15000 (0.355922 iter/s, 56.1921s/20 iters), loss = 0.214418
I0429 15:43:18.522723 25258 solver.cpp:258]     Train net output #0: loss = 0.214418 (* 1 = 0.214418 loss)
I0429 15:43:18.522804 25258 sgd_solver.cpp:112] Iteration 15000, lr = 0.001
I0429 15:43:23.685300 25258 solver.cpp:239] Iteration 15020 (3.8741 iter/s, 5.16249s/20 iters), loss = 0.157668
I0429 15:43:23.690587 25258 solver.cpp:258]     Train net output #0: loss = 0.157668 (* 1 = 0.157668 loss)
I0429 15:43:23.690626 25258 sgd_solver.cpp:112] Iteration 15020, lr = 0.001
I0429 15:43:29.975078 25258 solver.cpp:239] Iteration 15040 (3.18251 iter/s, 6.28435s/20 iters), loss = 0.262512
I0429 15:43:29.980196 25258 solver.cpp:258]     Train net output #0: loss = 0.262512 (* 1 = 0.262512 loss)
I0429 15:43:29.980242 25258 sgd_solver.cpp:112] Iteration 15040, lr = 0.001
I0429 15:43:35.162318 25258 solver.cpp:239] Iteration 15060 (3.85954 iter/s, 5.18197s/20 iters), loss = 0.2852
I0429 15:43:35.171509 25258 solver.cpp:258]     Train net output #0: loss = 0.2852 (* 1 = 0.2852 loss)
I0429 15:43:35.171552 25258 sgd_solver.cpp:112] Iteration 15060, lr = 0.001
I0429 15:43:41.627575 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:43:41.936663 25258 solver.cpp:239] Iteration 15080 (2.95639 iter/s, 6.76502s/20 iters), loss = 0.175216
I0429 15:43:41.936733 25258 solver.cpp:258]     Train net output #0: loss = 0.175216 (* 1 = 0.175216 loss)
I0429 15:43:41.936748 25258 sgd_solver.cpp:112] Iteration 15080, lr = 0.001
I0429 15:43:45.928345 25258 solver.cpp:239] Iteration 15100 (5.01064 iter/s, 3.9915s/20 iters), loss = 0.24247
I0429 15:43:45.935149 25258 solver.cpp:258]     Train net output #0: loss = 0.24247 (* 1 = 0.24247 loss)
I0429 15:43:45.935190 25258 sgd_solver.cpp:112] Iteration 15100, lr = 0.001
I0429 15:43:53.143285 25258 solver.cpp:239] Iteration 15120 (2.77473 iter/s, 7.20792s/20 iters), loss = 0.254314
I0429 15:43:53.149847 25258 solver.cpp:258]     Train net output #0: loss = 0.254314 (* 1 = 0.254314 loss)
I0429 15:43:53.149890 25258 sgd_solver.cpp:112] Iteration 15120, lr = 0.001
I0429 15:44:00.058851 25258 solver.cpp:239] Iteration 15140 (2.89483 iter/s, 6.90887s/20 iters), loss = 0.221305
I0429 15:44:00.065119 25258 solver.cpp:258]     Train net output #0: loss = 0.221305 (* 1 = 0.221305 loss)
I0429 15:44:00.065146 25258 sgd_solver.cpp:112] Iteration 15140, lr = 0.001
I0429 15:44:06.218009 25258 solver.cpp:239] Iteration 15160 (3.25017 iter/s, 6.15353s/20 iters), loss = 0.236064
I0429 15:44:06.224756 25258 solver.cpp:258]     Train net output #0: loss = 0.236064 (* 1 = 0.236064 loss)
I0429 15:44:06.224800 25258 sgd_solver.cpp:112] Iteration 15160, lr = 0.001
I0429 15:44:12.287353 25258 solver.cpp:239] Iteration 15180 (3.29899 iter/s, 6.06247s/20 iters), loss = 0.36389
I0429 15:44:12.321239 25258 solver.cpp:258]     Train net output #0: loss = 0.36389 (* 1 = 0.36389 loss)
I0429 15:44:12.321259 25258 sgd_solver.cpp:112] Iteration 15180, lr = 0.001
I0429 15:44:16.363535 25258 solver.cpp:239] Iteration 15200 (4.95138 iter/s, 4.03927s/20 iters), loss = 0.179233
I0429 15:44:16.369030 25258 solver.cpp:258]     Train net output #0: loss = 0.179233 (* 1 = 0.179233 loss)
I0429 15:44:16.369096 25258 sgd_solver.cpp:112] Iteration 15200, lr = 0.001
I0429 15:44:30.490016 25258 solver.cpp:239] Iteration 15220 (1.41636 iter/s, 14.1207s/20 iters), loss = 0.25219
I0429 15:44:30.495647 25258 solver.cpp:258]     Train net output #0: loss = 0.25219 (* 1 = 0.25219 loss)
I0429 15:44:30.495705 25258 sgd_solver.cpp:112] Iteration 15220, lr = 0.001
I0429 15:44:46.918880 25258 solver.cpp:239] Iteration 15240 (1.21781 iter/s, 16.4229s/20 iters), loss = 0.343009
I0429 15:44:46.925308 25258 solver.cpp:258]     Train net output #0: loss = 0.343009 (* 1 = 0.343009 loss)
I0429 15:44:46.925345 25258 sgd_solver.cpp:112] Iteration 15240, lr = 0.001
I0429 15:44:53.257336 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_15250.caffemodel
I0429 15:45:36.627296 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_15250.solverstate
I0429 15:45:37.033628 25258 solver.cpp:351] Iteration 15250, Testing net (#0)
I0429 15:45:46.722291 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:45:47.972018 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.881328
I0429 15:45:47.972066 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.948828
I0429 15:45:47.972080 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.976406
I0429 15:45:47.972095 25258 solver.cpp:418]     Test net output #3: loss = 0.317416 (* 1 = 0.317416 loss)
I0429 15:45:51.282901 25258 solver.cpp:239] Iteration 15260 (0.310771 iter/s, 64.3561s/20 iters), loss = 0.221784
I0429 15:45:51.288172 25258 solver.cpp:258]     Train net output #0: loss = 0.221784 (* 1 = 0.221784 loss)
I0429 15:45:51.288208 25258 sgd_solver.cpp:112] Iteration 15260, lr = 0.001
I0429 15:45:56.129158 25258 solver.cpp:239] Iteration 15280 (4.13149 iter/s, 4.84087s/20 iters), loss = 0.272584
I0429 15:45:56.134340 25258 solver.cpp:258]     Train net output #0: loss = 0.272584 (* 1 = 0.272584 loss)
I0429 15:45:56.134390 25258 sgd_solver.cpp:112] Iteration 15280, lr = 0.001
I0429 15:46:01.528790 25258 solver.cpp:239] Iteration 15300 (3.7076 iter/s, 5.39432s/20 iters), loss = 0.352044
I0429 15:46:01.536314 25258 solver.cpp:258]     Train net output #0: loss = 0.352044 (* 1 = 0.352044 loss)
I0429 15:46:01.536430 25258 sgd_solver.cpp:112] Iteration 15300, lr = 0.001
I0429 15:46:08.488685 25258 solver.cpp:239] Iteration 15320 (2.87676 iter/s, 6.95226s/20 iters), loss = 0.135036
I0429 15:46:08.495045 25258 solver.cpp:258]     Train net output #0: loss = 0.135036 (* 1 = 0.135036 loss)
I0429 15:46:08.495103 25258 sgd_solver.cpp:112] Iteration 15320, lr = 0.001
I0429 15:46:14.248726 25258 solver.cpp:239] Iteration 15340 (3.47609 iter/s, 5.75358s/20 iters), loss = 0.206003
I0429 15:46:14.253830 25258 solver.cpp:258]     Train net output #0: loss = 0.206003 (* 1 = 0.206003 loss)
I0429 15:46:14.253860 25258 sgd_solver.cpp:112] Iteration 15340, lr = 0.001
I0429 15:46:20.970321 25258 solver.cpp:239] Iteration 15360 (2.97782 iter/s, 6.71633s/20 iters), loss = 0.210564
I0429 15:46:20.975303 25258 solver.cpp:258]     Train net output #0: loss = 0.210564 (* 1 = 0.210564 loss)
I0429 15:46:20.975342 25258 sgd_solver.cpp:112] Iteration 15360, lr = 0.001
I0429 15:46:27.134614 25258 solver.cpp:239] Iteration 15380 (3.24719 iter/s, 6.15918s/20 iters), loss = 0.256153
I0429 15:46:27.134713 25258 solver.cpp:258]     Train net output #0: loss = 0.256153 (* 1 = 0.256153 loss)
I0429 15:46:27.134744 25258 sgd_solver.cpp:112] Iteration 15380, lr = 0.001
I0429 15:46:33.578016 25258 solver.cpp:239] Iteration 15400 (3.10408 iter/s, 6.44313s/20 iters), loss = 0.268995
I0429 15:46:33.583230 25258 solver.cpp:258]     Train net output #0: loss = 0.268995 (* 1 = 0.268995 loss)
I0429 15:46:33.583281 25258 sgd_solver.cpp:112] Iteration 15400, lr = 0.001
I0429 15:46:40.271029 25258 solver.cpp:239] Iteration 15420 (2.99059 iter/s, 6.68765s/20 iters), loss = 0.272411
I0429 15:46:40.272986 25258 solver.cpp:258]     Train net output #0: loss = 0.272411 (* 1 = 0.272411 loss)
I0429 15:46:40.273023 25258 sgd_solver.cpp:112] Iteration 15420, lr = 0.001
I0429 15:46:46.986291 25258 solver.cpp:239] Iteration 15440 (2.97922 iter/s, 6.71317s/20 iters), loss = 0.385888
I0429 15:46:46.991353 25258 solver.cpp:258]     Train net output #0: loss = 0.385888 (* 1 = 0.385888 loss)
I0429 15:46:46.991389 25258 sgd_solver.cpp:112] Iteration 15440, lr = 0.001
I0429 15:46:54.434363 25258 solver.cpp:239] Iteration 15460 (2.68715 iter/s, 7.44283s/20 iters), loss = 0.275134
I0429 15:46:54.439453 25258 solver.cpp:258]     Train net output #0: loss = 0.275134 (* 1 = 0.275134 loss)
I0429 15:46:54.439496 25258 sgd_solver.cpp:112] Iteration 15460, lr = 0.001
I0429 15:47:09.243271 25258 solver.cpp:239] Iteration 15480 (1.35103 iter/s, 14.8035s/20 iters), loss = 0.197876
I0429 15:47:09.248229 25258 solver.cpp:258]     Train net output #0: loss = 0.197876 (* 1 = 0.197876 loss)
I0429 15:47:09.248255 25258 sgd_solver.cpp:112] Iteration 15480, lr = 0.001
I0429 15:47:24.042811 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_15500.caffemodel
I0429 15:48:27.426674 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_15500.solverstate
I0429 15:48:27.791615 25258 solver.cpp:351] Iteration 15500, Testing net (#0)
I0429 15:48:36.472728 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:48:36.916779 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.885391
I0429 15:48:36.916846 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.951406
I0429 15:48:36.916858 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.977813
I0429 15:48:36.916877 25258 solver.cpp:418]     Test net output #3: loss = 0.302288 (* 1 = 0.302288 loss)
I0429 15:48:36.994345 25258 solver.cpp:239] Iteration 15500 (0.227936 iter/s, 87.7441s/20 iters), loss = 0.298822
I0429 15:48:36.998306 25258 solver.cpp:258]     Train net output #0: loss = 0.298822 (* 1 = 0.298822 loss)
I0429 15:48:36.998373 25258 sgd_solver.cpp:112] Iteration 15500, lr = 0.001
I0429 15:48:40.945204 25258 solver.cpp:239] Iteration 15520 (5.06734 iter/s, 3.94684s/20 iters), loss = 0.246826
I0429 15:48:40.950253 25258 solver.cpp:258]     Train net output #0: loss = 0.246827 (* 1 = 0.246827 loss)
I0429 15:48:40.950287 25258 sgd_solver.cpp:112] Iteration 15520, lr = 0.001
I0429 15:48:43.494755 25258 solver.cpp:239] Iteration 15540 (7.86031 iter/s, 2.54443s/20 iters), loss = 0.247528
I0429 15:48:43.499897 25258 solver.cpp:258]     Train net output #0: loss = 0.247528 (* 1 = 0.247528 loss)
I0429 15:48:43.499935 25258 sgd_solver.cpp:112] Iteration 15540, lr = 0.001
I0429 15:48:48.941287 25258 solver.cpp:239] Iteration 15560 (3.67562 iter/s, 5.44126s/20 iters), loss = 0.161707
I0429 15:48:48.948757 25258 solver.cpp:258]     Train net output #0: loss = 0.161707 (* 1 = 0.161707 loss)
I0429 15:48:48.948801 25258 sgd_solver.cpp:112] Iteration 15560, lr = 0.001
I0429 15:48:54.001173 25258 solver.cpp:239] Iteration 15580 (3.95859 iter/s, 5.05231s/20 iters), loss = 0.331174
I0429 15:48:54.007130 25258 solver.cpp:258]     Train net output #0: loss = 0.331174 (* 1 = 0.331174 loss)
I0429 15:48:54.007231 25258 sgd_solver.cpp:112] Iteration 15580, lr = 0.001
I0429 15:48:58.095031 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:48:58.711598 25258 solver.cpp:239] Iteration 15600 (4.25133 iter/s, 4.70441s/20 iters), loss = 0.175231
I0429 15:48:58.716553 25258 solver.cpp:258]     Train net output #0: loss = 0.175231 (* 1 = 0.175231 loss)
I0429 15:48:58.716609 25258 sgd_solver.cpp:112] Iteration 15600, lr = 0.001
I0429 15:49:05.544592 25258 solver.cpp:239] Iteration 15620 (2.92917 iter/s, 6.82788s/20 iters), loss = 0.120129
I0429 15:49:05.544672 25258 solver.cpp:258]     Train net output #0: loss = 0.120129 (* 1 = 0.120129 loss)
I0429 15:49:05.544685 25258 sgd_solver.cpp:112] Iteration 15620, lr = 0.001
I0429 15:49:11.435258 25258 solver.cpp:239] Iteration 15640 (3.39534 iter/s, 5.89042s/20 iters), loss = 0.263195
I0429 15:49:11.440575 25258 solver.cpp:258]     Train net output #0: loss = 0.263195 (* 1 = 0.263195 loss)
I0429 15:49:11.440641 25258 sgd_solver.cpp:112] Iteration 15640, lr = 0.001
I0429 15:49:18.888811 25258 solver.cpp:239] Iteration 15660 (2.68525 iter/s, 7.44809s/20 iters), loss = 0.195758
I0429 15:49:18.893811 25258 solver.cpp:258]     Train net output #0: loss = 0.195758 (* 1 = 0.195758 loss)
I0429 15:49:18.893852 25258 sgd_solver.cpp:112] Iteration 15660, lr = 0.001
I0429 15:49:25.498687 25258 solver.cpp:239] Iteration 15680 (3.02814 iter/s, 6.60472s/20 iters), loss = 0.130055
I0429 15:49:25.506491 25258 solver.cpp:258]     Train net output #0: loss = 0.130055 (* 1 = 0.130055 loss)
I0429 15:49:25.506566 25258 sgd_solver.cpp:112] Iteration 15680, lr = 0.001
I0429 15:49:34.582228 25258 solver.cpp:239] Iteration 15700 (2.20372 iter/s, 9.07557s/20 iters), loss = 0.290027
I0429 15:49:34.587747 25258 solver.cpp:258]     Train net output #0: loss = 0.290027 (* 1 = 0.290027 loss)
I0429 15:49:34.587801 25258 sgd_solver.cpp:112] Iteration 15700, lr = 0.001
I0429 15:49:48.583498 25258 solver.cpp:239] Iteration 15720 (1.42904 iter/s, 13.9954s/20 iters), loss = 0.17114
I0429 15:49:48.588802 25258 solver.cpp:258]     Train net output #0: loss = 0.17114 (* 1 = 0.17114 loss)
I0429 15:49:48.588848 25258 sgd_solver.cpp:112] Iteration 15720, lr = 0.001
I0429 15:50:02.789785 25258 solver.cpp:239] Iteration 15740 (1.40839 iter/s, 14.2007s/20 iters), loss = 0.252618
I0429 15:50:02.797825 25258 solver.cpp:258]     Train net output #0: loss = 0.252618 (* 1 = 0.252618 loss)
I0429 15:50:02.797866 25258 sgd_solver.cpp:112] Iteration 15740, lr = 0.001
I0429 15:50:05.833130 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_15750.caffemodel
I0429 15:51:02.036430 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_15750.solverstate
I0429 15:51:02.525990 25258 solver.cpp:351] Iteration 15750, Testing net (#0)
I0429 15:51:06.620107 25258 blocking_queue.cpp:49] Waiting for data
I0429 15:51:11.209966 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:51:11.458314 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.884297
I0429 15:51:11.458361 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.952266
I0429 15:51:11.458371 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.977656
I0429 15:51:11.458382 25258 solver.cpp:418]     Test net output #3: loss = 0.305345 (* 1 = 0.305345 loss)
I0429 15:51:13.248925 25258 solver.cpp:239] Iteration 15760 (0.283891 iter/s, 70.4495s/20 iters), loss = 0.214705
I0429 15:51:13.253983 25258 solver.cpp:258]     Train net output #0: loss = 0.214705 (* 1 = 0.214705 loss)
I0429 15:51:13.254026 25258 sgd_solver.cpp:112] Iteration 15760, lr = 0.001
I0429 15:51:16.482416 25258 solver.cpp:239] Iteration 15780 (6.19509 iter/s, 3.22836s/20 iters), loss = 0.209523
I0429 15:51:16.491363 25258 solver.cpp:258]     Train net output #0: loss = 0.209523 (* 1 = 0.209523 loss)
I0429 15:51:16.491408 25258 sgd_solver.cpp:112] Iteration 15780, lr = 0.001
I0429 15:51:20.758051 25258 solver.cpp:239] Iteration 15800 (4.68758 iter/s, 4.26659s/20 iters), loss = 0.164958
I0429 15:51:20.758153 25258 solver.cpp:258]     Train net output #0: loss = 0.164958 (* 1 = 0.164958 loss)
I0429 15:51:20.758168 25258 sgd_solver.cpp:112] Iteration 15800, lr = 0.001
I0429 15:51:26.292243 25258 solver.cpp:239] Iteration 15820 (3.61407 iter/s, 5.53393s/20 iters), loss = 0.291004
I0429 15:51:26.297361 25258 solver.cpp:258]     Train net output #0: loss = 0.291004 (* 1 = 0.291004 loss)
I0429 15:51:26.297430 25258 sgd_solver.cpp:112] Iteration 15820, lr = 0.001
I0429 15:51:30.369392 25258 solver.cpp:239] Iteration 15840 (4.91165 iter/s, 4.07195s/20 iters), loss = 0.215624
I0429 15:51:30.374642 25258 solver.cpp:258]     Train net output #0: loss = 0.215624 (* 1 = 0.215624 loss)
I0429 15:51:30.374691 25258 sgd_solver.cpp:112] Iteration 15840, lr = 0.001
I0429 15:51:37.596845 25258 solver.cpp:239] Iteration 15860 (2.76931 iter/s, 7.22203s/20 iters), loss = 0.186352
I0429 15:51:37.602085 25258 solver.cpp:258]     Train net output #0: loss = 0.186352 (* 1 = 0.186352 loss)
I0429 15:51:37.602124 25258 sgd_solver.cpp:112] Iteration 15860, lr = 0.001
I0429 15:51:43.510236 25258 solver.cpp:239] Iteration 15880 (3.38523 iter/s, 5.90802s/20 iters), loss = 0.146936
I0429 15:51:43.515694 25258 solver.cpp:258]     Train net output #0: loss = 0.146936 (* 1 = 0.146936 loss)
I0429 15:51:43.515748 25258 sgd_solver.cpp:112] Iteration 15880, lr = 0.001
I0429 15:51:50.601383 25258 solver.cpp:239] Iteration 15900 (2.82265 iter/s, 7.08553s/20 iters), loss = 0.212861
I0429 15:51:50.606523 25258 solver.cpp:258]     Train net output #0: loss = 0.212861 (* 1 = 0.212861 loss)
I0429 15:51:50.606572 25258 sgd_solver.cpp:112] Iteration 15900, lr = 0.001
I0429 15:51:55.737342 25258 solver.cpp:239] Iteration 15920 (3.8981 iter/s, 5.1307s/20 iters), loss = 0.324589
I0429 15:51:55.742833 25258 solver.cpp:258]     Train net output #0: loss = 0.324589 (* 1 = 0.324589 loss)
I0429 15:51:55.742875 25258 sgd_solver.cpp:112] Iteration 15920, lr = 0.001
I0429 15:52:03.553403 25258 solver.cpp:239] Iteration 15940 (2.5607 iter/s, 7.81038s/20 iters), loss = 0.241489
I0429 15:52:03.558624 25258 solver.cpp:258]     Train net output #0: loss = 0.241489 (* 1 = 0.241489 loss)
I0429 15:52:03.558660 25258 sgd_solver.cpp:112] Iteration 15940, lr = 0.001
I0429 15:52:17.535396 25258 solver.cpp:239] Iteration 15960 (1.43099 iter/s, 13.9764s/20 iters), loss = 0.28045
I0429 15:52:17.540933 25258 solver.cpp:258]     Train net output #0: loss = 0.28045 (* 1 = 0.28045 loss)
I0429 15:52:17.540972 25258 sgd_solver.cpp:112] Iteration 15960, lr = 0.001
I0429 15:52:30.928717 25258 solver.cpp:239] Iteration 15980 (1.49394 iter/s, 13.3874s/20 iters), loss = 0.262839
I0429 15:52:30.933836 25258 solver.cpp:258]     Train net output #0: loss = 0.262839 (* 1 = 0.262839 loss)
I0429 15:52:30.933864 25258 sgd_solver.cpp:112] Iteration 15980, lr = 0.001
I0429 15:52:42.560686 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_16000.caffemodel
I0429 15:53:36.288676 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_16000.solverstate
I0429 15:53:36.664022 25258 solver.cpp:351] Iteration 16000, Testing net (#0)
I0429 15:53:46.383826 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:53:46.426228 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.888359
I0429 15:53:46.426278 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.952812
I0429 15:53:46.426295 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.977344
I0429 15:53:46.426311 25258 solver.cpp:418]     Test net output #3: loss = 0.299942 (* 1 = 0.299942 loss)
I0429 15:53:46.577736 25258 solver.cpp:239] Iteration 16000 (0.264404 iter/s, 75.6417s/20 iters), loss = 0.235112
I0429 15:53:46.577817 25258 solver.cpp:258]     Train net output #0: loss = 0.235112 (* 1 = 0.235112 loss)
I0429 15:53:46.577832 25258 sgd_solver.cpp:112] Iteration 16000, lr = 0.001
I0429 15:53:50.598493 25258 solver.cpp:239] Iteration 16020 (4.97447 iter/s, 4.02053s/20 iters), loss = 0.288738
I0429 15:53:50.604349 25258 solver.cpp:258]     Train net output #0: loss = 0.288738 (* 1 = 0.288738 loss)
I0429 15:53:50.604418 25258 sgd_solver.cpp:112] Iteration 16020, lr = 0.001
I0429 15:53:55.914196 25258 solver.cpp:239] Iteration 16040 (3.76668 iter/s, 5.30972s/20 iters), loss = 0.23634
I0429 15:53:55.922317 25258 solver.cpp:258]     Train net output #0: loss = 0.23634 (* 1 = 0.23634 loss)
I0429 15:53:55.922379 25258 sgd_solver.cpp:112] Iteration 16040, lr = 0.001
I0429 15:54:01.712198 25258 solver.cpp:239] Iteration 16060 (3.45439 iter/s, 5.78973s/20 iters), loss = 0.199766
I0429 15:54:01.717389 25258 solver.cpp:258]     Train net output #0: loss = 0.199766 (* 1 = 0.199766 loss)
I0429 15:54:01.717424 25258 sgd_solver.cpp:112] Iteration 16060, lr = 0.001
I0429 15:54:07.004138 25258 solver.cpp:239] Iteration 16080 (3.78315 iter/s, 5.2866s/20 iters), loss = 0.205489
I0429 15:54:07.009551 25258 solver.cpp:258]     Train net output #0: loss = 0.205489 (* 1 = 0.205489 loss)
I0429 15:54:07.009574 25258 sgd_solver.cpp:112] Iteration 16080, lr = 0.001
I0429 15:54:13.643043 25258 solver.cpp:239] Iteration 16100 (3.01509 iter/s, 6.6333s/20 iters), loss = 0.30577
I0429 15:54:13.643105 25258 solver.cpp:258]     Train net output #0: loss = 0.30577 (* 1 = 0.30577 loss)
I0429 15:54:13.643121 25258 sgd_solver.cpp:112] Iteration 16100, lr = 0.001
I0429 15:54:19.120193 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:54:20.199378 25258 solver.cpp:239] Iteration 16120 (3.05061 iter/s, 6.55607s/20 iters), loss = 0.214787
I0429 15:54:20.204435 25258 solver.cpp:258]     Train net output #0: loss = 0.214787 (* 1 = 0.214787 loss)
I0429 15:54:20.204478 25258 sgd_solver.cpp:112] Iteration 16120, lr = 0.001
I0429 15:54:26.634651 25258 solver.cpp:239] Iteration 16140 (3.1104 iter/s, 6.43004s/20 iters), loss = 0.225367
I0429 15:54:26.639672 25258 solver.cpp:258]     Train net output #0: loss = 0.225367 (* 1 = 0.225367 loss)
I0429 15:54:26.639721 25258 sgd_solver.cpp:112] Iteration 16140, lr = 0.001
I0429 15:54:32.051467 25258 solver.cpp:239] Iteration 16160 (3.69573 iter/s, 5.41164s/20 iters), loss = 0.29148
I0429 15:54:32.058012 25258 solver.cpp:258]     Train net output #0: loss = 0.291481 (* 1 = 0.291481 loss)
I0429 15:54:32.058115 25258 sgd_solver.cpp:112] Iteration 16160, lr = 0.001
I0429 15:54:40.240821 25258 solver.cpp:239] Iteration 16180 (2.4442 iter/s, 8.18264s/20 iters), loss = 0.156323
I0429 15:54:40.248006 25258 solver.cpp:258]     Train net output #0: loss = 0.156323 (* 1 = 0.156323 loss)
I0429 15:54:40.248029 25258 sgd_solver.cpp:112] Iteration 16180, lr = 0.001
I0429 15:54:53.632279 25258 solver.cpp:239] Iteration 16200 (1.49433 iter/s, 13.3839s/20 iters), loss = 0.220042
I0429 15:54:53.638062 25258 solver.cpp:258]     Train net output #0: loss = 0.220042 (* 1 = 0.220042 loss)
I0429 15:54:53.638095 25258 sgd_solver.cpp:112] Iteration 16200, lr = 0.001
I0429 15:55:07.484766 25258 solver.cpp:239] Iteration 16220 (1.44443 iter/s, 13.8463s/20 iters), loss = 0.364132
I0429 15:55:07.491358 25258 solver.cpp:258]     Train net output #0: loss = 0.364132 (* 1 = 0.364132 loss)
I0429 15:55:07.491406 25258 sgd_solver.cpp:112] Iteration 16220, lr = 0.001
I0429 15:55:17.975153 25258 solver.cpp:239] Iteration 16240 (1.90775 iter/s, 10.4835s/20 iters), loss = 0.145564
I0429 15:55:17.980227 25258 solver.cpp:258]     Train net output #0: loss = 0.145564 (* 1 = 0.145564 loss)
I0429 15:55:17.980262 25258 sgd_solver.cpp:112] Iteration 16240, lr = 0.001
I0429 15:55:21.252185 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_16250.caffemodel
I0429 15:55:50.517983 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_16250.solverstate
I0429 15:55:50.931061 25258 solver.cpp:351] Iteration 16250, Testing net (#0)
I0429 15:56:02.236027 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.892266
I0429 15:56:02.236086 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.955469
I0429 15:56:02.236094 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.977813
I0429 15:56:02.236104 25258 solver.cpp:418]     Test net output #3: loss = 0.290086 (* 1 = 0.290086 loss)
I0429 15:56:05.137909 25258 solver.cpp:239] Iteration 16260 (0.424121 iter/s, 47.1564s/20 iters), loss = 0.309353
I0429 15:56:05.144058 25258 solver.cpp:258]     Train net output #0: loss = 0.309353 (* 1 = 0.309353 loss)
I0429 15:56:05.144114 25258 sgd_solver.cpp:112] Iteration 16260, lr = 0.001
I0429 15:56:11.144203 25258 solver.cpp:239] Iteration 16280 (3.33333 iter/s, 6.00001s/20 iters), loss = 0.26584
I0429 15:56:11.144289 25258 solver.cpp:258]     Train net output #0: loss = 0.26584 (* 1 = 0.26584 loss)
I0429 15:56:11.144304 25258 sgd_solver.cpp:112] Iteration 16280, lr = 0.001
I0429 15:56:17.414945 25258 solver.cpp:239] Iteration 16300 (3.18955 iter/s, 6.27047s/20 iters), loss = 0.153573
I0429 15:56:17.419998 25258 solver.cpp:258]     Train net output #0: loss = 0.153573 (* 1 = 0.153573 loss)
I0429 15:56:17.420042 25258 sgd_solver.cpp:112] Iteration 16300, lr = 0.001
I0429 15:56:24.831457 25258 solver.cpp:239] Iteration 16320 (2.6986 iter/s, 7.41126s/20 iters), loss = 0.160295
I0429 15:56:24.836676 25258 solver.cpp:258]     Train net output #0: loss = 0.160295 (* 1 = 0.160295 loss)
I0429 15:56:24.836714 25258 sgd_solver.cpp:112] Iteration 16320, lr = 0.001
I0429 15:56:31.321671 25258 solver.cpp:239] Iteration 16340 (3.08412 iter/s, 6.48484s/20 iters), loss = 0.249021
I0429 15:56:31.321772 25258 solver.cpp:258]     Train net output #0: loss = 0.249021 (* 1 = 0.249021 loss)
I0429 15:56:31.321791 25258 sgd_solver.cpp:112] Iteration 16340, lr = 0.001
I0429 15:56:37.782131 25258 solver.cpp:239] Iteration 16360 (3.0959 iter/s, 6.46016s/20 iters), loss = 0.216458
I0429 15:56:37.787690 25258 solver.cpp:258]     Train net output #0: loss = 0.216458 (* 1 = 0.216458 loss)
I0429 15:56:37.787736 25258 sgd_solver.cpp:112] Iteration 16360, lr = 0.001
I0429 15:56:45.046840 25258 solver.cpp:239] Iteration 16380 (2.75521 iter/s, 7.25897s/20 iters), loss = 0.198903
I0429 15:56:45.051900 25258 solver.cpp:258]     Train net output #0: loss = 0.198903 (* 1 = 0.198903 loss)
I0429 15:56:45.051949 25258 sgd_solver.cpp:112] Iteration 16380, lr = 0.001
I0429 15:56:51.496279 25258 solver.cpp:239] Iteration 16400 (3.10356 iter/s, 6.44421s/20 iters), loss = 0.23996
I0429 15:56:51.501796 25258 solver.cpp:258]     Train net output #0: loss = 0.23996 (* 1 = 0.23996 loss)
I0429 15:56:51.501840 25258 sgd_solver.cpp:112] Iteration 16400, lr = 0.001
I0429 15:56:59.061604 25258 solver.cpp:239] Iteration 16420 (2.646 iter/s, 7.55858s/20 iters), loss = 0.207192
I0429 15:56:59.066495 25258 solver.cpp:258]     Train net output #0: loss = 0.207192 (* 1 = 0.207192 loss)
I0429 15:56:59.066519 25258 sgd_solver.cpp:112] Iteration 16420, lr = 0.001
I0429 15:57:05.959544 25258 solver.cpp:239] Iteration 16440 (2.90155 iter/s, 6.89286s/20 iters), loss = 0.239265
I0429 15:57:05.959641 25258 solver.cpp:258]     Train net output #0: loss = 0.239265 (* 1 = 0.239265 loss)
I0429 15:57:05.959656 25258 sgd_solver.cpp:112] Iteration 16440, lr = 0.001
I0429 15:57:12.016101 25258 solver.cpp:239] Iteration 16460 (3.30238 iter/s, 6.05624s/20 iters), loss = 0.285676
I0429 15:57:12.022465 25258 solver.cpp:258]     Train net output #0: loss = 0.285676 (* 1 = 0.285676 loss)
I0429 15:57:12.022532 25258 sgd_solver.cpp:112] Iteration 16460, lr = 0.001
I0429 15:57:19.304770 25258 solver.cpp:239] Iteration 16480 (2.74645 iter/s, 7.28212s/20 iters), loss = 0.278208
I0429 15:57:19.309864 25258 solver.cpp:258]     Train net output #0: loss = 0.278209 (* 1 = 0.278209 loss)
I0429 15:57:19.309907 25258 sgd_solver.cpp:112] Iteration 16480, lr = 0.001
I0429 15:57:32.395700 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_16500.caffemodel
I0429 15:58:10.372663 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_16500.solverstate
I0429 15:58:10.735426 25258 solver.cpp:351] Iteration 16500, Testing net (#0)
I0429 15:58:10.760116 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:58:15.042893 25258 blocking_queue.cpp:49] Waiting for data
I0429 15:58:24.864473 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.888203
I0429 15:58:24.864544 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.952969
I0429 15:58:24.864565 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.978359
I0429 15:58:24.864583 25258 solver.cpp:418]     Test net output #3: loss = 0.298291 (* 1 = 0.298291 loss)
I0429 15:58:25.205586 25258 solver.cpp:239] Iteration 16500 (0.303518 iter/s, 65.8939s/20 iters), loss = 0.29029
I0429 15:58:25.209053 25258 solver.cpp:258]     Train net output #0: loss = 0.29029 (* 1 = 0.29029 loss)
I0429 15:58:25.209116 25258 sgd_solver.cpp:112] Iteration 16500, lr = 0.001
I0429 15:58:33.107255 25258 solver.cpp:239] Iteration 16520 (2.53228 iter/s, 7.89801s/20 iters), loss = 0.271054
I0429 15:58:33.112656 25258 solver.cpp:258]     Train net output #0: loss = 0.271054 (* 1 = 0.271054 loss)
I0429 15:58:33.112701 25258 sgd_solver.cpp:112] Iteration 16520, lr = 0.001
I0429 15:58:41.582762 25258 solver.cpp:239] Iteration 16540 (2.36131 iter/s, 8.46988s/20 iters), loss = 0.284399
I0429 15:58:41.588227 25258 solver.cpp:258]     Train net output #0: loss = 0.284399 (* 1 = 0.284399 loss)
I0429 15:58:41.588258 25258 sgd_solver.cpp:112] Iteration 16540, lr = 0.001
I0429 15:58:50.190124 25258 solver.cpp:239] Iteration 16560 (2.32514 iter/s, 8.60165s/20 iters), loss = 0.205147
I0429 15:58:50.197547 25258 solver.cpp:258]     Train net output #0: loss = 0.205147 (* 1 = 0.205147 loss)
I0429 15:58:50.197602 25258 sgd_solver.cpp:112] Iteration 16560, lr = 0.001
I0429 15:58:57.838907 25258 solver.cpp:239] Iteration 16580 (2.6174 iter/s, 7.64118s/20 iters), loss = 0.169508
I0429 15:58:57.844666 25258 solver.cpp:258]     Train net output #0: loss = 0.169508 (* 1 = 0.169508 loss)
I0429 15:58:57.844727 25258 sgd_solver.cpp:112] Iteration 16580, lr = 0.001
I0429 15:59:04.361660 25258 solver.cpp:239] Iteration 16600 (3.06897 iter/s, 6.51685s/20 iters), loss = 0.122285
I0429 15:59:04.366468 25258 solver.cpp:258]     Train net output #0: loss = 0.122285 (* 1 = 0.122285 loss)
I0429 15:59:04.366493 25258 sgd_solver.cpp:112] Iteration 16600, lr = 0.001
I0429 15:59:12.369830 25258 solver.cpp:239] Iteration 16620 (2.49903 iter/s, 8.00311s/20 iters), loss = 0.253584
I0429 15:59:12.380996 25258 solver.cpp:258]     Train net output #0: loss = 0.253584 (* 1 = 0.253584 loss)
I0429 15:59:12.381021 25258 sgd_solver.cpp:112] Iteration 16620, lr = 0.001
I0429 15:59:19.065474 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 15:59:19.379729 25258 solver.cpp:239] Iteration 16640 (2.85773 iter/s, 6.99855s/20 iters), loss = 0.146344
I0429 15:59:19.384807 25258 solver.cpp:258]     Train net output #0: loss = 0.146344 (* 1 = 0.146344 loss)
I0429 15:59:19.384845 25258 sgd_solver.cpp:112] Iteration 16640, lr = 0.001
I0429 15:59:28.160159 25258 solver.cpp:239] Iteration 16660 (2.27917 iter/s, 8.77512s/20 iters), loss = 0.244209
I0429 15:59:28.165051 25258 solver.cpp:258]     Train net output #0: loss = 0.244209 (* 1 = 0.244209 loss)
I0429 15:59:28.165093 25258 sgd_solver.cpp:112] Iteration 16660, lr = 0.001
I0429 15:59:36.062285 25258 solver.cpp:239] Iteration 16680 (2.5326 iter/s, 7.89703s/20 iters), loss = 0.219838
I0429 15:59:36.068020 25258 solver.cpp:258]     Train net output #0: loss = 0.219838 (* 1 = 0.219838 loss)
I0429 15:59:36.068089 25258 sgd_solver.cpp:112] Iteration 16680, lr = 0.001
I0429 15:59:43.846809 25258 solver.cpp:239] Iteration 16700 (2.57396 iter/s, 7.77014s/20 iters), loss = 0.16407
I0429 15:59:43.848718 25258 solver.cpp:258]     Train net output #0: loss = 0.16407 (* 1 = 0.16407 loss)
I0429 15:59:43.848742 25258 sgd_solver.cpp:112] Iteration 16700, lr = 0.001
I0429 15:59:51.585022 25258 solver.cpp:239] Iteration 16720 (2.58529 iter/s, 7.73609s/20 iters), loss = 0.247019
I0429 15:59:51.591332 25258 solver.cpp:258]     Train net output #0: loss = 0.247019 (* 1 = 0.247019 loss)
I0429 15:59:51.591389 25258 sgd_solver.cpp:112] Iteration 16720, lr = 0.001
I0429 16:00:09.548316 25258 solver.cpp:239] Iteration 16740 (1.1138 iter/s, 17.9565s/20 iters), loss = 0.276237
I0429 16:00:09.553591 25258 solver.cpp:258]     Train net output #0: loss = 0.276237 (* 1 = 0.276237 loss)
I0429 16:00:09.553629 25258 sgd_solver.cpp:112] Iteration 16740, lr = 0.001
I0429 16:00:17.372697 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_16750.caffemodel
I0429 16:00:41.406057 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_16750.solverstate
I0429 16:00:41.802336 25258 solver.cpp:351] Iteration 16750, Testing net (#0)
I0429 16:00:41.976657 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:00:57.431423 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.889531
I0429 16:00:57.432008 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.955312
I0429 16:00:57.432024 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.978984
I0429 16:00:57.432039 25258 solver.cpp:418]     Test net output #3: loss = 0.289216 (* 1 = 0.289216 loss)
I0429 16:01:01.139878 25258 solver.cpp:239] Iteration 16760 (0.38771 iter/s, 51.5849s/20 iters), loss = 0.148776
I0429 16:01:01.139986 25258 solver.cpp:258]     Train net output #0: loss = 0.148776 (* 1 = 0.148776 loss)
I0429 16:01:01.140005 25258 sgd_solver.cpp:112] Iteration 16760, lr = 0.001
I0429 16:01:08.395445 25258 solver.cpp:239] Iteration 16780 (2.75663 iter/s, 7.25524s/20 iters), loss = 0.215121
I0429 16:01:08.401324 25258 solver.cpp:258]     Train net output #0: loss = 0.215121 (* 1 = 0.215121 loss)
I0429 16:01:08.401372 25258 sgd_solver.cpp:112] Iteration 16780, lr = 0.001
I0429 16:01:12.566279 25258 solver.cpp:239] Iteration 16800 (4.80209 iter/s, 4.16485s/20 iters), loss = 0.187584
I0429 16:01:12.571525 25258 solver.cpp:258]     Train net output #0: loss = 0.187584 (* 1 = 0.187584 loss)
I0429 16:01:12.571560 25258 sgd_solver.cpp:112] Iteration 16800, lr = 0.001
I0429 16:01:22.359493 25258 solver.cpp:239] Iteration 16820 (2.04338 iter/s, 9.7877s/20 iters), loss = 0.216039
I0429 16:01:22.364291 25258 solver.cpp:258]     Train net output #0: loss = 0.216039 (* 1 = 0.216039 loss)
I0429 16:01:22.364315 25258 sgd_solver.cpp:112] Iteration 16820, lr = 0.001
I0429 16:01:28.248154 25258 solver.cpp:239] Iteration 16840 (3.39923 iter/s, 5.88369s/20 iters), loss = 0.169587
I0429 16:01:28.258590 25258 solver.cpp:258]     Train net output #0: loss = 0.169587 (* 1 = 0.169587 loss)
I0429 16:01:28.258618 25258 sgd_solver.cpp:112] Iteration 16840, lr = 0.001
I0429 16:01:33.424578 25258 solver.cpp:239] Iteration 16860 (3.87157 iter/s, 5.16586s/20 iters), loss = 0.268637
I0429 16:01:33.429822 25258 solver.cpp:258]     Train net output #0: loss = 0.268637 (* 1 = 0.268637 loss)
I0429 16:01:33.429880 25258 sgd_solver.cpp:112] Iteration 16860, lr = 0.001
I0429 16:01:41.656651 25258 solver.cpp:239] Iteration 16880 (2.4311 iter/s, 8.22673s/20 iters), loss = 0.0955914
I0429 16:01:41.656751 25258 solver.cpp:258]     Train net output #0: loss = 0.0955915 (* 1 = 0.0955915 loss)
I0429 16:01:41.656774 25258 sgd_solver.cpp:112] Iteration 16880, lr = 0.001
I0429 16:01:49.409759 25258 solver.cpp:239] Iteration 16900 (2.57972 iter/s, 7.75278s/20 iters), loss = 0.234682
I0429 16:01:49.414757 25258 solver.cpp:258]     Train net output #0: loss = 0.234682 (* 1 = 0.234682 loss)
I0429 16:01:49.414804 25258 sgd_solver.cpp:112] Iteration 16900, lr = 0.001
I0429 16:01:55.856477 25258 solver.cpp:239] Iteration 16920 (3.10486 iter/s, 6.44151s/20 iters), loss = 0.169051
I0429 16:01:55.863188 25258 solver.cpp:258]     Train net output #0: loss = 0.169051 (* 1 = 0.169051 loss)
I0429 16:01:55.863271 25258 sgd_solver.cpp:112] Iteration 16920, lr = 0.001
I0429 16:02:03.464141 25258 solver.cpp:239] Iteration 16940 (2.6313 iter/s, 7.60079s/20 iters), loss = 0.240075
I0429 16:02:03.469332 25258 solver.cpp:258]     Train net output #0: loss = 0.240075 (* 1 = 0.240075 loss)
I0429 16:02:03.469357 25258 sgd_solver.cpp:112] Iteration 16940, lr = 0.001
I0429 16:02:12.012437 25258 solver.cpp:239] Iteration 16960 (2.34114 iter/s, 8.54286s/20 iters), loss = 0.22499
I0429 16:02:12.018481 25258 solver.cpp:258]     Train net output #0: loss = 0.22499 (* 1 = 0.22499 loss)
I0429 16:02:12.018544 25258 sgd_solver.cpp:112] Iteration 16960, lr = 0.001
I0429 16:02:19.107950 25258 solver.cpp:239] Iteration 16980 (2.82115 iter/s, 7.08931s/20 iters), loss = 0.186942
I0429 16:02:19.113031 25258 solver.cpp:258]     Train net output #0: loss = 0.186942 (* 1 = 0.186942 loss)
I0429 16:02:19.113098 25258 sgd_solver.cpp:112] Iteration 16980, lr = 0.001
I0429 16:02:26.609668 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_17000.caffemodel
I0429 16:03:09.927043 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_17000.solverstate
I0429 16:03:10.344202 25258 solver.cpp:351] Iteration 17000, Testing net (#0)
I0429 16:03:10.585381 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:03:25.222615 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.895938
I0429 16:03:25.222668 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.957734
I0429 16:03:25.222679 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.979062
I0429 16:03:25.222692 25258 solver.cpp:418]     Test net output #3: loss = 0.275577 (* 1 = 0.275577 loss)
I0429 16:03:25.661823 25258 solver.cpp:239] Iteration 17000 (0.300539 iter/s, 66.5471s/20 iters), loss = 0.234109
I0429 16:03:25.665076 25258 solver.cpp:258]     Train net output #0: loss = 0.234109 (* 1 = 0.234109 loss)
I0429 16:03:25.665120 25258 sgd_solver.cpp:112] Iteration 17000, lr = 0.001
I0429 16:03:31.227563 25258 solver.cpp:239] Iteration 17020 (3.59561 iter/s, 5.56235s/20 iters), loss = 0.311566
I0429 16:03:31.232820 25258 solver.cpp:258]     Train net output #0: loss = 0.311566 (* 1 = 0.311566 loss)
I0429 16:03:31.232863 25258 sgd_solver.cpp:112] Iteration 17020, lr = 0.001
I0429 16:03:37.821800 25258 solver.cpp:239] Iteration 17040 (3.03548 iter/s, 6.58875s/20 iters), loss = 0.184946
I0429 16:03:37.829852 25258 solver.cpp:258]     Train net output #0: loss = 0.184946 (* 1 = 0.184946 loss)
I0429 16:03:37.829957 25258 sgd_solver.cpp:112] Iteration 17040, lr = 0.001
I0429 16:03:44.658573 25258 solver.cpp:239] Iteration 17060 (2.92887 iter/s, 6.82858s/20 iters), loss = 0.329636
I0429 16:03:44.668272 25258 solver.cpp:258]     Train net output #0: loss = 0.329636 (* 1 = 0.329636 loss)
I0429 16:03:44.668309 25258 sgd_solver.cpp:112] Iteration 17060, lr = 0.001
I0429 16:03:51.481604 25258 solver.cpp:239] Iteration 17080 (2.9355 iter/s, 6.81315s/20 iters), loss = 0.193084
I0429 16:03:51.486676 25258 solver.cpp:258]     Train net output #0: loss = 0.193084 (* 1 = 0.193084 loss)
I0429 16:03:51.486716 25258 sgd_solver.cpp:112] Iteration 17080, lr = 0.001
I0429 16:03:58.702484 25258 solver.cpp:239] Iteration 17100 (2.77176 iter/s, 7.21564s/20 iters), loss = 0.19699
I0429 16:03:58.707979 25258 solver.cpp:258]     Train net output #0: loss = 0.19699 (* 1 = 0.19699 loss)
I0429 16:03:58.708036 25258 sgd_solver.cpp:112] Iteration 17100, lr = 0.001
I0429 16:04:05.519114 25258 solver.cpp:239] Iteration 17120 (2.93643 iter/s, 6.81098s/20 iters), loss = 0.210718
I0429 16:04:05.524861 25258 solver.cpp:258]     Train net output #0: loss = 0.210719 (* 1 = 0.210719 loss)
I0429 16:04:05.524916 25258 sgd_solver.cpp:112] Iteration 17120, lr = 0.001
I0429 16:04:12.706198 25258 solver.cpp:239] Iteration 17140 (2.78506 iter/s, 7.18117s/20 iters), loss = 0.257817
I0429 16:04:12.715576 25258 solver.cpp:258]     Train net output #0: loss = 0.257817 (* 1 = 0.257817 loss)
I0429 16:04:12.715627 25258 sgd_solver.cpp:112] Iteration 17140, lr = 0.001
I0429 16:04:18.542366 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:04:19.888823 25258 solver.cpp:239] Iteration 17160 (2.7882 iter/s, 7.17307s/20 iters), loss = 0.163152
I0429 16:04:19.894011 25258 solver.cpp:258]     Train net output #0: loss = 0.163152 (* 1 = 0.163152 loss)
I0429 16:04:19.894057 25258 sgd_solver.cpp:112] Iteration 17160, lr = 0.001
I0429 16:04:27.195879 25258 solver.cpp:239] Iteration 17180 (2.73909 iter/s, 7.30168s/20 iters), loss = 0.154236
I0429 16:04:27.200870 25258 solver.cpp:258]     Train net output #0: loss = 0.154237 (* 1 = 0.154237 loss)
I0429 16:04:27.200899 25258 sgd_solver.cpp:112] Iteration 17180, lr = 0.001
I0429 16:04:34.501664 25258 solver.cpp:239] Iteration 17200 (2.7395 iter/s, 7.30059s/20 iters), loss = 0.242509
I0429 16:04:34.510048 25258 solver.cpp:258]     Train net output #0: loss = 0.242509 (* 1 = 0.242509 loss)
I0429 16:04:34.510098 25258 sgd_solver.cpp:112] Iteration 17200, lr = 0.001
I0429 16:04:43.001657 25258 solver.cpp:239] Iteration 17220 (2.35533 iter/s, 8.49137s/20 iters), loss = 0.239973
I0429 16:04:43.007362 25258 solver.cpp:258]     Train net output #0: loss = 0.239973 (* 1 = 0.239973 loss)
I0429 16:04:43.007416 25258 sgd_solver.cpp:112] Iteration 17220, lr = 0.001
I0429 16:04:58.860586 25258 solver.cpp:239] Iteration 17240 (1.2616 iter/s, 15.8528s/20 iters), loss = 0.147902
I0429 16:04:58.865772 25258 solver.cpp:258]     Train net output #0: loss = 0.147902 (* 1 = 0.147902 loss)
I0429 16:04:58.865799 25258 sgd_solver.cpp:112] Iteration 17240, lr = 0.001
I0429 16:05:05.480871 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_17250.caffemodel
I0429 16:05:44.725991 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_17250.solverstate
I0429 16:05:45.170678 25258 solver.cpp:351] Iteration 17250, Testing net (#0)
I0429 16:05:45.515117 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:05:51.235417 25258 blocking_queue.cpp:49] Waiting for data
I0429 16:05:56.250838 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.896797
I0429 16:05:56.250892 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.953906
I0429 16:05:56.250907 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.978437
I0429 16:05:56.250926 25258 solver.cpp:418]     Test net output #3: loss = 0.272333 (* 1 = 0.272333 loss)
I0429 16:05:58.855350 25258 solver.cpp:239] Iteration 17260 (0.333399 iter/s, 59.9881s/20 iters), loss = 0.251603
I0429 16:05:58.855410 25258 solver.cpp:258]     Train net output #0: loss = 0.251603 (* 1 = 0.251603 loss)
I0429 16:05:58.855423 25258 sgd_solver.cpp:112] Iteration 17260, lr = 0.001
I0429 16:06:04.140827 25258 solver.cpp:239] Iteration 17280 (3.78411 iter/s, 5.28526s/20 iters), loss = 0.185153
I0429 16:06:04.145838 25258 solver.cpp:258]     Train net output #0: loss = 0.185153 (* 1 = 0.185153 loss)
I0429 16:06:04.145893 25258 sgd_solver.cpp:112] Iteration 17280, lr = 0.001
I0429 16:06:11.528574 25258 solver.cpp:239] Iteration 17300 (2.70909 iter/s, 7.38256s/20 iters), loss = 0.322734
I0429 16:06:11.533577 25258 solver.cpp:258]     Train net output #0: loss = 0.322734 (* 1 = 0.322734 loss)
I0429 16:06:11.533607 25258 sgd_solver.cpp:112] Iteration 17300, lr = 0.001
I0429 16:06:16.863651 25258 solver.cpp:239] Iteration 17320 (3.7524 iter/s, 5.32993s/20 iters), loss = 0.223491
I0429 16:06:16.869164 25258 solver.cpp:258]     Train net output #0: loss = 0.223491 (* 1 = 0.223491 loss)
I0429 16:06:16.869187 25258 sgd_solver.cpp:112] Iteration 17320, lr = 0.001
I0429 16:06:20.729848 25258 solver.cpp:239] Iteration 17340 (5.18056 iter/s, 3.86059s/20 iters), loss = 0.141343
I0429 16:06:20.734875 25258 solver.cpp:258]     Train net output #0: loss = 0.141343 (* 1 = 0.141343 loss)
I0429 16:06:20.734908 25258 sgd_solver.cpp:112] Iteration 17340, lr = 0.001
I0429 16:06:30.118145 25258 solver.cpp:239] Iteration 17360 (2.13151 iter/s, 9.38301s/20 iters), loss = 0.276409
I0429 16:06:30.123086 25258 solver.cpp:258]     Train net output #0: loss = 0.276409 (* 1 = 0.276409 loss)
I0429 16:06:30.123117 25258 sgd_solver.cpp:112] Iteration 17360, lr = 0.001
I0429 16:06:37.447203 25258 solver.cpp:239] Iteration 17380 (2.73078 iter/s, 7.32392s/20 iters), loss = 0.235476
I0429 16:06:37.452002 25258 solver.cpp:258]     Train net output #0: loss = 0.235476 (* 1 = 0.235476 loss)
I0429 16:06:37.452041 25258 sgd_solver.cpp:112] Iteration 17380, lr = 0.001
I0429 16:06:44.972770 25258 solver.cpp:239] Iteration 17400 (2.65937 iter/s, 7.52058s/20 iters), loss = 0.0966798
I0429 16:06:44.977674 25258 solver.cpp:258]     Train net output #0: loss = 0.0966799 (* 1 = 0.0966799 loss)
I0429 16:06:44.977790 25258 sgd_solver.cpp:112] Iteration 17400, lr = 0.001
I0429 16:06:51.069254 25258 solver.cpp:239] Iteration 17420 (3.28329 iter/s, 6.09144s/20 iters), loss = 0.215296
I0429 16:06:51.074520 25258 solver.cpp:258]     Train net output #0: loss = 0.215296 (* 1 = 0.215296 loss)
I0429 16:06:51.074569 25258 sgd_solver.cpp:112] Iteration 17420, lr = 0.001
I0429 16:06:57.450592 25258 solver.cpp:239] Iteration 17440 (3.13681 iter/s, 6.37591s/20 iters), loss = 0.224185
I0429 16:06:57.455415 25258 solver.cpp:258]     Train net output #0: loss = 0.224185 (* 1 = 0.224185 loss)
I0429 16:06:57.455446 25258 sgd_solver.cpp:112] Iteration 17440, lr = 0.001
I0429 16:07:07.649861 25258 solver.cpp:239] Iteration 17460 (1.9619 iter/s, 10.1942s/20 iters), loss = 0.185578
I0429 16:07:07.655133 25258 solver.cpp:258]     Train net output #0: loss = 0.185578 (* 1 = 0.185578 loss)
I0429 16:07:07.655164 25258 sgd_solver.cpp:112] Iteration 17460, lr = 0.001
I0429 16:07:23.648272 25258 solver.cpp:239] Iteration 17480 (1.25057 iter/s, 15.9927s/20 iters), loss = 0.26427
I0429 16:07:23.675271 25258 solver.cpp:258]     Train net output #0: loss = 0.26427 (* 1 = 0.26427 loss)
I0429 16:07:23.675292 25258 sgd_solver.cpp:112] Iteration 17480, lr = 0.001
I0429 16:07:36.463441 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_17500.caffemodel
I0429 16:07:46.479390 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_17500.solverstate
I0429 16:07:46.857568 25258 solver.cpp:351] Iteration 17500, Testing net (#0)
I0429 16:07:47.301157 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:08:00.199538 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.899063
I0429 16:08:00.202070 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.957344
I0429 16:08:00.202105 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.979297
I0429 16:08:00.202124 25258 solver.cpp:418]     Test net output #3: loss = 0.271723 (* 1 = 0.271723 loss)
I0429 16:08:00.718495 25258 solver.cpp:239] Iteration 17500 (0.53993 iter/s, 37.0418s/20 iters), loss = 0.247749
I0429 16:08:00.721606 25258 solver.cpp:258]     Train net output #0: loss = 0.247749 (* 1 = 0.247749 loss)
I0429 16:08:00.721678 25258 sgd_solver.cpp:112] Iteration 17500, lr = 0.001
I0429 16:08:07.637977 25258 solver.cpp:239] Iteration 17520 (2.89175 iter/s, 6.91622s/20 iters), loss = 0.328582
I0429 16:08:07.642797 25258 solver.cpp:258]     Train net output #0: loss = 0.328582 (* 1 = 0.328582 loss)
I0429 16:08:07.642822 25258 sgd_solver.cpp:112] Iteration 17520, lr = 0.001
I0429 16:08:14.119457 25258 solver.cpp:239] Iteration 17540 (3.0881 iter/s, 6.47648s/20 iters), loss = 0.16883
I0429 16:08:14.125063 25258 solver.cpp:258]     Train net output #0: loss = 0.16883 (* 1 = 0.16883 loss)
I0429 16:08:14.125133 25258 sgd_solver.cpp:112] Iteration 17540, lr = 0.001
I0429 16:08:21.939568 25258 solver.cpp:239] Iteration 17560 (2.5594 iter/s, 7.81434s/20 iters), loss = 0.101485
I0429 16:08:21.944370 25258 solver.cpp:258]     Train net output #0: loss = 0.101485 (* 1 = 0.101485 loss)
I0429 16:08:21.944402 25258 sgd_solver.cpp:112] Iteration 17560, lr = 0.001
I0429 16:08:28.337254 25258 solver.cpp:239] Iteration 17580 (3.12856 iter/s, 6.39271s/20 iters), loss = 0.235402
I0429 16:08:28.346622 25258 solver.cpp:258]     Train net output #0: loss = 0.235402 (* 1 = 0.235402 loss)
I0429 16:08:28.346685 25258 sgd_solver.cpp:112] Iteration 17580, lr = 0.001
I0429 16:08:35.269436 25258 solver.cpp:239] Iteration 17600 (2.88907 iter/s, 6.92265s/20 iters), loss = 0.137564
I0429 16:08:35.274727 25258 solver.cpp:258]     Train net output #0: loss = 0.137564 (* 1 = 0.137564 loss)
I0429 16:08:35.274777 25258 sgd_solver.cpp:112] Iteration 17600, lr = 0.001
I0429 16:08:41.970506 25258 solver.cpp:239] Iteration 17620 (2.98703 iter/s, 6.69562s/20 iters), loss = 0.152104
I0429 16:08:41.979991 25258 solver.cpp:258]     Train net output #0: loss = 0.152104 (* 1 = 0.152104 loss)
I0429 16:08:41.980038 25258 sgd_solver.cpp:112] Iteration 17620, lr = 0.001
I0429 16:08:49.153029 25258 solver.cpp:239] Iteration 17640 (2.78829 iter/s, 7.17287s/20 iters), loss = 0.165664
I0429 16:08:49.157853 25258 solver.cpp:258]     Train net output #0: loss = 0.165664 (* 1 = 0.165664 loss)
I0429 16:08:49.157902 25258 sgd_solver.cpp:112] Iteration 17640, lr = 0.001
I0429 16:08:54.449251 25258 solver.cpp:239] Iteration 17660 (3.77981 iter/s, 5.29127s/20 iters), loss = 0.265206
I0429 16:08:54.454073 25258 solver.cpp:258]     Train net output #0: loss = 0.265206 (* 1 = 0.265206 loss)
I0429 16:08:54.454109 25258 sgd_solver.cpp:112] Iteration 17660, lr = 0.001
I0429 16:09:00.404805 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:09:01.073093 25258 solver.cpp:239] Iteration 17680 (3.02168 iter/s, 6.61884s/20 iters), loss = 0.187179
I0429 16:09:01.077898 25258 solver.cpp:258]     Train net output #0: loss = 0.187179 (* 1 = 0.187179 loss)
I0429 16:09:01.077932 25258 sgd_solver.cpp:112] Iteration 17680, lr = 0.001
I0429 16:09:07.067662 25258 solver.cpp:239] Iteration 17700 (3.33911 iter/s, 5.98961s/20 iters), loss = 0.135872
I0429 16:09:07.072479 25258 solver.cpp:258]     Train net output #0: loss = 0.135872 (* 1 = 0.135872 loss)
I0429 16:09:07.072497 25258 sgd_solver.cpp:112] Iteration 17700, lr = 0.001
I0429 16:09:13.870965 25258 solver.cpp:239] Iteration 17720 (2.94191 iter/s, 6.7983s/20 iters), loss = 0.221728
I0429 16:09:13.875787 25258 solver.cpp:258]     Train net output #0: loss = 0.221728 (* 1 = 0.221728 loss)
I0429 16:09:13.875818 25258 sgd_solver.cpp:112] Iteration 17720, lr = 0.001
I0429 16:09:21.937819 25258 solver.cpp:239] Iteration 17740 (2.48083 iter/s, 8.06182s/20 iters), loss = 0.15382
I0429 16:09:21.943842 25258 solver.cpp:258]     Train net output #0: loss = 0.15382 (* 1 = 0.15382 loss)
I0429 16:09:21.943868 25258 sgd_solver.cpp:112] Iteration 17740, lr = 0.001
I0429 16:09:27.006031 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_17750.caffemodel
I0429 16:10:32.028370 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_17750.solverstate
I0429 16:10:32.382323 25258 solver.cpp:351] Iteration 17750, Testing net (#0)
I0429 16:10:32.943799 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:10:40.787834 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.902031
I0429 16:10:40.787874 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.956094
I0429 16:10:40.787881 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.977344
I0429 16:10:40.787889 25258 solver.cpp:418]     Test net output #3: loss = 0.265396 (* 1 = 0.265396 loss)
I0429 16:10:42.227507 25258 solver.cpp:239] Iteration 17760 (0.249123 iter/s, 80.2816s/20 iters), loss = 0.176651
I0429 16:10:42.232492 25258 solver.cpp:258]     Train net output #0: loss = 0.176651 (* 1 = 0.176651 loss)
I0429 16:10:42.232527 25258 sgd_solver.cpp:112] Iteration 17760, lr = 0.001
I0429 16:10:45.745327 25258 solver.cpp:239] Iteration 17780 (5.69356 iter/s, 3.51274s/20 iters), loss = 0.271078
I0429 16:10:45.750146 25258 solver.cpp:258]     Train net output #0: loss = 0.271078 (* 1 = 0.271078 loss)
I0429 16:10:45.750188 25258 sgd_solver.cpp:112] Iteration 17780, lr = 0.001
I0429 16:10:49.507664 25258 solver.cpp:239] Iteration 17800 (5.32289 iter/s, 3.75736s/20 iters), loss = 0.257867
I0429 16:10:49.513463 25258 solver.cpp:258]     Train net output #0: loss = 0.257867 (* 1 = 0.257867 loss)
I0429 16:10:49.513535 25258 sgd_solver.cpp:112] Iteration 17800, lr = 0.001
I0429 16:10:54.212162 25258 solver.cpp:239] Iteration 17820 (4.25657 iter/s, 4.69862s/20 iters), loss = 0.238096
I0429 16:10:54.216981 25258 solver.cpp:258]     Train net output #0: loss = 0.238096 (* 1 = 0.238096 loss)
I0429 16:10:54.217010 25258 sgd_solver.cpp:112] Iteration 17820, lr = 0.001
I0429 16:10:58.166154 25258 solver.cpp:239] Iteration 17840 (5.06448 iter/s, 3.94907s/20 iters), loss = 0.191414
I0429 16:10:58.170948 25258 solver.cpp:258]     Train net output #0: loss = 0.191414 (* 1 = 0.191414 loss)
I0429 16:10:58.170974 25258 sgd_solver.cpp:112] Iteration 17840, lr = 0.001
I0429 16:11:03.327808 25258 solver.cpp:239] Iteration 17860 (3.87843 iter/s, 5.15672s/20 iters), loss = 0.131244
I0429 16:11:03.332619 25258 solver.cpp:258]     Train net output #0: loss = 0.131244 (* 1 = 0.131244 loss)
I0429 16:11:03.332646 25258 sgd_solver.cpp:112] Iteration 17860, lr = 0.001
I0429 16:11:09.642369 25258 solver.cpp:239] Iteration 17880 (3.16978 iter/s, 6.30958s/20 iters), loss = 0.148217
I0429 16:11:09.650759 25258 solver.cpp:258]     Train net output #0: loss = 0.148217 (* 1 = 0.148217 loss)
I0429 16:11:09.650805 25258 sgd_solver.cpp:112] Iteration 17880, lr = 0.001
I0429 16:11:15.578290 25258 solver.cpp:239] Iteration 17900 (3.37416 iter/s, 5.92739s/20 iters), loss = 0.311026
I0429 16:11:15.583096 25258 solver.cpp:258]     Train net output #0: loss = 0.311026 (* 1 = 0.311026 loss)
I0429 16:11:15.583130 25258 sgd_solver.cpp:112] Iteration 17900, lr = 0.001
I0429 16:11:21.125289 25258 solver.cpp:239] Iteration 17920 (3.60878 iter/s, 5.54204s/20 iters), loss = 0.0961347
I0429 16:11:21.130462 25258 solver.cpp:258]     Train net output #0: loss = 0.0961348 (* 1 = 0.0961348 loss)
I0429 16:11:21.130509 25258 sgd_solver.cpp:112] Iteration 17920, lr = 0.001
I0429 16:11:33.302739 25258 solver.cpp:239] Iteration 17940 (1.64312 iter/s, 12.172s/20 iters), loss = 0.155578
I0429 16:11:33.307610 25258 solver.cpp:258]     Train net output #0: loss = 0.155578 (* 1 = 0.155578 loss)
I0429 16:11:33.307649 25258 sgd_solver.cpp:112] Iteration 17940, lr = 0.001
I0429 16:11:47.492735 25258 solver.cpp:239] Iteration 17960 (1.40996 iter/s, 14.1848s/20 iters), loss = 0.12584
I0429 16:11:47.498260 25258 solver.cpp:258]     Train net output #0: loss = 0.12584 (* 1 = 0.12584 loss)
I0429 16:11:47.498284 25258 sgd_solver.cpp:112] Iteration 17960, lr = 0.001
I0429 16:11:57.299981 25258 solver.cpp:239] Iteration 17980 (2.04051 iter/s, 9.80147s/20 iters), loss = 0.206346
I0429 16:11:57.305523 25258 solver.cpp:258]     Train net output #0: loss = 0.206346 (* 1 = 0.206346 loss)
I0429 16:11:57.305559 25258 sgd_solver.cpp:112] Iteration 17980, lr = 0.001
I0429 16:12:03.275120 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_18000.caffemodel
I0429 16:12:26.976183 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_18000.solverstate
I0429 16:12:27.311794 25258 solver.cpp:351] Iteration 18000, Testing net (#0)
I0429 16:12:27.968931 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:12:36.317371 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.901797
I0429 16:12:36.317440 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.955078
I0429 16:12:36.317458 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.977578
I0429 16:12:36.317474 25258 solver.cpp:418]     Test net output #3: loss = 0.267641 (* 1 = 0.267641 loss)
I0429 16:12:36.487282 25258 solver.cpp:239] Iteration 18000 (0.510455 iter/s, 39.1807s/20 iters), loss = 0.224194
I0429 16:12:36.490738 25258 solver.cpp:258]     Train net output #0: loss = 0.224194 (* 1 = 0.224194 loss)
I0429 16:12:36.490825 25258 sgd_solver.cpp:112] Iteration 18000, lr = 0.001
I0429 16:12:41.681768 25258 solver.cpp:239] Iteration 18020 (3.8529 iter/s, 5.1909s/20 iters), loss = 0.147942
I0429 16:12:41.688318 25258 solver.cpp:258]     Train net output #0: loss = 0.147942 (* 1 = 0.147942 loss)
I0429 16:12:41.688354 25258 sgd_solver.cpp:112] Iteration 18020, lr = 0.001
I0429 16:12:47.786092 25258 solver.cpp:239] Iteration 18040 (3.27997 iter/s, 6.09762s/20 iters), loss = 0.18163
I0429 16:12:47.790859 25258 solver.cpp:258]     Train net output #0: loss = 0.18163 (* 1 = 0.18163 loss)
I0429 16:12:47.790894 25258 sgd_solver.cpp:112] Iteration 18040, lr = 0.001
I0429 16:12:53.454022 25258 solver.cpp:239] Iteration 18060 (3.5317 iter/s, 5.663s/20 iters), loss = 0.163305
I0429 16:12:53.460983 25258 solver.cpp:258]     Train net output #0: loss = 0.163306 (* 1 = 0.163306 loss)
I0429 16:12:53.461040 25258 sgd_solver.cpp:112] Iteration 18060, lr = 0.001
I0429 16:12:58.302865 25258 solver.cpp:239] Iteration 18080 (4.13071 iter/s, 4.84178s/20 iters), loss = 0.154608
I0429 16:12:58.308395 25258 solver.cpp:258]     Train net output #0: loss = 0.154608 (* 1 = 0.154608 loss)
I0429 16:12:58.309079 25258 sgd_solver.cpp:112] Iteration 18080, lr = 0.001
I0429 16:12:59.463235 25258 blocking_queue.cpp:49] Waiting for data
I0429 16:13:01.775543 25258 solver.cpp:239] Iteration 18100 (5.76856 iter/s, 3.46707s/20 iters), loss = 0.361799
I0429 16:13:01.780781 25258 solver.cpp:258]     Train net output #0: loss = 0.361799 (* 1 = 0.361799 loss)
I0429 16:13:01.780827 25258 sgd_solver.cpp:112] Iteration 18100, lr = 0.001
I0429 16:13:09.626580 25258 solver.cpp:239] Iteration 18120 (2.5492 iter/s, 7.84561s/20 iters), loss = 0.141673
I0429 16:13:09.632103 25258 solver.cpp:258]     Train net output #0: loss = 0.141673 (* 1 = 0.141673 loss)
I0429 16:13:09.632156 25258 sgd_solver.cpp:112] Iteration 18120, lr = 0.001
I0429 16:13:15.522675 25258 solver.cpp:239] Iteration 18140 (3.39533 iter/s, 5.89044s/20 iters), loss = 0.164202
I0429 16:13:15.528367 25258 solver.cpp:258]     Train net output #0: loss = 0.164202 (* 1 = 0.164202 loss)
I0429 16:13:15.528419 25258 sgd_solver.cpp:112] Iteration 18140, lr = 0.001
I0429 16:13:20.758074 25258 solver.cpp:239] Iteration 18160 (3.82439 iter/s, 5.22959s/20 iters), loss = 0.168198
I0429 16:13:20.763667 25258 solver.cpp:258]     Train net output #0: loss = 0.168198 (* 1 = 0.168198 loss)
I0429 16:13:20.763721 25258 sgd_solver.cpp:112] Iteration 18160, lr = 0.001
I0429 16:13:24.702756 25258 solver.cpp:239] Iteration 18180 (5.07741 iter/s, 3.93902s/20 iters), loss = 0.269655
I0429 16:13:24.708807 25258 solver.cpp:258]     Train net output #0: loss = 0.269655 (* 1 = 0.269655 loss)
I0429 16:13:24.708866 25258 sgd_solver.cpp:112] Iteration 18180, lr = 0.001
I0429 16:13:29.797564 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:13:31.134008 25258 solver.cpp:239] Iteration 18200 (3.11281 iter/s, 6.42505s/20 iters), loss = 0.162493
I0429 16:13:31.139971 25258 solver.cpp:258]     Train net output #0: loss = 0.162493 (* 1 = 0.162493 loss)
I0429 16:13:31.140030 25258 sgd_solver.cpp:112] Iteration 18200, lr = 0.001
I0429 16:13:37.711848 25258 solver.cpp:239] Iteration 18220 (3.04334 iter/s, 6.57173s/20 iters), loss = 0.153807
I0429 16:13:37.719825 25258 solver.cpp:258]     Train net output #0: loss = 0.153807 (* 1 = 0.153807 loss)
I0429 16:13:37.719866 25258 sgd_solver.cpp:112] Iteration 18220, lr = 0.001
I0429 16:13:44.426287 25258 solver.cpp:239] Iteration 18240 (2.98227 iter/s, 6.70629s/20 iters), loss = 0.19344
I0429 16:13:44.431310 25258 solver.cpp:258]     Train net output #0: loss = 0.19344 (* 1 = 0.19344 loss)
I0429 16:13:44.431347 25258 sgd_solver.cpp:112] Iteration 18240, lr = 0.001
I0429 16:13:50.086874 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_18250.caffemodel
I0429 16:14:09.613930 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_18250.solverstate
I0429 16:14:10.107717 25258 solver.cpp:351] Iteration 18250, Testing net (#0)
I0429 16:14:11.323760 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:14:24.933054 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.902891
I0429 16:14:24.933117 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.956563
I0429 16:14:24.933128 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.978594
I0429 16:14:24.933146 25258 solver.cpp:418]     Test net output #3: loss = 0.260375 (* 1 = 0.260375 loss)
I0429 16:14:29.812551 25258 solver.cpp:239] Iteration 18260 (0.440722 iter/s, 45.3801s/20 iters), loss = 0.182856
I0429 16:14:29.817415 25258 solver.cpp:258]     Train net output #0: loss = 0.182857 (* 1 = 0.182857 loss)
I0429 16:14:29.817457 25258 sgd_solver.cpp:112] Iteration 18260, lr = 0.001
I0429 16:14:36.364058 25258 solver.cpp:239] Iteration 18280 (3.05508 iter/s, 6.54648s/20 iters), loss = 0.238623
I0429 16:14:36.368917 25258 solver.cpp:258]     Train net output #0: loss = 0.238623 (* 1 = 0.238623 loss)
I0429 16:14:36.368963 25258 sgd_solver.cpp:112] Iteration 18280, lr = 0.001
I0429 16:14:42.145447 25258 solver.cpp:239] Iteration 18300 (3.46236 iter/s, 5.7764s/20 iters), loss = 0.268771
I0429 16:14:42.150246 25258 solver.cpp:258]     Train net output #0: loss = 0.268771 (* 1 = 0.268771 loss)
I0429 16:14:42.150274 25258 sgd_solver.cpp:112] Iteration 18300, lr = 0.001
I0429 16:14:48.335428 25258 solver.cpp:239] Iteration 18320 (3.23362 iter/s, 6.18502s/20 iters), loss = 0.0787396
I0429 16:14:48.340224 25258 solver.cpp:258]     Train net output #0: loss = 0.0787397 (* 1 = 0.0787397 loss)
I0429 16:14:48.340251 25258 sgd_solver.cpp:112] Iteration 18320, lr = 0.001
I0429 16:14:54.382906 25258 solver.cpp:239] Iteration 18340 (3.30988 iter/s, 6.04252s/20 iters), loss = 0.212426
I0429 16:14:54.387732 25258 solver.cpp:258]     Train net output #0: loss = 0.212426 (* 1 = 0.212426 loss)
I0429 16:14:54.387756 25258 sgd_solver.cpp:112] Iteration 18340, lr = 0.001
I0429 16:15:00.213822 25258 solver.cpp:239] Iteration 18360 (3.43293 iter/s, 5.82593s/20 iters), loss = 0.200821
I0429 16:15:00.219291 25258 solver.cpp:258]     Train net output #0: loss = 0.200821 (* 1 = 0.200821 loss)
I0429 16:15:00.219311 25258 sgd_solver.cpp:112] Iteration 18360, lr = 0.001
I0429 16:15:07.043956 25258 solver.cpp:239] Iteration 18380 (2.93063 iter/s, 6.82448s/20 iters), loss = 0.116598
I0429 16:15:07.048754 25258 solver.cpp:258]     Train net output #0: loss = 0.116598 (* 1 = 0.116598 loss)
I0429 16:15:07.048784 25258 sgd_solver.cpp:112] Iteration 18380, lr = 0.001
I0429 16:15:13.475248 25258 solver.cpp:239] Iteration 18400 (3.1122 iter/s, 6.42633s/20 iters), loss = 0.166386
I0429 16:15:13.480154 25258 solver.cpp:258]     Train net output #0: loss = 0.166386 (* 1 = 0.166386 loss)
I0429 16:15:13.480185 25258 sgd_solver.cpp:112] Iteration 18400, lr = 0.001
I0429 16:15:19.406397 25258 solver.cpp:239] Iteration 18420 (3.3749 iter/s, 5.9261s/20 iters), loss = 0.223176
I0429 16:15:19.411212 25258 solver.cpp:258]     Train net output #0: loss = 0.223176 (* 1 = 0.223176 loss)
I0429 16:15:19.411247 25258 sgd_solver.cpp:112] Iteration 18420, lr = 0.001
I0429 16:15:25.792294 25258 solver.cpp:239] Iteration 18440 (3.13434 iter/s, 6.38092s/20 iters), loss = 0.0875937
I0429 16:15:25.792351 25258 solver.cpp:258]     Train net output #0: loss = 0.0875939 (* 1 = 0.0875939 loss)
I0429 16:15:25.792361 25258 sgd_solver.cpp:112] Iteration 18440, lr = 0.001
I0429 16:15:32.261602 25258 solver.cpp:239] Iteration 18460 (3.09164 iter/s, 6.46907s/20 iters), loss = 0.156555
I0429 16:15:32.266450 25258 solver.cpp:258]     Train net output #0: loss = 0.156555 (* 1 = 0.156555 loss)
I0429 16:15:32.266492 25258 sgd_solver.cpp:112] Iteration 18460, lr = 0.001
I0429 16:15:39.346508 25258 solver.cpp:239] Iteration 18480 (2.8249 iter/s, 7.07989s/20 iters), loss = 0.193322
I0429 16:15:39.351372 25258 solver.cpp:258]     Train net output #0: loss = 0.193322 (* 1 = 0.193322 loss)
I0429 16:15:39.351420 25258 sgd_solver.cpp:112] Iteration 18480, lr = 0.001
I0429 16:15:44.774679 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_18500.caffemodel
I0429 16:16:35.364508 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_18500.solverstate
I0429 16:16:35.718928 25258 solver.cpp:351] Iteration 18500, Testing net (#0)
I0429 16:16:36.413872 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:16:43.788249 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.902578
I0429 16:16:43.788302 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.955547
I0429 16:16:43.788311 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.978203
I0429 16:16:43.788317 25258 solver.cpp:418]     Test net output #3: loss = 0.262779 (* 1 = 0.262779 loss)
I0429 16:16:44.357990 25258 solver.cpp:239] Iteration 18500 (0.307669 iter/s, 65.005s/20 iters), loss = 0.194145
I0429 16:16:44.358048 25258 solver.cpp:258]     Train net output #0: loss = 0.194145 (* 1 = 0.194145 loss)
I0429 16:16:44.358059 25258 sgd_solver.cpp:112] Iteration 18500, lr = 0.001
I0429 16:16:49.908783 25258 solver.cpp:239] Iteration 18520 (3.60323 iter/s, 5.55058s/20 iters), loss = 0.223732
I0429 16:16:49.913620 25258 solver.cpp:258]     Train net output #0: loss = 0.223732 (* 1 = 0.223732 loss)
I0429 16:16:49.913647 25258 sgd_solver.cpp:112] Iteration 18520, lr = 0.001
I0429 16:16:55.904923 25258 solver.cpp:239] Iteration 18540 (3.33826 iter/s, 5.99115s/20 iters), loss = 0.151923
I0429 16:16:55.909832 25258 solver.cpp:258]     Train net output #0: loss = 0.151923 (* 1 = 0.151923 loss)
I0429 16:16:55.909868 25258 sgd_solver.cpp:112] Iteration 18540, lr = 0.001
I0429 16:17:01.917028 25258 solver.cpp:239] Iteration 18560 (3.32942 iter/s, 6.00705s/20 iters), loss = 0.216269
I0429 16:17:01.917104 25258 solver.cpp:258]     Train net output #0: loss = 0.216269 (* 1 = 0.216269 loss)
I0429 16:17:01.917117 25258 sgd_solver.cpp:112] Iteration 18560, lr = 0.001
I0429 16:17:07.770032 25258 solver.cpp:239] Iteration 18580 (3.41719 iter/s, 5.85277s/20 iters), loss = 0.183185
I0429 16:17:07.775266 25258 solver.cpp:258]     Train net output #0: loss = 0.183185 (* 1 = 0.183185 loss)
I0429 16:17:07.775285 25258 sgd_solver.cpp:112] Iteration 18580, lr = 0.001
I0429 16:17:13.551576 25258 solver.cpp:239] Iteration 18600 (3.46251 iter/s, 5.77616s/20 iters), loss = 0.125404
I0429 16:17:13.556423 25258 solver.cpp:258]     Train net output #0: loss = 0.125404 (* 1 = 0.125404 loss)
I0429 16:17:13.556474 25258 sgd_solver.cpp:112] Iteration 18600, lr = 0.001
I0429 16:17:20.137544 25258 solver.cpp:239] Iteration 18620 (3.03907 iter/s, 6.58097s/20 iters), loss = 0.193356
I0429 16:17:20.142359 25258 solver.cpp:258]     Train net output #0: loss = 0.193356 (* 1 = 0.193356 loss)
I0429 16:17:20.142379 25258 sgd_solver.cpp:112] Iteration 18620, lr = 0.001
I0429 16:17:26.834237 25258 solver.cpp:239] Iteration 18640 (2.98878 iter/s, 6.6917s/20 iters), loss = 0.12489
I0429 16:17:26.839045 25258 solver.cpp:258]     Train net output #0: loss = 0.12489 (* 1 = 0.12489 loss)
I0429 16:17:26.839082 25258 sgd_solver.cpp:112] Iteration 18640, lr = 0.001
I0429 16:17:33.353159 25258 solver.cpp:239] Iteration 18660 (3.07033 iter/s, 6.51395s/20 iters), loss = 0.172488
I0429 16:17:33.358009 25258 solver.cpp:258]     Train net output #0: loss = 0.172489 (* 1 = 0.172489 loss)
I0429 16:17:33.358037 25258 sgd_solver.cpp:112] Iteration 18660, lr = 0.001
I0429 16:17:38.838301 25258 solver.cpp:239] Iteration 18680 (3.64954 iter/s, 5.48015s/20 iters), loss = 0.152394
I0429 16:17:38.843185 25258 solver.cpp:258]     Train net output #0: loss = 0.152394 (* 1 = 0.152394 loss)
I0429 16:17:38.843221 25258 sgd_solver.cpp:112] Iteration 18680, lr = 0.001
I0429 16:17:45.456213 25258 solver.cpp:239] Iteration 18700 (3.0244 iter/s, 6.61287s/20 iters), loss = 0.17665
I0429 16:17:45.461035 25258 solver.cpp:258]     Train net output #0: loss = 0.17665 (* 1 = 0.17665 loss)
I0429 16:17:45.461061 25258 sgd_solver.cpp:112] Iteration 18700, lr = 0.001
I0429 16:17:51.108667 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:17:52.047821 25258 solver.cpp:239] Iteration 18720 (3.03646 iter/s, 6.58661s/20 iters), loss = 0.101268
I0429 16:17:52.052626 25258 solver.cpp:258]     Train net output #0: loss = 0.101268 (* 1 = 0.101268 loss)
I0429 16:17:52.052657 25258 sgd_solver.cpp:112] Iteration 18720, lr = 0.001
I0429 16:17:58.513497 25258 solver.cpp:239] Iteration 18740 (3.09564 iter/s, 6.46071s/20 iters), loss = 0.138197
I0429 16:17:58.518402 25258 solver.cpp:258]     Train net output #0: loss = 0.138197 (* 1 = 0.138197 loss)
I0429 16:17:58.518435 25258 sgd_solver.cpp:112] Iteration 18740, lr = 0.001
I0429 16:18:02.414424 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_18750.caffemodel
I0429 16:18:56.506086 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_18750.solverstate
I0429 16:18:56.841073 25258 solver.cpp:351] Iteration 18750, Testing net (#0)
I0429 16:18:57.546784 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:19:01.786252 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.907109
I0429 16:19:01.786317 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.958828
I0429 16:19:01.786334 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.979219
I0429 16:19:01.786347 25258 solver.cpp:418]     Test net output #3: loss = 0.24994 (* 1 = 0.24994 loss)
I0429 16:19:03.656276 25258 solver.cpp:239] Iteration 18760 (0.307049 iter/s, 65.1362s/20 iters), loss = 0.205069
I0429 16:19:03.661073 25258 solver.cpp:258]     Train net output #0: loss = 0.205069 (* 1 = 0.205069 loss)
I0429 16:19:03.661103 25258 sgd_solver.cpp:112] Iteration 18760, lr = 0.001
I0429 16:19:07.910830 25258 solver.cpp:239] Iteration 18780 (4.70628 iter/s, 4.24964s/20 iters), loss = 0.294487
I0429 16:19:07.915637 25258 solver.cpp:258]     Train net output #0: loss = 0.294487 (* 1 = 0.294487 loss)
I0429 16:19:07.915660 25258 sgd_solver.cpp:112] Iteration 18780, lr = 0.001
I0429 16:19:12.427194 25258 solver.cpp:239] Iteration 18800 (4.43318 iter/s, 4.51143s/20 iters), loss = 0.166766
I0429 16:19:12.432170 25258 solver.cpp:258]     Train net output #0: loss = 0.166766 (* 1 = 0.166766 loss)
I0429 16:19:12.432229 25258 sgd_solver.cpp:112] Iteration 18800, lr = 0.001
I0429 16:19:16.716478 25258 solver.cpp:239] Iteration 18820 (4.66829 iter/s, 4.28422s/20 iters), loss = 0.255386
I0429 16:19:16.721297 25258 solver.cpp:258]     Train net output #0: loss = 0.255386 (* 1 = 0.255386 loss)
I0429 16:19:16.721335 25258 sgd_solver.cpp:112] Iteration 18820, lr = 0.001
I0429 16:19:22.448842 25258 solver.cpp:239] Iteration 18840 (3.49199 iter/s, 5.7274s/20 iters), loss = 0.120209
I0429 16:19:22.453650 25258 solver.cpp:258]     Train net output #0: loss = 0.120209 (* 1 = 0.120209 loss)
I0429 16:19:22.453682 25258 sgd_solver.cpp:112] Iteration 18840, lr = 0.001
I0429 16:19:28.719439 25258 solver.cpp:239] Iteration 18860 (3.19202 iter/s, 6.26562s/20 iters), loss = 0.26505
I0429 16:19:28.724306 25258 solver.cpp:258]     Train net output #0: loss = 0.26505 (* 1 = 0.26505 loss)
I0429 16:19:28.724334 25258 sgd_solver.cpp:112] Iteration 18860, lr = 0.001
I0429 16:19:34.110322 25258 solver.cpp:239] Iteration 18880 (3.71341 iter/s, 5.38588s/20 iters), loss = 0.199409
I0429 16:19:34.115128 25258 solver.cpp:258]     Train net output #0: loss = 0.199409 (* 1 = 0.199409 loss)
I0429 16:19:34.115155 25258 sgd_solver.cpp:112] Iteration 18880, lr = 0.001
I0429 16:19:39.901540 25258 solver.cpp:239] Iteration 18900 (3.45647 iter/s, 5.78625s/20 iters), loss = 0.216373
I0429 16:19:39.906345 25258 solver.cpp:258]     Train net output #0: loss = 0.216374 (* 1 = 0.216374 loss)
I0429 16:19:39.906383 25258 sgd_solver.cpp:112] Iteration 18900, lr = 0.001
I0429 16:19:47.172101 25258 solver.cpp:239] Iteration 18920 (2.75271 iter/s, 7.26557s/20 iters), loss = 0.121598
I0429 16:19:47.176926 25258 solver.cpp:258]     Train net output #0: loss = 0.121598 (* 1 = 0.121598 loss)
I0429 16:19:47.176955 25258 sgd_solver.cpp:112] Iteration 18920, lr = 0.001
I0429 16:19:53.364136 25258 solver.cpp:239] Iteration 18940 (3.23256 iter/s, 6.18705s/20 iters), loss = 0.36871
I0429 16:19:53.370445 25258 solver.cpp:258]     Train net output #0: loss = 0.36871 (* 1 = 0.36871 loss)
I0429 16:19:53.370492 25258 sgd_solver.cpp:112] Iteration 18940, lr = 0.001
I0429 16:19:58.877126 25258 solver.cpp:239] Iteration 18960 (3.63205 iter/s, 5.50654s/20 iters), loss = 0.0848498
I0429 16:19:58.883131 25258 solver.cpp:258]     Train net output #0: loss = 0.0848499 (* 1 = 0.0848499 loss)
I0429 16:19:58.883185 25258 sgd_solver.cpp:112] Iteration 18960, lr = 0.001
I0429 16:20:05.930801 25258 solver.cpp:239] Iteration 18980 (2.83788 iter/s, 7.04751s/20 iters), loss = 0.213019
I0429 16:20:05.936264 25258 solver.cpp:258]     Train net output #0: loss = 0.213019 (* 1 = 0.213019 loss)
I0429 16:20:05.936338 25258 sgd_solver.cpp:112] Iteration 18980, lr = 0.001
I0429 16:20:18.100909 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_19000.caffemodel
I0429 16:20:29.136405 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_19000.solverstate
I0429 16:20:29.565238 25258 solver.cpp:351] Iteration 19000, Testing net (#0)
I0429 16:20:30.598500 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:20:42.720204 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.906328
I0429 16:20:42.720257 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.957656
I0429 16:20:42.720264 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.97875
I0429 16:20:42.720275 25258 solver.cpp:418]     Test net output #3: loss = 0.248801 (* 1 = 0.248801 loss)
I0429 16:20:43.209581 25258 solver.cpp:239] Iteration 19000 (0.53659 iter/s, 37.2724s/20 iters), loss = 0.136576
I0429 16:20:43.209658 25258 solver.cpp:258]     Train net output #0: loss = 0.136576 (* 1 = 0.136576 loss)
I0429 16:20:43.209816 25258 sgd_solver.cpp:112] Iteration 19000, lr = 0.001
I0429 16:20:49.465075 25258 solver.cpp:239] Iteration 19020 (3.19732 iter/s, 6.25525s/20 iters), loss = 0.156003
I0429 16:20:49.469880 25258 solver.cpp:258]     Train net output #0: loss = 0.156003 (* 1 = 0.156003 loss)
I0429 16:20:49.469908 25258 sgd_solver.cpp:112] Iteration 19020, lr = 0.001
I0429 16:20:55.268496 25258 solver.cpp:239] Iteration 19040 (3.44919 iter/s, 5.79846s/20 iters), loss = 0.197626
I0429 16:20:55.273295 25258 solver.cpp:258]     Train net output #0: loss = 0.197626 (* 1 = 0.197626 loss)
I0429 16:20:55.273324 25258 sgd_solver.cpp:112] Iteration 19040, lr = 0.001
I0429 16:21:01.965595 25258 solver.cpp:239] Iteration 19060 (2.98858 iter/s, 6.69213s/20 iters), loss = 0.214196
I0429 16:21:01.970450 25258 solver.cpp:258]     Train net output #0: loss = 0.214196 (* 1 = 0.214196 loss)
I0429 16:21:01.970471 25258 sgd_solver.cpp:112] Iteration 19060, lr = 0.001
I0429 16:21:08.035946 25258 solver.cpp:239] Iteration 19080 (3.29743 iter/s, 6.06533s/20 iters), loss = 0.249758
I0429 16:21:08.040809 25258 solver.cpp:258]     Train net output #0: loss = 0.249759 (* 1 = 0.249759 loss)
I0429 16:21:08.040843 25258 sgd_solver.cpp:112] Iteration 19080, lr = 0.001
I0429 16:21:14.879098 25258 solver.cpp:239] Iteration 19100 (2.92478 iter/s, 6.83812s/20 iters), loss = 0.190624
I0429 16:21:14.883932 25258 solver.cpp:258]     Train net output #0: loss = 0.190624 (* 1 = 0.190624 loss)
I0429 16:21:14.883961 25258 sgd_solver.cpp:112] Iteration 19100, lr = 0.001
I0429 16:21:21.060899 25258 solver.cpp:239] Iteration 19120 (3.23792 iter/s, 6.17681s/20 iters), loss = 0.124548
I0429 16:21:21.065824 25258 solver.cpp:258]     Train net output #0: loss = 0.124548 (* 1 = 0.124548 loss)
I0429 16:21:21.065888 25258 sgd_solver.cpp:112] Iteration 19120, lr = 0.001
I0429 16:21:28.666158 25258 solver.cpp:239] Iteration 19140 (2.63154 iter/s, 7.60011s/20 iters), loss = 0.164222
I0429 16:21:28.673472 25258 solver.cpp:258]     Train net output #0: loss = 0.164222 (* 1 = 0.164222 loss)
I0429 16:21:28.673511 25258 sgd_solver.cpp:112] Iteration 19140, lr = 0.001
I0429 16:21:35.847362 25258 solver.cpp:239] Iteration 19160 (2.78796 iter/s, 7.17371s/20 iters), loss = 0.217181
I0429 16:21:35.852188 25258 solver.cpp:258]     Train net output #0: loss = 0.217181 (* 1 = 0.217181 loss)
I0429 16:21:35.852210 25258 sgd_solver.cpp:112] Iteration 19160, lr = 0.001
I0429 16:21:42.397027 25258 solver.cpp:239] Iteration 19180 (3.05593 iter/s, 6.54466s/20 iters), loss = 0.151702
I0429 16:21:42.403712 25258 solver.cpp:258]     Train net output #0: loss = 0.151702 (* 1 = 0.151702 loss)
I0429 16:21:42.403777 25258 sgd_solver.cpp:112] Iteration 19180, lr = 0.001
I0429 16:21:42.450801 25258 blocking_queue.cpp:49] Waiting for data
I0429 16:21:48.104996 25258 solver.cpp:239] Iteration 19200 (3.50805 iter/s, 5.70117s/20 iters), loss = 0.143429
I0429 16:21:48.110005 25258 solver.cpp:258]     Train net output #0: loss = 0.143429 (* 1 = 0.143429 loss)
I0429 16:21:48.110055 25258 sgd_solver.cpp:112] Iteration 19200, lr = 0.001
I0429 16:21:54.636781 25258 solver.cpp:239] Iteration 19220 (3.06437 iter/s, 6.52663s/20 iters), loss = 0.228555
I0429 16:21:54.641588 25258 solver.cpp:258]     Train net output #0: loss = 0.228556 (* 1 = 0.228556 loss)
I0429 16:21:54.641649 25258 sgd_solver.cpp:112] Iteration 19220, lr = 0.001
I0429 16:21:59.506944 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:22:00.312022 25258 solver.cpp:239] Iteration 19240 (3.52715 iter/s, 5.6703s/20 iters), loss = 0.163929
I0429 16:22:00.319203 25258 solver.cpp:258]     Train net output #0: loss = 0.163929 (* 1 = 0.163929 loss)
I0429 16:22:00.319245 25258 sgd_solver.cpp:112] Iteration 19240, lr = 0.001
I0429 16:22:02.354542 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_19250.caffemodel
I0429 16:22:38.424437 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_19250.solverstate
I0429 16:22:38.831307 25258 solver.cpp:351] Iteration 19250, Testing net (#0)
I0429 16:22:39.866523 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:22:48.364455 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.908828
I0429 16:22:48.364506 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.958125
I0429 16:22:48.364519 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.979453
I0429 16:22:48.364533 25258 solver.cpp:418]     Test net output #3: loss = 0.241649 (* 1 = 0.241649 loss)
I0429 16:22:52.083032 25258 solver.cpp:239] Iteration 19260 (0.38638 iter/s, 51.7625s/20 iters), loss = 0.13821
I0429 16:22:52.087981 25258 solver.cpp:258]     Train net output #0: loss = 0.138211 (* 1 = 0.138211 loss)
I0429 16:22:52.088024 25258 sgd_solver.cpp:112] Iteration 19260, lr = 0.001
I0429 16:22:58.247922 25258 solver.cpp:239] Iteration 19280 (3.24686 iter/s, 6.1598s/20 iters), loss = 0.194935
I0429 16:22:58.252764 25258 solver.cpp:258]     Train net output #0: loss = 0.194935 (* 1 = 0.194935 loss)
I0429 16:22:58.252795 25258 sgd_solver.cpp:112] Iteration 19280, lr = 0.001
I0429 16:23:03.907080 25258 solver.cpp:239] Iteration 19300 (3.53721 iter/s, 5.65417s/20 iters), loss = 0.196206
I0429 16:23:03.916447 25258 solver.cpp:258]     Train net output #0: loss = 0.196206 (* 1 = 0.196206 loss)
I0429 16:23:03.916491 25258 sgd_solver.cpp:112] Iteration 19300, lr = 0.001
I0429 16:23:11.138787 25258 solver.cpp:239] Iteration 19320 (2.76925 iter/s, 7.22217s/20 iters), loss = 0.144897
I0429 16:23:11.143620 25258 solver.cpp:258]     Train net output #0: loss = 0.144897 (* 1 = 0.144897 loss)
I0429 16:23:11.143652 25258 sgd_solver.cpp:112] Iteration 19320, lr = 0.001
I0429 16:23:17.517388 25258 solver.cpp:239] Iteration 19340 (3.13794 iter/s, 6.3736s/20 iters), loss = 0.296728
I0429 16:23:17.523288 25258 solver.cpp:258]     Train net output #0: loss = 0.296728 (* 1 = 0.296728 loss)
I0429 16:23:17.523344 25258 sgd_solver.cpp:112] Iteration 19340, lr = 0.001
I0429 16:23:24.749274 25258 solver.cpp:239] Iteration 19360 (2.76785 iter/s, 7.22583s/20 iters), loss = 0.103371
I0429 16:23:24.754216 25258 solver.cpp:258]     Train net output #0: loss = 0.103371 (* 1 = 0.103371 loss)
I0429 16:23:24.754254 25258 sgd_solver.cpp:112] Iteration 19360, lr = 0.001
I0429 16:23:29.936954 25258 solver.cpp:239] Iteration 19380 (3.85906 iter/s, 5.18261s/20 iters), loss = 0.213304
I0429 16:23:29.942163 25258 solver.cpp:258]     Train net output #0: loss = 0.213304 (* 1 = 0.213304 loss)
I0429 16:23:29.942196 25258 sgd_solver.cpp:112] Iteration 19380, lr = 0.001
I0429 16:23:36.924883 25258 solver.cpp:239] Iteration 19400 (2.86429 iter/s, 6.98254s/20 iters), loss = 0.181389
I0429 16:23:36.929778 25258 solver.cpp:258]     Train net output #0: loss = 0.18139 (* 1 = 0.18139 loss)
I0429 16:23:36.929821 25258 sgd_solver.cpp:112] Iteration 19400, lr = 0.001
I0429 16:23:43.984088 25258 solver.cpp:239] Iteration 19420 (2.83519 iter/s, 7.0542s/20 iters), loss = 0.14642
I0429 16:23:43.988987 25258 solver.cpp:258]     Train net output #0: loss = 0.14642 (* 1 = 0.14642 loss)
I0429 16:23:43.989034 25258 sgd_solver.cpp:112] Iteration 19420, lr = 0.001
I0429 16:23:50.335503 25258 solver.cpp:239] Iteration 19440 (3.1514 iter/s, 6.34639s/20 iters), loss = 0.198647
I0429 16:23:50.344861 25258 solver.cpp:258]     Train net output #0: loss = 0.198648 (* 1 = 0.198648 loss)
I0429 16:23:50.344913 25258 sgd_solver.cpp:112] Iteration 19440, lr = 0.001
I0429 16:23:56.699559 25258 solver.cpp:239] Iteration 19460 (3.14735 iter/s, 6.35455s/20 iters), loss = 0.21883
I0429 16:23:56.704391 25258 solver.cpp:258]     Train net output #0: loss = 0.21883 (* 1 = 0.21883 loss)
I0429 16:23:56.704468 25258 sgd_solver.cpp:112] Iteration 19460, lr = 0.001
I0429 16:24:03.860772 25258 solver.cpp:239] Iteration 19480 (2.79477 iter/s, 7.15621s/20 iters), loss = 0.0863034
I0429 16:24:03.868228 25258 solver.cpp:258]     Train net output #0: loss = 0.0863035 (* 1 = 0.0863035 loss)
I0429 16:24:03.868273 25258 sgd_solver.cpp:112] Iteration 19480, lr = 0.001
I0429 16:24:09.172184 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_19500.caffemodel
I0429 16:24:29.704449 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_19500.solverstate
I0429 16:24:30.077045 25258 solver.cpp:351] Iteration 19500, Testing net (#0)
I0429 16:24:31.579715 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:24:43.311309 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.910937
I0429 16:24:43.311394 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.959219
I0429 16:24:43.311408 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.979531
I0429 16:24:43.311420 25258 solver.cpp:418]     Test net output #3: loss = 0.238017 (* 1 = 0.238017 loss)
I0429 16:24:43.613626 25258 solver.cpp:239] Iteration 19500 (0.503215 iter/s, 39.7444s/20 iters), loss = 0.183804
I0429 16:24:43.617923 25258 solver.cpp:258]     Train net output #0: loss = 0.183804 (* 1 = 0.183804 loss)
I0429 16:24:43.617996 25258 sgd_solver.cpp:112] Iteration 19500, lr = 0.001
I0429 16:24:49.709854 25258 solver.cpp:239] Iteration 19520 (3.28309 iter/s, 6.09183s/20 iters), loss = 0.16799
I0429 16:24:49.715109 25258 solver.cpp:258]     Train net output #0: loss = 0.16799 (* 1 = 0.16799 loss)
I0429 16:24:49.715150 25258 sgd_solver.cpp:112] Iteration 19520, lr = 0.001
I0429 16:24:55.969399 25258 solver.cpp:239] Iteration 19540 (3.19788 iter/s, 6.25414s/20 iters), loss = 0.226728
I0429 16:24:55.974759 25258 solver.cpp:258]     Train net output #0: loss = 0.226728 (* 1 = 0.226728 loss)
I0429 16:24:55.974813 25258 sgd_solver.cpp:112] Iteration 19540, lr = 0.001
I0429 16:25:02.755367 25258 solver.cpp:239] Iteration 19560 (2.94965 iter/s, 6.78046s/20 iters), loss = 0.198753
I0429 16:25:02.760697 25258 solver.cpp:258]     Train net output #0: loss = 0.198753 (* 1 = 0.198753 loss)
I0429 16:25:02.760737 25258 sgd_solver.cpp:112] Iteration 19560, lr = 0.001
I0429 16:25:09.239449 25258 solver.cpp:239] Iteration 19580 (3.08709 iter/s, 6.4786s/20 iters), loss = 0.197713
I0429 16:25:09.244967 25258 solver.cpp:258]     Train net output #0: loss = 0.197713 (* 1 = 0.197713 loss)
I0429 16:25:09.245025 25258 sgd_solver.cpp:112] Iteration 19580, lr = 0.001
I0429 16:25:16.078857 25258 solver.cpp:239] Iteration 19600 (2.92667 iter/s, 6.83372s/20 iters), loss = 0.193555
I0429 16:25:16.085140 25258 solver.cpp:258]     Train net output #0: loss = 0.193555 (* 1 = 0.193555 loss)
I0429 16:25:16.085198 25258 sgd_solver.cpp:112] Iteration 19600, lr = 0.001
I0429 16:25:21.619176 25258 solver.cpp:239] Iteration 19620 (3.61409 iter/s, 5.53389s/20 iters), loss = 0.131643
I0429 16:25:21.626834 25258 solver.cpp:258]     Train net output #0: loss = 0.131643 (* 1 = 0.131643 loss)
I0429 16:25:21.626924 25258 sgd_solver.cpp:112] Iteration 19620, lr = 0.001
I0429 16:25:25.415277 25258 solver.cpp:239] Iteration 19640 (5.27927 iter/s, 3.7884s/20 iters), loss = 0.159535
I0429 16:25:25.420433 25258 solver.cpp:258]     Train net output #0: loss = 0.159535 (* 1 = 0.159535 loss)
I0429 16:25:25.420477 25258 sgd_solver.cpp:112] Iteration 19640, lr = 0.001
I0429 16:25:32.927230 25258 solver.cpp:239] Iteration 19660 (2.66431 iter/s, 7.50662s/20 iters), loss = 0.215921
I0429 16:25:32.932277 25258 solver.cpp:258]     Train net output #0: loss = 0.215921 (* 1 = 0.215921 loss)
I0429 16:25:32.932322 25258 sgd_solver.cpp:112] Iteration 19660, lr = 0.001
I0429 16:25:39.333122 25258 solver.cpp:239] Iteration 19680 (3.12466 iter/s, 6.40069s/20 iters), loss = 0.145007
I0429 16:25:39.337982 25258 solver.cpp:258]     Train net output #0: loss = 0.145007 (* 1 = 0.145007 loss)
I0429 16:25:39.338055 25258 sgd_solver.cpp:112] Iteration 19680, lr = 0.001
I0429 16:25:45.912394 25258 solver.cpp:239] Iteration 19700 (3.04217 iter/s, 6.57426s/20 iters), loss = 0.148521
I0429 16:25:45.917363 25258 solver.cpp:258]     Train net output #0: loss = 0.148521 (* 1 = 0.148521 loss)
I0429 16:25:45.917410 25258 sgd_solver.cpp:112] Iteration 19700, lr = 0.001
I0429 16:25:52.729141 25258 solver.cpp:239] Iteration 19720 (2.93616 iter/s, 6.81162s/20 iters), loss = 0.102036
I0429 16:25:52.734207 25258 solver.cpp:258]     Train net output #0: loss = 0.102036 (* 1 = 0.102036 loss)
I0429 16:25:52.734263 25258 sgd_solver.cpp:112] Iteration 19720, lr = 0.001
I0429 16:25:59.133149 25258 solver.cpp:239] Iteration 19740 (3.12559 iter/s, 6.3988s/20 iters), loss = 0.228936
I0429 16:25:59.139436 25258 solver.cpp:258]     Train net output #0: loss = 0.228936 (* 1 = 0.228936 loss)
I0429 16:25:59.139490 25258 sgd_solver.cpp:112] Iteration 19740, lr = 0.001
I0429 16:26:01.585078 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_19750.caffemodel
I0429 16:26:58.729205 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_19750.solverstate
I0429 16:26:59.044958 25258 solver.cpp:351] Iteration 19750, Testing net (#0)
I0429 16:27:00.011298 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:27:04.261878 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.909531
I0429 16:27:04.261924 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.957891
I0429 16:27:04.261934 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.979609
I0429 16:27:04.261943 25258 solver.cpp:418]     Test net output #3: loss = 0.243541 (* 1 = 0.243541 loss)
I0429 16:27:05.336673 25312 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:27:05.579939 25258 solver.cpp:239] Iteration 19760 (0.301029 iter/s, 66.4387s/20 iters), loss = 0.107319
I0429 16:27:05.584714 25258 solver.cpp:258]     Train net output #0: loss = 0.107319 (* 1 = 0.107319 loss)
I0429 16:27:05.584740 25258 sgd_solver.cpp:112] Iteration 19760, lr = 0.001
I0429 16:27:08.938021 25258 solver.cpp:239] Iteration 19780 (5.96444 iter/s, 3.35321s/20 iters), loss = 0.174104
I0429 16:27:08.942827 25258 solver.cpp:258]     Train net output #0: loss = 0.174104 (* 1 = 0.174104 loss)
I0429 16:27:08.942859 25258 sgd_solver.cpp:112] Iteration 19780, lr = 0.001
I0429 16:27:13.112711 25258 solver.cpp:239] Iteration 19800 (4.79643 iter/s, 4.16977s/20 iters), loss = 0.205164
I0429 16:27:13.117511 25258 solver.cpp:258]     Train net output #0: loss = 0.205164 (* 1 = 0.205164 loss)
I0429 16:27:13.117530 25258 sgd_solver.cpp:112] Iteration 19800, lr = 0.001
I0429 16:27:17.929010 25258 solver.cpp:239] Iteration 19820 (4.15683 iter/s, 4.81135s/20 iters), loss = 0.168019
I0429 16:27:17.933811 25258 solver.cpp:258]     Train net output #0: loss = 0.168019 (* 1 = 0.168019 loss)
I0429 16:27:17.933835 25258 sgd_solver.cpp:112] Iteration 19820, lr = 0.001
I0429 16:27:23.382011 25258 solver.cpp:239] Iteration 19840 (3.67105 iter/s, 5.44803s/20 iters), loss = 0.0745421
I0429 16:27:23.386961 25258 solver.cpp:258]     Train net output #0: loss = 0.0745422 (* 1 = 0.0745422 loss)
I0429 16:27:23.386994 25258 sgd_solver.cpp:112] Iteration 19840, lr = 0.001
I0429 16:27:29.278570 25258 solver.cpp:239] Iteration 19860 (3.39475 iter/s, 5.89145s/20 iters), loss = 0.282148
I0429 16:27:29.283579 25258 solver.cpp:258]     Train net output #0: loss = 0.282149 (* 1 = 0.282149 loss)
I0429 16:27:29.283612 25258 sgd_solver.cpp:112] Iteration 19860, lr = 0.001
I0429 16:27:35.174088 25258 solver.cpp:239] Iteration 19880 (3.39538 iter/s, 5.89036s/20 iters), loss = 0.0788868
I0429 16:27:35.178886 25258 solver.cpp:258]     Train net output #0: loss = 0.0788868 (* 1 = 0.0788868 loss)
I0429 16:27:35.178906 25258 sgd_solver.cpp:112] Iteration 19880, lr = 0.001
I0429 16:27:41.021950 25258 solver.cpp:239] Iteration 19900 (3.42297 iter/s, 5.84289s/20 iters), loss = 0.270218
I0429 16:27:41.026773 25258 solver.cpp:258]     Train net output #0: loss = 0.270218 (* 1 = 0.270218 loss)
I0429 16:27:41.026814 25258 sgd_solver.cpp:112] Iteration 19900, lr = 0.001
I0429 16:27:46.847235 25258 solver.cpp:239] Iteration 19920 (3.43625 iter/s, 5.8203s/20 iters), loss = 0.16859
I0429 16:27:46.852092 25258 solver.cpp:258]     Train net output #0: loss = 0.16859 (* 1 = 0.16859 loss)
I0429 16:27:46.852123 25258 sgd_solver.cpp:112] Iteration 19920, lr = 0.001
I0429 16:27:53.113526 25258 solver.cpp:239] Iteration 19940 (3.19425 iter/s, 6.26125s/20 iters), loss = 0.105817
I0429 16:27:53.118331 25258 solver.cpp:258]     Train net output #0: loss = 0.105817 (* 1 = 0.105817 loss)
I0429 16:27:53.118372 25258 sgd_solver.cpp:112] Iteration 19940, lr = 0.001
I0429 16:27:59.603507 25258 solver.cpp:239] Iteration 19960 (3.08404 iter/s, 6.485s/20 iters), loss = 0.157075
I0429 16:27:59.612519 25258 solver.cpp:258]     Train net output #0: loss = 0.157076 (* 1 = 0.157076 loss)
I0429 16:27:59.612550 25258 sgd_solver.cpp:112] Iteration 19960, lr = 0.001
I0429 16:28:05.604115 25258 solver.cpp:239] Iteration 19980 (3.3381 iter/s, 5.99143s/20 iters), loss = 0.23646
I0429 16:28:05.608937 25258 solver.cpp:258]     Train net output #0: loss = 0.23646 (* 1 = 0.23646 loss)
I0429 16:28:05.608971 25258 sgd_solver.cpp:112] Iteration 19980, lr = 0.001
I0429 16:28:14.475378 25258 solver.cpp:468] Snapshotting to binary proto file snap_iter_20000.caffemodel
I0429 16:29:25.965829 25258 sgd_solver.cpp:280] Snapshotting solver state to binary proto file snap_iter_20000.solverstate
I0429 16:29:26.369879 25258 solver.cpp:331] Iteration 20000, loss = 0.0940306
I0429 16:29:26.369999 25258 solver.cpp:351] Iteration 20000, Testing net (#0)
I0429 16:29:27.630801 25355 data_layer.cpp:73] Restarting data prefetching from start.
I0429 16:29:31.650537 25258 solver.cpp:418]     Test net output #0: accuracy_top_1 = 0.908906
I0429 16:29:31.650599 25258 solver.cpp:418]     Test net output #1: accuracy_top_2 = 0.956797
I0429 16:29:31.650612 25258 solver.cpp:418]     Test net output #2: accuracy_top_3 = 0.979375
I0429 16:29:31.650625 25258 solver.cpp:418]     Test net output #3: loss = 0.247899 (* 1 = 0.247899 loss)
I0429 16:29:31.650636 25258 solver.cpp:336] Optimization Done.
I0429 16:29:31.650651 25258 caffe.cpp:250] Optimization Done.
